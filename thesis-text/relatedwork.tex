
%*******************************************************************************
\chapter{Related work}
We have studied the latent representations obtained from maximising the InfoNCE objective. 
We achieved this through the introduction of V-GIM, a self-supervised representation learning approach with the same InfoNCE objective, but with an additional constraint to the latent space resulting in better interpretable representations. Such that a decoder could be trained and predict meaningful ...
This is a vastly different approach from existing techniques in explainable AI.

In the field of Explainable AI multiple paradigms exist, ranging from activation heatmaps ...
These techniques give insights in audio domain, but lack in other domains such as speech domain where heatmaps be harder to gain insights from.




---
Explainable ANNs:
	- diff paradigms, by looking at heath maps and lr etc
	- our work is in fact new paradigm, by adding constraints to the optimisation metric, resulting in better understandable latent representations
	- Explainable deep learning methods survey: \cite{baiExplainableDeepLearning2021} (attribution and non attribution, zie mijn draft.dox) --> propbeert contribution van elke feature te linken. dat zijn technieken die werken voor foto's of feature vectors, maar voor puur sequential audio is moeilijker bruikbaar.

Others who have added prior constraint to latent space (ik heb denk ik paper daar van)

Alternative priors

Explainable representation learning

Explainable representation learning in speech data


Maybe exists other techniques that change the ANN resulting in bette explainable. (eg pruning?)
	- methodology to remove features that do not contribute to accuracy. (feature selection) with interpretability motivations. \cite{glorfeldMethodologySimplificationInterpretation1996}

---
CPC and GreedyInfomax:
	- Bart's previous thesis student,
		The same dataset was used by X, Y, for speech learning. X trained a convolutional neural network with the speech recognition task. Y further continued this work by developing a model, based on Greedy Infomax. Showing that learning is feasible. We contribute to Yâ€™s ideas by inspecting the representations that were learned from GIM.
		--> Showing that greedy learning with the corpus is feasible.





\section{Representation learning: explainable}
\section{Variational learning}
There already were a few papers with variational contrastive predictive coding

\section{Links I should investigate}
- S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data Generation
https://arxiv.org/abs/2005.11437

- Implementation of Sequential VAE
https://github.com/ermongroup/Sequential-Variational-Autoencoder

- Contrastively Disentangled Sequential Variational Autoencoder
https://proceedings.neurips.cc/paper/2021/file/53c5b2affa12eed84dfec9bfd83550b1-Paper.pdf

- Sequential Variational Autoencoders for Collaborative Filtering
https://arxiv.org/pdf/1811.09975.pdf

- !! Variational noise contrastive estimation:
https://arxiv.org/abs/1810.08010