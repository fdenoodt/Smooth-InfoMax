@inproceedings{anejaContrastiveLearningApproach2021,
  title = {A {{Contrastive Learning Approach}} for {{Training Variational Autoencoder Priors}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Aneja, Jyoti and Schwing, Alex and Kautz, Jan and Vahdat, Arash},
  date = {2021},
  volume = {34},
  pages = {480--493},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2021/hash/0496604c1d80f66fbeb963c12e570a26-Abstract.html},
  urldate = {2023-02-19},
  abstract = {Variational autoencoders (VAEs) are one of the powerful likelihood-based generative models with applications in many domains. However, they struggle to generate high-quality images, especially when samples are obtained from the prior without any tempering. One explanation for VAEs' poor generative quality is the prior hole problem: the prior distribution fails to match the aggregate approximate posterior. Due to this mismatch, there exist areas in the latent space with high density under the prior that do not correspond to any encoded image. Samples from those areas are decoded to corrupted images. To tackle this issue, we propose an energy-based prior defined by the product of a base prior distribution and a reweighting factor, designed to bring the base closer to the aggregate posterior. We train the reweighting factor by noise contrastive estimation, and we generalize it to hierarchical VAEs with many latent variable groups. Our experiments confirm that the proposed noise contrastive priors improve the generative performance of state-of-the-art VAEs by a large margin on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ 256 datasets. Our method is simple and can be applied to a wide variety of VAEs to improve the expressivity of their prior distribution.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NXZVI8UU\\Aneja et al. - 2021 - A Contrastive Learning Approach for Training Varia.pdf}
}

@article{baiExplainableDeepLearning2021,
  title = {Explainable Deep Learning for Efficient and Robust Pattern Recognition: {{A}} Survey of Recent Developments},
  shorttitle = {Explainable Deep Learning for Efficient and Robust Pattern Recognition},
  author = {Bai, Xiao and Wang, Xiang and Liu, Xianglong and Liu, Qiang and Song, Jingkuan and Sebe, Nicu and Kim, Been},
  date = {2021-12-01},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {120},
  pages = {108102},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2021.108102},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320321002892},
  urldate = {2022-11-05},
  abstract = {Deep learning has recently achieved great success in many visual recognition tasks. However, the deep neural networks (DNNs) are often perceived as black-boxes, making their decision less understandable to humans and prohibiting their usage in safety-critical applications. This guest editorial introduces the thirty papers accepted for the Special Issue on Explainable Deep Learning for Efficient and Robust Pattern Recognition. They are grouped into three main categories: explainable deep learning methods, efficient deep learning via model compression and acceleration, as well as robustness and stability in deep learning. For each of the three topics, a survey of the representative works and latest developments is presented, followed by the brief introduction of the accepted papers belonging to this topic. The special issue should be of high relevance to the reader interested in explainable deep learning methods for efficient and robust pattern recognition applications and it helps promoting the future research directions in this field.},
  langid = {english},
  keywords = {Adversarial robustness,Explainable deep learning,Network compression and acceleration,Stability in deep learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\BFT4CIV5\\S0031320321002892.html}
}

@online{bankAutoencoders2021,
  title = {Autoencoders},
  author = {Bank, Dor and Koenigstein, Noam and Giryes, Raja},
  date = {2021-04-03},
  eprint = {2003.05991},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2003.05991},
  url = {http://arxiv.org/abs/2003.05991},
  urldate = {2023-03-29},
  abstract = {An autoencoder is a specific type of a neural network, which is mainly designed to encode the input into a compressed and meaningful representation, and then decode it back such that the reconstructed input is similar as possible to the original one. This chapter surveys the different types of autoencoders that are mainly used today. It also describes various applications and use-cases of autoencoders.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\4PZ3MMVG\\Bank et al. - 2021 - Autoencoders.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RR5Q4DAM\\2003.html}
}

@online{bartwronskiComparingImagesFrequency2021,
  title = {Comparing Images in Frequency Domain. “{{Spectral}} Loss” – Does It Make Sense?},
  author = {{bartwronski}},
  date = {2021-07-06T22:07:46+00:00},
  url = {https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss-does-it-make-sense/},
  urldate = {2023-02-20},
  abstract = {Recently, numerous academic papers in the machine learning / computer vision / image processing domains (re)introduce and discuss a “frequency loss function” or “spectral loss” – …},
  langid = {english},
  organization = {{Bart Wronski}}
}

@article{bengioRepresentationLearningReview2013,
  title = {Representation {{Learning}}: {{A Review}} and {{New Perspectives}}},
  shorttitle = {Representation {{Learning}}},
  author = {Bengio, Y. and Courville, Aaron and Vincent, Pascal},
  date = {2013-08-01},
  journaltitle = {IEEE transactions on pattern analysis and machine intelligence},
  shortjournal = {IEEE transactions on pattern analysis and machine intelligence},
  volume = {35},
  pages = {1798--1828},
  doi = {10.1109/TPAMI.2013.50},
  abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MVXRT5Y7\\Bengio et al. - 2013 - Representation Learning A Review and New Perspect.pdf}
}

@article{bengioRepresentationLearningReview2013a,
  title = {Representation {{Learning}}: {{A Review}} and {{New Perspectives}}},
  shorttitle = {Representation {{Learning}}},
  author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  date = {2013-08},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {35},
  number = {8},
  pages = {1798--1828},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2013.50},
  abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Abstracts,autoencoder,Boltzmann machine,Deep learning,Feature extraction,feature learning,Learning systems,Machine learning,Manifolds,neural nets,Neural networks,representation learning,Speech recognition,unsupervised learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\XF8CRHKC\\Bengio et al. - 2013 - Representation Learning A Review and New Perspect.pdf;C\:\\Users\\Fab\\Zotero\\storage\\U3UKJRU6\\6472238.html}
}

@online{bhandariStandardNormalDistribution2020,
  title = {The {{Standard Normal Distribution}} | {{Calculator}}, {{Examples}} \& {{Uses}}},
  author = {Bhandari, Pritha},
  date = {2020-11-05T15:14:16+00:00},
  url = {https://www.scribbr.com/statistics/standard-normal-distribution/},
  urldate = {2023-03-30},
  abstract = {The standard normal distribution, also called the z-distribution, is a special normal distribution where the mean is 0 and the standard deviation is 1.},
  langid = {american},
  organization = {{Scribbr}},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\U8GSDBAT\\standard-normal-distribution.html}
}

@online{bhatiSegmentalContrastivePredictive2021b,
  title = {Segmental {{Contrastive Predictive Coding}} for {{Unsupervised Word Segmentation}}},
  author = {Bhati, Saurabhchand and Villalba, Jesús and Żelasko, Piotr and Moro-Velazquez, Laureano and Dehak, Najim},
  date = {2021-06-03},
  eprint = {2106.02170},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2106.02170},
  url = {http://arxiv.org/abs/2106.02170},
  urldate = {2023-04-06},
  abstract = {Automatic detection of phoneme or word-like units is one of the core objectives in zero-resource speech processing. Recent attempts employ self-supervised training methods, such as contrastive predictive coding (CPC), where the next frame is predicted given past context. However, CPC only looks at the audio signal's frame-level structure. We overcome this limitation with a segmental contrastive predictive coding (SCPC) framework that can model the signal structure at a higher level e.g. at the phoneme level. In this framework, a convolutional neural network learns frame-level representation from the raw waveform via noise-contrastive estimation (NCE). A differentiable boundary detector finds variable-length segments, which are then used to optimize a segment encoder via NCE to learn segment representations. The differentiable boundary detector allows us to train frame-level and segment-level encoders jointly. Typically, phoneme and word segmentation are treated as separate tasks. We unify them and experimentally show that our single model outperforms existing phoneme and word segmentation methods on TIMIT and Buckeye datasets. We analyze the impact of boundary threshold and when is the right time to include the segmental loss in the learning process.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\LXSRLX2U\\Bhati et al. - 2021 - Segmental Contrastive Predictive Coding for Unsupe.pdf;C\:\\Users\\Fab\\Zotero\\storage\\8HRLZWUD\\2106.html}
}

@inproceedings{bjorckUnderstandingBatchNormalization2018,
  title = {Understanding {{Batch Normalization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/36072923bfc3cf47745d704feb489480-Abstract.html},
  urldate = {2023-04-25},
  abstract = {Batch normalization (BN) is a technique to normalize activations in intermediate layers of deep neural networks. Its tendency to improve accuracy and speed up training have established BN as a favorite technique in deep learning. Yet, despite its enormous success, there remains little consensus on the exact reason and mechanism behind these improvements. In this paper we take a step towards a better understanding of BN, following an empirical approach. We conduct several experiments, and show that BN primarily enables training with larger learning rates, which is the cause for faster convergence and better generalization. For networks without BN we demonstrate how large gradient updates can result in diverging loss and activations growing uncontrollably with network depth, which limits possible learning rates. BN avoids this problem by constantly correcting activations to be zero-mean and of unit standard deviation, which enables larger gradient steps, yields faster convergence and may help bypass sharp local minima. We further show various ways in which gradients and activations of deep unnormalized networks are ill-behaved. We contrast our results against recent findings in random matrix theory, shedding new light on classical initialization schemes and their consequences.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\YSZAW48P\\Bjorck et al. - 2018 - Understanding Batch Normalization.pdf}
}

@online{burgessUnderstandingDisentanglingBeta2018,
  title = {Understanding Disentangling in \$\textbackslash beta\$-{{VAE}}},
  author = {Burgess, Christopher P. and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  date = {2018-04-10},
  eprint = {1804.03599},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1804.03599},
  url = {http://arxiv.org/abs/1804.03599},
  urldate = {2023-04-22},
  abstract = {We present new intuitions and theoretical assessments of the emergence of disentangled representation in variational autoencoders. Taking a rate-distortion theory perspective, we show the circumstances under which representations aligned with the underlying generative factors of variation of data emerge when optimising the modified ELBO bound in \$\textbackslash beta\$-VAE, as training progresses. From these insights, we propose a modification to the training regime of \$\textbackslash beta\$-VAE, that progressively increases the information capacity of the latent code during training. This modification facilitates the robust learning of disentangled representations in \$\textbackslash beta\$-VAE, without the previous trade-off in reconstruction accuracy.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NF379PPK\\Burgess et al. - 2018 - Understanding disentangling in $beta$-VAE.pdf;C\:\\Users\\Fab\\Zotero\\storage\\24YSE2M4\\1804.html}
}

@article{caporaleSpikeTimingdependentPlasticity2008,
  title = {Spike Timing-Dependent Plasticity: A {{Hebbian}} Learning Rule},
  shorttitle = {Spike Timing-Dependent Plasticity},
  author = {Caporale, Natalia and Dan, Yang},
  date = {2008},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu Rev Neurosci},
  volume = {31},
  eprint = {18275283},
  eprinttype = {pmid},
  pages = {25--46},
  issn = {0147-006X},
  doi = {10.1146/annurev.neuro.31.060407.125639},
  abstract = {Spike timing-dependent plasticity (STDP) as a Hebbian synaptic learning rule has been demonstrated in various neural circuits over a wide spectrum of species, from insects to humans. The dependence of synaptic modification on the order of pre- and postsynaptic spiking within a critical window of tens of milliseconds has profound functional implications. Over the past decade, significant progress has been made in understanding the cellular mechanisms of STDP at both excitatory and inhibitory synapses and of the associated changes in neuronal excitability and synaptic integration. Beyond the basic asymmetric window, recent studies have also revealed several layers of complexity in STDP, including its dependence on dendritic location, the nonlinear integration of synaptic modification induced by complex spike trains, and the modulation of STDP by inhibitory and neuromodulatory inputs. Finally, the functional consequences of STDP have been examined directly in an increasing number of neural circuits in vivo.},
  langid = {english},
  keywords = {Action Potentials,Animals,Brain,Dendrites,Humans,Learning,Neural Inhibition,Neuronal Plasticity,Neurons,Synaptic Transmission,Time Factors}
}

@book{cinelliVariationalMethodsMachine2021,
  title = {Variational {{Methods}} for {{Machine Learning}} with {{Applications}} to {{Deep Networks}}},
  author = {Cinelli, Lucas Pinheiro and Marins, Matheus Araújo and Barros da Silva, Eduardo Antônio and Netto, Sérgio Lima},
  date = {2021},
  edition = {1st ed. 2021 edition},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-70679-1},
  url = {https://link.springer.com/10.1007/978-3-030-70679-1},
  urldate = {2023-04-13},
  abstract = {This book provides a straightforward look at the concepts, algorithms and advantages of Bayesian Deep Learning and Deep Generative Models. Starting from the model-based approach to Machine Learning, the authors motivate Probabilistic Graphical Models and show how Bayesian inference naturally lends itself to this framework. The authors present detailed explanations of the main modern algorithms on variational approximations for Bayesian inference in neural networks. Each algorithm of this selected set develops a distinct aspect of the theory. The book builds from the ground-up well-known deep generative models, such as Variational Autoencoder and subsequent theoretical developments. By also exposing the main issues of the algorithms together with different methods to mitigate such issues, the book supplies the necessary knowledge on generative models for the reader to handle a wide range of data types: sequential or not, continuous or not, labelled or not. The book is self-contained, promptly covering all necessary theory so that the reader does not have to search for additional information elsewhere.Offers a concise self-contained resource, covering the basic concepts to the algorithms for Bayesian Deep Learning;Presents Statistical Inference concepts, offering a set of elucidative examples, practical aspects, and pseudo-codes;Every chapter includes hands-on examples and exercises and a website features lecture slides, additional examples, and other support material.},
  isbn = {978-3-030-70678-4 978-3-030-70679-1},
  langid = {english},
  keywords = {Approximate inference,Artificial intelligence,Bayesian deep learning,Bayesian neural network,Computer vision,Deep neural networks,Expectation propagation,Machine theory,Variational autoencoder,Variational inference},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\KVTZZ3EA\\Cinelli et al. - 2021 - Variational Methods for Machine Learning with Appl.pdf}
}

@book{coverELEMENTSINFORMATIONTHEORY,
  title = {{{ELEMENTS OF INFORMATION THEORY}}},
  author = {Cover, Thomas M and Thomas, Joy A},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\EEF9ZL96\\Cover and Thomas - ELEMENTS OF INFORMATION THEORY.pdf}
}

@video{datasciencecoursesAliGhodsiLec2017,
  title = {Ali {{Ghodsi}}, {{Lec}} : {{Deep Learning}}, {{Variational Autoencoder}}, {{Oct}} 12 2017 [{{Lect}} 6.2]},
  shorttitle = {Ali {{Ghodsi}}, {{Lec}}},
  editor = {{Data Science Courses}},
  date = {2017-10-15},
  url = {https://www.youtube.com/watch?v=uaaqyVS9-rM},
  urldate = {2023-04-07},
  abstract = {Variational Autoencoder},
  editortype = {director}
}

@incollection{davidfosterVariationalAutoencoders2023,
  title = {3. {{Variational Autoencoders}}},
  booktitle = {Generative {{Deep Learning}}, 2nd {{Edition}}},
  author = {{David Foster}},
  date = {2023-05},
  edition = {2},
  url = {https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/},
  urldate = {2023-03-30},
  abstract = {Generative modeling is one of the hottest topics in AI. It's now possible to teach a machine to excel at human endeavors such as painting, writing, and composing music. With this practical book, machine learning engineers and data scientists will discover how to re-create some of the most impressive examples of generative deep learning models such as variational autoencoders (VAEs), generative adversarial networks (GANs), Transformers, normalizing flows, energy based models, and diffusion models. Author David Foster demonstrates the inner workings of each technique, starting with the basics of deep learning before advancing to some of the most cutting-edge algorithms in the field. Through tips and tricks, you'll understand how to make your models learn more efficiently and become more creative. Discover how VAEs can change facial expressions in photos Build practical GAN examples from scratch to generate images based on your own dataset Create autoregressive generative models, such as LSTMs for text generation and PixelCNN models for image generation Build music generation models, using Transformers and MuseGAN Explore the inner workings of state-of-the-art architectures such as StyleGANGPT-3, and DDIM Dive into the the detail of multimodal models such as DALL.E 2 and Imagen for text-to-image generation Understand how generative world models can help agents accomplish tasks within a reinforcement learning setting Understand how the future of generative modeling might evolve, including how businesses will need to adapt to take advantage of the new technologies},
  isbn = {978-1-09-813418-1},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\WIL9MQ4N\\9781098134174.html}
}

@online{dehaanContrastivePredictiveCoding2021,
  title = {Contrastive {{Predictive Coding}} for {{Anomaly Detection}}},
  author = {family=Haan, given=Puck, prefix=de, useprefix=true and Löwe, Sindy},
  date = {2021-07-16},
  eprint = {2107.07820},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2107.07820},
  url = {http://arxiv.org/abs/2107.07820},
  urldate = {2023-04-06},
  abstract = {Reliable detection of anomalies is crucial when deploying machine learning models in practice, but remains challenging due to the lack of labeled data. To tackle this challenge, contrastive learning approaches are becoming increasingly popular, given the impressive results they have achieved in self-supervised representation learning settings. However, while most existing contrastive anomaly detection and segmentation approaches have been applied to images, none of them can use the contrastive losses directly for both anomaly detection and segmentation. In this paper, we close this gap by making use of the Contrastive Predictive Coding model (arXiv:1807.03748). We show that its patch-wise contrastive loss can directly be interpreted as an anomaly score, and how this allows for the creation of anomaly segmentation masks. The resulting model achieves promising results for both anomaly detection and segmentation on the challenging MVTec-AD dataset.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\32XAAULP\\de Haan and Löwe - 2021 - Contrastive Predictive Coding for Anomaly Detectio.pdf;C\:\\Users\\Fab\\Zotero\\storage\\HTAD9LUH\\2107.html}
}

@inproceedings{deldariTimeSeriesChange2021,
  title = {Time {{Series Change Point Detection}} with {{Self-Supervised Contrastive Predictive Coding}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Deldari, Shohreh and Smith, Daniel V. and Xue, Hao and Salim, Flora D.},
  date = {2021-06-03},
  series = {{{WWW}} '21},
  pages = {3124--3135},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3442381.3449903},
  url = {https://dl.acm.org/doi/10.1145/3442381.3449903},
  urldate = {2023-04-06},
  abstract = {Change Point Detection (CPD) methods identify the times associated with changes in the trends and properties of time series data in order to describe the underlying behaviour of the system. For instance, detecting the changes and anomalies associated with web service usage, application usage or human behaviour can provide valuable insights for downstream modelling tasks. We propose a novel approach for self-supervised Time Series Change Point detection method based on Contrastive Predictive coding (TS − CP2). TS − CP2 is the first approach to employ a contrastive learning strategy for CPD by learning an embedded representation that separates pairs of embeddings of time adjacent intervals from pairs of interval embeddings separated across time. Through extensive experiments on three diverse, widely used time series datasets, we demonstrate that our method outperforms five state-of-the-art CPD methods, which include unsupervised and semi-supervised approaches. TS − CP2 is shown to improve the performance of methods that use either handcrafted statistical or temporal features by 79.4\% and deep learning-based methods by 17.0\% with respect to the F1-score averaged across the three datasets.},
  isbn = {978-1-4503-8312-7},
  keywords = {Anomaly detection,Contrastive learning,Time series change point detection,Unsupervised learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\7K5W3KIP\\Deldari et al. - 2021 - Time Series Change Point Detection with Self-Super.pdf}
}

@online{doerschTutorialVariationalAutoencoders2021,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  date = {2021-01-03},
  eprint = {1606.05908},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1606.05908},
  url = {http://arxiv.org/abs/1606.05908},
  urldate = {2023-04-07},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GRM99QC6\\Doersch - 2021 - Tutorial on Variational Autoencoders.pdf;C\:\\Users\\Fab\\Zotero\\storage\\484AFYZ3\\1606.html}
}

@article{grossuttiDeepLearningInfrared2022,
  title = {Deep {{Learning}} and {{Infrared Spectroscopy}}: {{Representation Learning}} with a {{Beta-Variational Autoencoder}}},
  shorttitle = {Deep {{Learning}} and {{Infrared Spectroscopy}}},
  author = {Grossutti, Michael and D’Amico, Joseph and Quintal, Jonathan and MacFarlane, Hugh and Quirk, Amanda and Dutcher, John R.},
  date = {2022-06-30},
  journaltitle = {The Journal of Physical Chemistry Letters},
  shortjournal = {J. Phys. Chem. Lett.},
  volume = {13},
  number = {25},
  pages = {5787--5793},
  publisher = {{American Chemical Society}},
  doi = {10.1021/acs.jpclett.2c01328},
  url = {https://doi.org/10.1021/acs.jpclett.2c01328},
  urldate = {2023-04-12},
  abstract = {Infrared (IR) spectra contain detailed and extensive information about the chemical composition and bonding environment in a sample. However, this information is difficult to extract from complex heterogeneous systems because of overlapping absorptions due to different generative factors. We implement a deep learning approach to study the complex spectroscopic changes that occur in cross-linked polyethylene (PEX-a) pipe by training a Beta-variational autoencoder (Beta-VAE) on a database of PEX-a pipe spectra. We show that the Beta-VAE outperforms principal component analysis (PCA) and learns interpretable and independent representations of the generative factors of variance in the spectra. We apply the Beta-VAE encoder to a hyperspectrum of a crack in the wall of a pipe to evaluate the spatial distribution of these learned representations. This study shows how deep learning architectures like Beta-VAE can enhance the analysis of spectroscopic data of complex heterogeneous systems.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\J7NTSUB7\\Grossutti et al. - 2022 - Deep Learning and Infrared Spectroscopy Represent.pdf;C\:\\Users\\Fab\\Zotero\\storage\\FS248ZH7\\acs.jpclett.html}
}

@inproceedings{henaffDataEfficientImageRecognition2020,
  title = {Data-{{Efficient Image Recognition}} with {{Contrastive Predictive Coding}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Henaff, Olivier},
  date = {2020-11-21},
  pages = {4182--4192},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/henaff20a.html},
  urldate = {2023-04-06},
  abstract = {Human observers can learn to recognize new categories of images from a handful of examples, yet doing so with artificial ones remains an open challenge. We hypothesize that data-efficient recognition is enabled by representations which make the variability in natural signals more predictable. We therefore revisit and improve Contrastive Predictive Coding, an unsupervised objective for learning such representations. This new implementation produces features which support state-of-the-art linear classification accuracy on the ImageNet dataset. When used as input for non-linear classification with deep neural networks, this representation allows us to use 2-5x less labels than classifiers trained directly on image pixels. Finally, this unsupervised representation substantially improves transfer learning to object detection on the PASCAL VOC dataset, surpassing fully supervised pre-trained ImageNet classifiers.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\EIZ3GV98\\Henaff - 2020 - Data-Efficient Image Recognition with Contrastive .pdf;C\:\\Users\\Fab\\Zotero\\storage\\RAJYDHYM\\Henaff - 2020 - Data-Efficient Image Recognition with Contrastive .pdf}
}

@inproceedings{higginsBetaVAELearningBasic2022,
  title = {Beta-{{VAE}}: {{Learning Basic Visual Concepts}} with a {{Constrained Variational Framework}}},
  shorttitle = {Beta-{{VAE}}},
  author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  date = {2022-07-21},
  url = {https://openreview.net/forum?id=Sy2fzU9gl},
  urldate = {2023-04-22},
  abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter beta that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that beta-VAE with appropriately tuned beta {$>$} 1 qualitatively outperforms VAE (beta = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also significantly outperforms all baselines quantitatively. Unlike InfoGAN, beta-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter, which can be directly optimised through a hyper parameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\KVW7LUBW\\Higgins et al. - 2022 - beta-VAE Learning Basic Visual Concepts with a Co.pdf}
}

@online{ioffeBatchNormalizationAccelerating2015,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  date = {2015-03-02},
  eprint = {1502.03167},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1502.03167},
  url = {http://arxiv.org/abs/1502.03167},
  urldate = {2023-04-19},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\AXZ49JIK\\Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf;C\:\\Users\\Fab\\Zotero\\storage\\XEH27CBD\\1502.html}
}

@online{karagiannakosHowGenerateImages2018,
  title = {How to {{Generate Images}} Using {{Autoencoders}}},
  author = {Karagiannakos, Sergios},
  date = {2018-09-09},
  url = {https://theaisummer.com/Autoencoder/},
  urldate = {2023-04-07},
  abstract = {Learn what autoencoders are and build one to generate new images},
  langid = {english},
  organization = {{AI Summer}}
}

@online{kingmaAutoEncodingVariationalBayes2022,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2022-12-10},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1312.6114},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2023-04-04},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\58JTVZV4\\Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf;C\:\\Users\\Fab\\Zotero\\storage\\C5TQ888L\\1312.html}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {4},
  eprint = {1906.02691},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {http://arxiv.org/abs/1906.02691},
  urldate = {2023-03-30},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\RVFG7F9F\\Kingma and Welling - 2019 - An Introduction to Variational Autoencoders.pdf;C\:\\Users\\Fab\\Zotero\\storage\\AQ83KMRQ\\1906.html}
}

@online{laiContrastivePredictiveCoding2019,
  title = {Contrastive {{Predictive Coding Based Feature}} for {{Automatic Speaker Verification}}},
  author = {Lai, Cheng-I.},
  date = {2019-04-01},
  eprint = {1904.01575},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.1904.01575},
  url = {http://arxiv.org/abs/1904.01575},
  urldate = {2023-04-06},
  abstract = {This thesis describes our ongoing work on Contrastive Predictive Coding (CPC) features for speaker verification. CPC is a recently proposed representation learning framework based on predictive coding and noise contrastive estimation. We focus on incorporating CPC features into the standard automatic speaker verification systems, and we present our methods, experiments, and analysis. This thesis also details necessary background knowledge in past and recent work on automatic speaker verification systems, conventional speech features, and the motivation and techniques behind CPC.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\XISIK4LT\\Lai - 2019 - Contrastive Predictive Coding Based Feature for Au.pdf;C\:\\Users\\Fab\\Zotero\\storage\\LXU26RFN\\1904.html}
}

@article{le-khacContrastiveRepresentationLearning2020,
  title = {Contrastive {{Representation Learning}}: {{A Framework}} and {{Review}}},
  shorttitle = {Contrastive {{Representation Learning}}},
  author = {Le-Khac, Phuc H. and Healy, Graham and Smeaton, Alan F.},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {193907--193934},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3031549},
  abstract = {Contrastive Learning has recently received interest due to its success in self-supervised representation learning in the computer vision domain. However, the origins of Contrastive Learning date as far back as the 1990s and its development has spanned across many fields and domains including Metric Learning and natural language processing. In this paper, we provide a comprehensive literature review and we propose a general Contrastive Representation Learning framework that simplifies and unifies many different contrastive learning methods. We also provide a taxonomy for each of the components of contrastive learning in order to summarise it and distinguish it from other forms of machine learning. We then discuss the inductive biases which are present in any contrastive learning system and we analyse our framework under different views from various sub-fields of Machine Learning. Examples of how contrastive learning has been applied in computer vision, natural language processing, audio processing, and others, as well as in Reinforcement Learning are also presented. Finally, we discuss the challenges and some of the most promising future research directions ahead.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Computational modeling,Contrastive learning,Data models,deep learning,Feature extraction,Learning systems,machine learning,Machine learning,Natural language processing,representation learning,self-supervised learning,Task analysis,unsupervised learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GRTCEVRE\\Le-Khac et al. - 2020 - Contrastive Representation Learning A Framework a.pdf;C\:\\Users\\Fab\\Zotero\\storage\\WWSBG6JX\\stamp.html}
}

@incollection{lecunEfficientBackProp1998,
  title = {Efficient {{BackProp}}},
  booktitle = {Neural {{Networks}}: {{Tricks}} of the {{Trade}}},
  author = {LeCun, Yann and Bottou, Leon and Orr, Genevieve B. and Müller, Klaus -Robert},
  editor = {Orr, Genevieve B. and Müller, Klaus-Robert},
  date = {1998},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {9--50},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-49430-8},
  url = {https://doi.org/10.1007/3-540-49430-8},
  urldate = {2023-04-25},
  abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observedb y practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposedin serious technical publications. This paper gives some of those tricks, ando.ers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most “classical” second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
  isbn = {978-3-540-49430-0},
  langid = {english},
  keywords = {Conjugate Gradient,Handwritten Digit,Learning Rate,Neural Information Processing System,Newton Algorithm},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\UQZKDQAQ\\LeCun et al. - 1998 - Efficient BackProp.pdf}
}

@article{linskerSelfOrganizationPerceptualNetwork1988,
  title = {Self-{{Organization}} in a {{Perceptual Network}}.},
  author = {Linsker, Ralph},
  date = {1988-03-01},
  journaltitle = {IEEE Computer},
  shortjournal = {IEEE Computer},
  volume = {21},
  pages = {105--117},
  doi = {10.1109/2.36},
  abstract = {In this article, the author briefly summarizes the network ideas from an earlier publication and reviews some of the main results. This sets the stage for exploring why a feature-analyzing function emerges. He then shows that even a single developing cell of a layered network exhibits a remarkable set of optimization properties. These properties are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representations in artificial intelligence, and information theory. Next, he uses these results to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle he proposes is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. He illustrates how this principle works for some very simple cases. Much more work will be needed to apply the principle to practical computations of biologically important cases, but the approach appears very promising. He concludes with some speculative comments on why this principle, or some variant of it, may be important for the emergence of perceptual function in biological and synthetic systems.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\4UV3LQ8S\\Linsker - 1988 - Self-Organization in a Perceptual Network..pdf}
}

@online{lowePuttingEndEndtoEnd2020,
  title = {Putting {{An End}} to {{End-to-End}}: {{Gradient-Isolated Learning}} of {{Representations}}},
  shorttitle = {Putting {{An End}} to {{End-to-End}}},
  author = {Löwe, Sindy and O'Connor, Peter and Veeling, Bastiaan S.},
  date = {2020-01-27},
  eprint = {1905.11786},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1905.11786},
  url = {http://arxiv.org/abs/1905.11786},
  urldate = {2022-10-05},
  abstract = {We propose a novel deep learning method for local self-supervised representation learning that does not require labels nor end-to-end backpropagation but exploits the natural order in data instead. Inspired by the observation that biological neural networks appear to learn without backpropagating a global error signal, we split a deep neural network into a stack of gradient-isolated modules. Each module is trained to maximally preserve the information of its inputs using the InfoNCE bound from Oord et al. [2018]. Despite this greedy training, we demonstrate that each module improves upon the output of its predecessor, and that the representations created by the top module yield highly competitive results on downstream classification tasks in the audio and visual domain. The proposal enables optimizing modules asynchronously, allowing large-scale distributed training of very deep neural networks on unlabelled datasets.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NKST6QEI\\Löwe et al. - 2020 - Putting An End to End-to-End Gradient-Isolated Le.pdf;C\:\\Users\\Fab\\Zotero\\storage\\DGLLIKIT\\1905.html}
}

@article{lucasUnderstandingPosteriorCollapse2022,
  title = {Understanding {{Posterior Collapse}} in {{Generative Latent Variable Models}}},
  author = {Lucas, James and Tucker, George and Grosse, Roger and Norouzi, Mohammad},
  date = {2022-07-11},
  url = {https://openreview.net/forum?id=r1xaVLUYuE},
  urldate = {2023-04-22},
  abstract = {Posterior collapse in Variational Autoencoders (VAEs) arises when the variational distribution closely matches the uninformative prior for a subset of latent variables. This paper presents a simple and intuitive explanation for posterior collapse through the analysis of linear VAEs and their direct correspondence with Probabilistic PCA (pPCA). We identify how local maxima can emerge from the marginal log-likelihood of pPCA, which yields similar local maxima for the evidence lower bound (ELBO). We show that training a linear VAE with variational inference recovers a uniquely identifiable global maximum corresponding to the principal component directions. We provide empirical evidence that the presence of local maxima causes posterior collapse in deep non-linear VAEs. Our findings help to explain a wide range of heuristic approaches in the literature that attempt to diminish the effect of the KL term in the ELBO to reduce posterior collapse.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\9RLA5RXB\\Lucas et al. - 2022 - Understanding Posterior Collapse in Generative Lat.pdf}
}

@article{luongDesigningInterpretableRecurrent2021,
  title = {Designing {{Interpretable Recurrent Neural Networks}} for {{Video Reconstruction}} via {{Deep Unfolding}}},
  author = {Luong, Huynh Van and Joukovsky, Boris and Deligiannis, Nikos},
  date = {2021},
  journaltitle = {Ieee Transactions on Image Processing},
  shortjournal = {IEEE Trans. Image Process.},
  volume = {30},
  pages = {4099--4113},
  publisher = {{Ieee-Inst Electrical Electronics Engineers Inc}},
  location = {{Piscataway}},
  issn = {1057-7149},
  doi = {10.1109/TIP.2021.3069296},
  url = {http://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DynamicDOIArticle&SrcApp=WOS&KeyAID=10.1109%2FTIP.2021.3069296&DestApp=DOI&SrcAppSID=EUW1ED0EC2mMtqu9x5Eo9sqmWEy6d&SrcJTitle=IEEE+TRANSACTIONS+ON+IMAGE+PROCESSING&DestDOIRegistrantName=Institute+of+Electrical+and+Electronics+Engineers},
  urldate = {2022-11-05},
  abstract = {Deep unfolding methods design deep neural networks as learned variations of optimization algorithms through the unrolling of their iterations. These networks have been shown to achieve faster convergence and higher accuracy than the original optimization methods. In this line of research, this paper presents novel interpretable deep recurrent neural networks (RNNs), designed by the unfolding of iterative algorithms that solve the task of sequential signal reconstruction (in particular, video reconstruction). The proposed networks are designed by accounting that video frames' patches have a sparse representation and the temporal difference between consecutive representations is also sparse. Specifically, we design an interpretable deep RNN (coined reweighted-RNN) by unrolling the iterations of a proximal method that solves a reweighted version of the l(1)-l(1) minimization problem. Due to the underlying minimization model, our reweighted-RNN has a different thresholding function (alias, different activation function) for each hidden unit in each layer. In this way, it has higher network expressivity than existing deep unfolding RNN models. We also present the derivative l(1)-l(1)-RNN model, which is obtained by unfolding a proximal method for the l(1)-l(1) minimization problem. We apply the proposed interpretable RNNs to the task of video frame reconstruction from low-dimensional measurements, that is, sequential video frame reconstruction. The experimental results on various datasets demonstrate that the proposed deep RNNs outperform various RNN models.},
  langid = {english},
  keywords = {Deep unfolding,inverse problems,recurrent neural   networks,reweighted l(1)-l(1) minimization,sequential frame reconstruction,sparse,thresholding algorithm},
  annotation = {WOS:000639653800002}
}

@online{luSemiSupervisedHistologyClassification2019,
  title = {Semi-{{Supervised Histology Classification}} Using {{Deep Multiple Instance Learning}} and {{Contrastive Predictive Coding}}},
  author = {Lu, Ming Y. and Chen, Richard J. and Wang, Jingwen and Dillon, Debora and Mahmood, Faisal},
  date = {2019-11-02},
  eprint = {1910.10825},
  eprinttype = {arxiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.1910.10825},
  url = {http://arxiv.org/abs/1910.10825},
  urldate = {2023-04-06},
  abstract = {Convolutional neural networks can be trained to perform histology slide classification using weak annotations with multiple instance learning (MIL). However, given the paucity of labeled histology data, direct application of MIL can easily suffer from overfitting and the network is unable to learn rich feature representations due to the weak supervisory signal. We propose to overcome such limitations with a two-stage semi-supervised approach that combines the power of data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and the interpretability and flexibility of regularized attention-based MIL. We apply our two-stage CPC + MIL semi-supervised pipeline to the binary classification of breast cancer histology images. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95\% and an area under the ROC curve of 0.968. We further evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework even with the feature encoder frozen.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Quantitative Biology - Tissues and Organs},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MRM6G54A\\Lu et al. - 2019 - Semi-Supervised Histology Classification using Dee.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RVZT5KGU\\1910.html}
}

@article{marblestoneIntegrationDeepLearning2016,
  title = {Toward an {{Integration}} of {{Deep Learning}} and {{Neuroscience}}},
  author = {Marblestone, Adam H. and Wayne, Greg and Kording, Konrad P.},
  date = {2016},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {10},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2016.00094},
  urldate = {2023-04-04},
  abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\LTDYZYN2\\Marblestone et al. - 2016 - Toward an Integration of Deep Learning and Neurosc.pdf}
}

@inproceedings{NIPS2012_c399862d,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
  date = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper{\_}files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf}
}

@online{oordRepresentationLearningContrastive2019,
  title = {Representation {{Learning}} with {{Contrastive Predictive Coding}}},
  author = {family=Oord, given=Aaron, prefix=van den, useprefix=false and Li, Yazhe and Vinyals, Oriol},
  date = {2019-01-22},
  eprint = {1807.03748},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1807.03748},
  url = {http://arxiv.org/abs/1807.03748},
  urldate = {2022-10-16},
  abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\YRNBNG2M\\Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RP9HCEKT\\1807.html}
}

@online{PapersCodeMNIST,
  title = {Papers with {{Code}} - {{MNIST Dataset}}},
  url = {https://paperswithcode.com/dataset/mnist},
  urldate = {2023-03-30},
  abstract = {The MNIST database (Modified National Institute of Standards and Technology database) is a large collection of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger NIST Special Database 3 (digits written by employees of the United States Census Bureau) and Special Database 1 (digits written by high school students) which contain monochrome images of handwritten digits. The digits have been size-normalized and centered in a fixed-size image. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\CA79ISSF\\mnist.html}
}

@online{raoUnderstandingGradientIsolatedLearning2020,
  title = {Understanding the {{Gradient-Isolated Learning}} of {{Representations}} and Intuition to the {{Greedy}}…},
  author = {Rao, Sumanth S.},
  date = {2020-01-28T04:15:53},
  url = {https://medium.com/analytics-vidhya/understanding-the-gradient-isolated-learning-of-representations-and-intuition-to-the-greedy-cb6c3598e317},
  urldate = {2022-11-13},
  abstract = {Since my association with Data Science and Machine learning, the one question that has always fascinated me is the humongous amount of…},
  langid = {english},
  organization = {{Analytics Vidhya}},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\D7XD89X5\\understanding-the-gradient-isolated-learning-of-representations-and-intuition-to-the-greedy-cb6.html}
}

@online{rhodesVariationalNoiseContrastiveEstimation2019,
  title = {Variational {{Noise-Contrastive Estimation}}},
  author = {Rhodes, Benjamin and Gutmann, Michael},
  date = {2019-02-24},
  eprint = {1810.08010},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1810.08010},
  urldate = {2023-02-19},
  abstract = {Unnormalised latent variable models are a broad and flexible class of statistical models. However, learning their parameters from data is intractable, and few estimation techniques are currently available for such models. To increase the number of techniques in our arsenal, we propose variational noise-contrastive estimation (VNCE), building on NCE which is a method that only applies to unnormalised models. The core idea is to use a variational lower bound to the NCE objective function, which can be optimised in the same fashion as the evidence lower bound (ELBO) in standard variational inference (VI). We prove that VNCE can be used for both parameter estimation of unnormalised models and posterior inference of latent variables. The developed theory shows that VNCE has the same level of generality as standard VI, meaning that advances made there can be directly imported to the unnormalised setting. We validate VNCE on toy models and apply it to a realistic problem of estimating an undirected graphical model from incomplete data.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\4NUG94Z8\\Rhodes and Gutmann - 2019 - Variational Noise-Contrastive Estimation.pdf;C\:\\Users\\Fab\\Zotero\\storage\\E5RCECL5\\1810.html}
}

@inproceedings{rumelhartLearningInternalRepresentations1988,
  title = {Learning {{Internal Representations}} by {{Error Propagation}}},
  booktitle = {Readings in {{Cognitive Science}}},
  author = {Rumelhart, D.E. and Hinton, G.E. and Williams, R.J.},
  date = {1988},
  pages = {399--421},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-1-4832-1446-7.50035-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9781483214467500352},
  urldate = {2023-03-29},
  abstract = {Semantic Scholar extracted view of "Learning internal representations by error propagation" by D. Rumelhart et al.},
  isbn = {978-1-4832-1446-7},
  langid = {english}
}

@inproceedings{santurkarHowDoesBatch2018,
  title = {How {{Does Batch Normalization Help Optimization}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/905056c1ac1dad141560467e0a99e1cf-Abstract.html},
  urldate = {2023-04-25},
  abstract = {Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers' input distributions during training to reduce the so-called "internal covariate shift". In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\ITSBCI6D\\Santurkar et al. - 2018 - How Does Batch Normalization Help Optimization.pdf}
}

@article{shah92LearningGood,
  title = {[{{AN}} \#92]: {{Learning}} Good Representations with Contrastive Predictive Coding},
  shorttitle = {[{{AN}} \#92]},
  author = {Shah, Rohin},
  url = {https://www.lesswrong.com/posts/XE6LD2c9NtB7gMdEm/an-92-learning-good-representations-with-contrastive},
  urldate = {2023-04-04},
  abstract = {Newsletter \#92 • Alignment Newsletter is a weekly publication with recent content relevant to AI alignment around the world. Find all Alignment Newsletter resources here. In particular, you can look…},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MMJNICYH\\an-92-learning-good-representations-with-contrastive.html}
}

@inproceedings{sivasankaranExplainingDeepLearning2021,
  title = {Explaining Deep Learning Models for Speech Enhancement},
  booktitle = {Interspeech 2021},
  author = {Sivasankaran, Sunit and Vincent, Emmanuel and Fohr, Dominique},
  date = {2021},
  pages = {696--700},
  publisher = {{Isca-Int Speech Communication Assoc}},
  location = {{Baixas}},
  issn = {2308-457X},
  doi = {10.21437/Interspeech.2021-1764},
  url = {http://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DOISource&SrcApp=UA&KeyAID=10.21437%2Finterspeech.2021-1764&DestApp=DOI&SrcAppSID=EUW1ED0EC2mMtqu9x5Eo9sqmWEy6d&SrcJTitle=INTERSPEECH+2021&DestDOIRegistrantName=International+Speech+Communication+Association},
  urldate = {2022-11-05},
  abstract = {We consider the problem of explaining the robustness of neural networks used to compute time-frequency masks for speech enhancement to mismatched noise conditions. We employ the Deep SHapley Additive exPlanations (DeepSHAP) feature attribution method to quantify the contribution of every time-frequency bin in the input noisy speech signal to every time-frequency bin in the output time-frequency mask. We define an objective metric - referred to as the speech relevance score-that summarizes the obtained SHAP values and show that it correlates with the enhancement performance, as measured by the word error rate on the CHiME-4 real evaluation dataset. We use the speech relevance score to explain the generalization ability of three speech enhancement models trained using synthetically generated speech-shaped noise, noise from a professional sound effects library, or real CHiME-4 noise. To the best of our knowledge, this is the first study on neural network explainability in the context of speech enhancement.},
  langid = {english},
  keywords = {Deep learning,explainable AI,feature attribution,recognition,separation,speech enhancement},
  annotation = {WOS:000841879500140},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\AHRHL8CM\\Sivasankaran et al. - 2021 - Explaining deep learning models for speech enhance.pdf}
}

@inproceedings{stackeEvaluationContrastivePredictive2020,
  title = {Evaluation of {{Contrastive Predictive Coding}} for {{Histopathology Applications}}},
  booktitle = {Proceedings of the {{Machine Learning}} for {{Health NeurIPS Workshop}}},
  author = {Stacke, Karin and Lundström, Claes and Unger, Jonas and Eilertsen, Gabriel},
  date = {2020-11-23},
  pages = {328--340},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v136/stacke20a.html},
  urldate = {2023-04-06},
  abstract = {Recent advances in self-supervised learning for image data are closing the gap between unsupervised and supervised learning. However, the effectiveness of self-supervised methods has primarily been demonstrated for natural images. If the results would extrapolate to histopathology images, there could be significant benefits due to the reduced need for annotated data. In this paper, Contrastive Predictive Coding (CPC), one of the most promising stateof-the-art self-supervised methods, is extensively evaluated on histology data by varying a range of different parameters, including training objective, resolution, and data setup. From the results, we are able to draw important conclusions on the usefulness of CPC for digital pathology. We show strong evidence of the limitations of the learned representation for tumor classification, where only low-level information learned early during training, in the first CPC layers, is used. Furthermore, in our experiments, diversifying the distribution of the dataset (i.e., data from multiple organs or medical centers) does not lead to the model learning a more general representation. This study deepens the understanding of how the CPC model’s objective relates to intrinsic characteristics of histology datasets and will help the development of effective self-supervised methods for histopathology.},
  eventtitle = {Machine {{Learning}} for {{Health}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\Y7A6ZGSE\\Stacke et al. - 2020 - Evaluation of Contrastive Predictive Coding for Hi.pdf}
}

@online{steinmetzAutomaticMultitrackMixing2020,
  title = {Automatic Multitrack Mixing with a Differentiable Mixing Console of Neural Audio Effects},
  author = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
  date = {2020-10-20},
  eprint = {2010.10291},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2010.10291},
  urldate = {2023-04-21},
  abstract = {We present auraloss1, a PyTorch package that implements time and frequency domain loss functions designed for audio generation tasks. The package provides a straightforward interface, as well as multichannel support. We demonstrate its application by using each loss function to train a model on the task of emulating an analog dynamic range compressor.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NR57CR4V\\Steinmetz et al. - 2020 - Automatic multitrack mixing with a differentiable .pdf}
}

@online{steinmetzAutomaticMultitrackMixing2020a,
  title = {Automatic Multitrack Mixing with a Differentiable Mixing Console of Neural Audio Effects},
  author = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
  date = {2020-10-20},
  eprint = {2010.10291},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2010.10291},
  urldate = {2023-04-22},
  abstract = {We present auraloss1, a PyTorch package that implements time and frequency domain loss functions designed for audio generation tasks. The package provides a straightforward interface, as well as multichannel support. We demonstrate its application by using each loss function to train a model on the task of emulating an analog dynamic range compressor.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\2SUTWJAN\\Steinmetz et al. - 2020 - Automatic multitrack mixing with a differentiable .pdf}
}

@online{tschannenRecentAdvancesAutoencoderBased2018,
  title = {Recent {{Advances}} in {{Autoencoder-Based Representation Learning}}},
  author = {Tschannen, Michael and Bachem, Olivier and Lucic, Mario},
  date = {2018-12-12},
  eprint = {1812.05069},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1812.05069},
  url = {http://arxiv.org/abs/1812.05069},
  urldate = {2023-04-13},
  abstract = {Learning useful representations with little or no supervision is a key challenge in artificial intelligence. We provide an in-depth review of recent advances in representation learning with a focus on autoencoder-based models. To organize these results we make use of meta-priors believed useful for downstream tasks, such as disentanglement and hierarchical organization of features. In particular, we uncover three main mechanisms to enforce such properties, namely (i) regularizing the (approximate or aggregate) posterior distribution, (ii) factorizing the encoding and decoding distribution, or (iii) introducing a structured prior distribution. While there are some promising results, implicit or explicit supervision remains a key enabler and all current methods use strong inductive biases and modeling assumptions. Finally, we provide an analysis of autoencoder-based representation learning through the lens of rate-distortion theory and identify a clear tradeoff between the amount of prior knowledge available about the downstream tasks, and how useful the representation is for this task.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\DDUVT5AT\\Tschannen et al. - 2018 - Recent Advances in Autoencoder-Based Representatio.pdf;C\:\\Users\\Fab\\Zotero\\storage\\V2YIM77C\\1812.html}
}

@online{wangContrastVAEContrastiveVariational2022,
  title = {{{ContrastVAE}}: {{Contrastive Variational AutoEncoder}} for {{Sequential Recommendation}}},
  shorttitle = {{{ContrastVAE}}},
  author = {Wang, Yu and Zhang, Hengrui and Liu, Zhiwei and Yang, Liangwei and Yu, Philip S.},
  date = {2022-12-05},
  eprint = {2209.00456},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.00456},
  urldate = {2023-02-19},
  abstract = {Aiming at exploiting the rich information in user behaviour sequences, sequential recommendation has been widely adopted in real-world recommender systems. However, current methods suffer from the following issues: 1) sparsity of user-item interactions, 2) uncertainty of sequential records, 3) long-tail items. In this paper, we propose to incorporate contrastive learning into the framework of Variational AutoEncoders to address these challenges simultaneously. Firstly, we introduce ContrastELBO, a novel training objective that extends the conventional single-view ELBO to two-view case and theoretically builds a connection between VAE and contrastive learning from a two-view perspective. Then we propose Contrastive Variational AutoEncoder (ContrastVAE in short), a two-branched VAE model with contrastive regularization as an embodiment of ContrastELBO for sequential recommendation. We further introduce two simple yet effective augmentation strategies named model augmentation and variational augmentation to create a second view of a sequence and thus making contrastive learning possible. Experiments on four benchmark datasets demonstrate the effectiveness of ContrastVAE and the proposed augmentation methods. Codes are available at https://github.com/YuWang-1024/ContrastVAE},
  pubstate = {preprint},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\U6ZB8GPZ\\Wang et al. - 2022 - ContrastVAE Contrastive Variational AutoEncoder f.pdf;C\:\\Users\\Fab\\Zotero\\storage\\YDPKPFPL\\2209.html}
}

@article{weiRecentAdvancesVariational2021,
  title = {Recent {{Advances}} in {{Variational Autoencoders With Representation Learning}} for {{Biomedical Informatics}}: {{A Survey}}},
  shorttitle = {Recent {{Advances}} in {{Variational Autoencoders With Representation Learning}} for {{Biomedical Informatics}}},
  author = {Wei, Ruoqi and Mahmood, Ausif},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {4939--4956},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3048309},
  abstract = {Variational autoencoders (VAEs) are deep latent space generative models that have been immensely successful in multiple exciting applications in biomedical informatics such as molecular design, protein design, medical image classification and segmentation, integrated multi-omics data analyses, and large-scale biological sequence analyses, among others. The fundamental idea in VAEs is to learn the distribution of data in such a way that new meaningful data with more intra-class variations can be generated from the encoded distribution. The ability of VAEs to synthesize new data with more representation variance at state-of-art levels provides hope that the chronic scarcity of labeled data in the biomedical field can be resolved. Furthermore, VAEs have made nonlinear latent variable models tractable for modeling complex distributions. This has allowed for efficient extraction of relevant biomedical information from learned features for biological data sets, referred to as unsupervised feature representation learning. In this article, we review the various recent advancements in the development and application of VAEs for biomedical informatics. We discuss challenges and future opportunities for biomedical research with respect to VAEs.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Bioinformatics,Biological system modeling,biomedical informatics,Data models,data representation,Decoding,Deep learning,generative models,latent space,Mathematical model,representation learning,Training,unsupervised learning,variational autoencoders (VAEs)},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\K3ZNRVJA\\Wei and Mahmood - 2021 - Recent Advances in Variational Autoencoders With R.pdf;C\:\\Users\\Fab\\Zotero\\storage\\6DB7RA94\\9311619.html}
}

@article{zhangSlowFeatureAnalysis2012,
  title = {Slow {{Feature Analysis}} for {{Human Action Recognition}}},
  author = {Zhang, Zhang and Tao, Dacheng},
  date = {2012-03},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {34},
  number = {3},
  pages = {436--450},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2011.157},
  abstract = {Slow Feature Analysis (SFA) extracts slowly varying features from a quickly varying input signal [1]. It has been successfully applied to modeling the visual receptive fields of the cortical neurons. Sufficient experimental results in neuroscience suggest that the temporal slowness principle is a general learning principle in visual perception. In this paper, we introduce the SFA framework to the problem of human action recognition by incorporating the discriminative information with SFA learning and considering the spatial relationship of body parts. In particular, we consider four kinds of SFA learning strategies, including the original unsupervised SFA (U-SFA), the supervised SFA (S-SFA), the discriminative SFA (D-SFA), and the spatial discriminative SFA (SD–SFA), to extract slow feature functions from a large amount of training cuboids which are obtained by random sampling in motion boundaries. Afterward, to represent action sequences, the squared first order temporal derivatives are accumulated over all transformed cuboids into one feature vector, which is termed the Accumulated Squared Derivative (ASD) feature. The ASD feature encodes the statistical distribution of slow features in an action sequence. Finally, a linear support vector machine (SVM) is trained to classify actions represented by ASD features. We conduct extensive experiments, including two sets of control experiments, two sets of large scale experiments on the KTH and Weizmann databases, and two sets of experiments on the CASIA and UT-interaction databases, to demonstrate the effectiveness of SFA for human action recognition. Experimental results suggest that the SFA-based approach (1) is able to extract useful motion patterns and improves the recognition performance, (2) requires less intermediate processing steps but achieves comparable or even better performance, and (3) has good potential to recognize complex multiperson activities.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Feature extraction,Human action recognition,Humans,Neurons,Pattern recognition,slow feature analysis.,Spatiotemporal phenomena,Vectors,Visualization},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NQBMBLMJ\\Zhang and Tao - 2012 - Slow Feature Analysis for Human Action Recognition.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RCB6IWT4\\6136516.html}
}

@article{zouConvolutionalNeuralNetwork2018,
  title = {Convolutional Neural Network Simplification via Feature Map Pruning},
  author = {Zou, Junhua and Rui, Ting and Zhou, You and Yang, Chengsong and Zhang, Sai},
  date = {2018-08-01},
  journaltitle = {Computers \& Electrical Engineering},
  shortjournal = {Computers \& Electrical Engineering},
  volume = {70},
  pages = {950--958},
  issn = {0045-7906},
  doi = {10.1016/j.compeleceng.2018.01.036},
  url = {https://www.sciencedirect.com/science/article/pii/S0045790617326393},
  urldate = {2022-11-05},
  abstract = {Convolutional neural networks (CNNs) have been a focus area of machine learning in recent years, and they are widely used in vision and speech processing because of their superior performance. However, CNNs are usually resource-heavy to ensure higher accuracy, i.e., an accurate network with millions of parameters requires high performance computing devices. This prevents the use of CNNs in resource-limited hardware. In this paper, we propose a novel CNN simplification method to prune feature maps with relatively low discriminability magnitudes, which can produce a simplified CNN with reduced computational cost. Specifically, we define the critical points among the discriminability values of feature maps in each convolutional layer, and use these critical points to easily find the best pruning number of feature maps. Our experimental results show that in each convolutional layer of the VGG model, 15.6\% to 59.7\% of feature maps can be pruned without any loss of accuracy in classification tasks.},
  langid = {english},
  keywords = {Convolutional neural network,Critical points,Discriminability,Feature maps pruning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\P9ZINAV9\\S0045790617326393.html}
}
