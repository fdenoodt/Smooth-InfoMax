@article{ackleyLearningAlgorithmBoltzmann1985,
  title = {A Learning Algorithm for Boltzmann Machines},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  date = {1985-01-01},
  journaltitle = {Cognitive Science},
  shortjournal = {Cognitive Science},
  volume = {9},
  number = {1},
  pages = {147--169},
  issn = {0364-0213},
  doi = {10.1016/S0364-0213(85)80012-4},
  url = {https://www.sciencedirect.com/science/article/pii/S0364021385800124},
  urldate = {2023-05-08},
  abstract = {The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\JZCAA6DW\\Ackley et al. - 1985 - A learning algorithm for boltzmann machines.pdf;C\:\\Users\\Fab\\Zotero\\storage\\9BUK7H8G\\S0364021385800124.html}
}

@article{agrawalInterpretableRepresentationLearning2020,
  title = {Interpretable {{Representation Learning}} for {{Speech}} and {{Audio Signals Based}} on {{Relevance Weighting}}},
  author = {Agrawal, Purvi and Ganapathy, Sriram},
  date = {2020},
  journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {28},
  pages = {2823--2836},
  issn = {2329-9304},
  doi = {10.1109/TASLP.2020.3030489},
  abstract = {The learning of interpretable representations from raw data presents significant challenges for time series data like speech. In this work, we propose a relevance weighting scheme that allows the interpretation of the speech representations during the forward propagation of the model itself. The relevance weighting is achieved using a sub-network approach that performs the task of feature selection. A relevance sub-network, applied on the output of first layer of a convolutional neural network model operating on raw speech signals, acts as an acoustic filterbank (FB) layer with relevance weighting. A similar relevance sub-network applied on the second convolutional layer performs modulation filterbank learning with relevance weighting. The full acoustic model consisting of relevance sub-networks, convolutional layers and feed-forward layers is trained for a speech recognition task on noisy and reverberant speech in the Aurora-4, CHiME-3 and VOiCES datasets. The proposed representation learning framework is also applied for the task of sound classification in the UrbanSound8K dataset. A detailed analysis of the relevance weights learned by the model reveals that the relevance weights capture information regarding the underlying speech/audio content. In addition, speech recognition and sound classification experiments reveal that the incorporation of relevance weighting in the neural network architecture improves the performance significantly.},
  eventtitle = {{{IEEE}}/{{ACM Transactions}} on {{Audio}}, {{Speech}}, and {{Language Processing}}},
  keywords = {Acoustic-phonetics,Acoustics,automatic speech recognition,deep representation learning,Kernel,Modulation,modulation filtering,Neural networks,raw waveform processing,relevance modeling,Speech recognition,Task analysis,Time-frequency analysis,urban sound classification},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\UCR7YKX3\\Agrawal and Ganapathy - 2020 - Interpretable Representation Learning for Speech a.pdf;C\:\\Users\\Fab\\Zotero\\storage\\WNVZJS5R\\9224148.html}
}

@inproceedings{anejaContrastiveLearningApproach2021,
  title = {A {{Contrastive Learning Approach}} for {{Training Variational Autoencoder Priors}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Aneja, Jyoti and Schwing, Alex and Kautz, Jan and Vahdat, Arash},
  date = {2021},
  volume = {34},
  pages = {480--493},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2021/hash/0496604c1d80f66fbeb963c12e570a26-Abstract.html},
  urldate = {2023-02-19},
  abstract = {Variational autoencoders (VAEs) are one of the powerful likelihood-based generative models with applications in many domains. However, they struggle to generate high-quality images, especially when samples are obtained from the prior without any tempering. One explanation for VAEs' poor generative quality is the prior hole problem: the prior distribution fails to match the aggregate approximate posterior. Due to this mismatch, there exist areas in the latent space with high density under the prior that do not correspond to any encoded image. Samples from those areas are decoded to corrupted images. To tackle this issue, we propose an energy-based prior defined by the product of a base prior distribution and a reweighting factor, designed to bring the base closer to the aggregate posterior. We train the reweighting factor by noise contrastive estimation, and we generalize it to hierarchical VAEs with many latent variable groups. Our experiments confirm that the proposed noise contrastive priors improve the generative performance of state-of-the-art VAEs by a large margin on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ 256 datasets. Our method is simple and can be applied to a wide variety of VAEs to improve the expressivity of their prior distribution.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NXZVI8UU\\Aneja et al. - 2021 - A Contrastive Learning Approach for Training Varia.pdf}
}

@article{aremuMachineLearningApproach2020,
  title = {A Machine Learning Approach to Circumventing the Curse of Dimensionality in Discontinuous Time Series Machine Data},
  author = {Aremu, Oluseun Omotola and Hyland-Wood, David and McAree, Peter Ross},
  date = {2020-03-01},
  journaltitle = {Reliability Engineering \& System Safety},
  shortjournal = {Reliability Engineering \& System Safety},
  volume = {195},
  pages = {106706},
  issn = {0951-8320},
  doi = {10.1016/j.ress.2019.106706},
  url = {https://www.sciencedirect.com/science/article/pii/S0951832019304752},
  urldate = {2023-05-01},
  abstract = {The growing interest in artificial intelligence has led to current data-driven predictive maintenance (PdM) relying on machine learning (ML) algorithms. Although ML algorithms are useful for data-intensive analysis, research shows that their performance and reliability are reduced when high-dimensional data is used for training and testing. Raw machine data can be high-dimensional due to multi-sensor measurements and discontinuous due to the wide ranges of parameter variations during continuous sensor measurements. While standard dimension reduction methods such as principal component analysis are often applied to circumvent high-dimensionality, they are often unreliable when the data is discontinuous. This paper presents a ML-based dimension reduction framework to circumvent the challenges of high-dimensional discontinuous machine data. This framework minimizes discontinuity by clustering observations based on the dataset’s modality. The modality is identified using a kernel density estimation parameterized using a heat diffusion solution to the approximate mean integrated squared error. Then, low-dimension representations of each cluster are learned using Laplacian eigenmaps embedding. Finally, the original time sequence of observations across the low-dimensional clusters is used to re-index the observations into a continuous low-dimension feature set. We demonstrate the framework’s utility on common ML-based PdM analysis using the Commercial Modular Aero-Propulsion System Simulation dataset.},
  langid = {english},
  keywords = {Deep learning,Dimension reduction,Machine learning,Manifold learning,Partial differential equations,Predictive maintenance,Prognostics},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\F3I3R33I\\Aremu et al. - 2020 - A machine learning approach to circumventing the c.pdf;C\:\\Users\\Fab\\Zotero\\storage\\PCWUVDIA\\S0951832019304752.html}
}

@article{bachBreakingCurseDimensionality,
  title = {Breaking the {{Curse}} of {{Dimensionality}} with {{Convex Neural Networks}}},
  author = {Bach, Francis},
  abstract = {We consider neural networks with a single hidden layer and non-decreasing positively homogeneous activation functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, they lead to a convex optimization problem and we provide a detailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity-inducing norms on the input weights, we show that high-dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total number of variables potentially exponential in the number of observations. However, solving this convex optimization problem in infinite dimensions is only possible if the non-convex subproblem of addition of a new unit can be solved efficiently. We provide a simple geometric interpretation for our choice of activation functions and describe simple conditions for convex relaxations of the finite-dimensional non-convex subproblem to achieve the same generalization error bounds, even when constant-factor approximations cannot be found. We were not able to find strong enough convex relaxations to obtain provably polynomialtime algorithms and leave open the existence or non-existence of such tractable algorithms with non-exponential sample complexities.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\94EEF8H2\\Bach - Breaking the Curse of Dimensionality with Convex N.pdf}
}

@article{baiExplainableDeepLearning2021,
  title = {Explainable Deep Learning for Efficient and Robust Pattern Recognition: {{A}} Survey of Recent Developments},
  shorttitle = {Explainable Deep Learning for Efficient and Robust Pattern Recognition},
  author = {Bai, Xiao and Wang, Xiang and Liu, Xianglong and Liu, Qiang and Song, Jingkuan and Sebe, Nicu and Kim, Been},
  date = {2021-12-01},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {120},
  pages = {108102},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2021.108102},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320321002892},
  urldate = {2022-11-05},
  abstract = {Deep learning has recently achieved great success in many visual recognition tasks. However, the deep neural networks (DNNs) are often perceived as black-boxes, making their decision less understandable to humans and prohibiting their usage in safety-critical applications. This guest editorial introduces the thirty papers accepted for the Special Issue on Explainable Deep Learning for Efficient and Robust Pattern Recognition. They are grouped into three main categories: explainable deep learning methods, efficient deep learning via model compression and acceleration, as well as robustness and stability in deep learning. For each of the three topics, a survey of the representative works and latest developments is presented, followed by the brief introduction of the accepted papers belonging to this topic. The special issue should be of high relevance to the reader interested in explainable deep learning methods for efficient and robust pattern recognition applications and it helps promoting the future research directions in this field.},
  langid = {english},
  keywords = {Adversarial robustness,Explainable deep learning,Network compression and acceleration,Stability in deep learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\7IZHVWIH\\Bai et al. - 2021 - Explainable deep learning for efficient and robust.pdf;C\:\\Users\\Fab\\Zotero\\storage\\BFT4CIV5\\S0031320321002892.html}
}

@inproceedings{baiInterpretableRepresentationLearning2018,
  title = {Interpretable {{Representation Learning}} for {{Healthcare}} via {{Capturing Disease Progression}} through {{Time}}},
  booktitle = {Proceedings of the 24th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Bai, Tian and Zhang, Shanshan and Egleston, Brian L. and Vucetic, Slobodan},
  date = {2018-07-19},
  series = {{{KDD}} '18},
  pages = {43--51},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3219819.3219904},
  url = {https://dl.acm.org/doi/10.1145/3219819.3219904},
  urldate = {2023-05-23},
  abstract = {Various deep learning models have recently been applied to predictive modeling of Electronic Health Records (EHR). In medical claims data, which is a particular type of EHR data, each patient is represented as a sequence of temporally ordered irregularly sampled visits to health providers, where each visit is recorded as an unordered set of medical codes specifying patient's diagnosis and treatment provided during the visit. Based on the observation that different patient conditions have different temporal progression patterns, in this paper we propose a novel interpretable deep learning model, called Timeline. The main novelty of Timeline is that it has a mechanism that learns time decay factors for every medical code. This allows the Timeline to learn that chronic conditions have a longer lasting impact on future visits than acute conditions. Timeline also has an attention mechanism that improves vector embeddings of visits. By analyzing the attention weights and disease progression functions of Timeline, it is possible to interpret the predictions and understand how risks of future visits change over time. We evaluated Timeline on two large-scale real world data sets. The specific task was to predict what is the primary diagnosis category for the next hospital visit given previous visits. Our results show that Timeline has higher accuracy than the state of the art deep learning models based on RNN. In addition, we demonstrate that time decay factors and attentions learned by Timeline are in accord with the medical knowledge and that Timeline can provide a useful insight into its predictions.},
  isbn = {978-1-4503-5552-0},
  keywords = {attention model,deep learning,electronic health records,healthcare},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\6399U4EC\\Bai et al. - 2018 - Interpretable Representation Learning for Healthca.pdf}
}

@online{bankAutoencoders2021,
  title = {Autoencoders},
  author = {Bank, Dor and Koenigstein, Noam and Giryes, Raja},
  date = {2021-04-03},
  eprint = {2003.05991},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2003.05991},
  url = {http://arxiv.org/abs/2003.05991},
  urldate = {2023-03-29},
  abstract = {An autoencoder is a specific type of a neural network, which is mainly designed to encode the input into a compressed and meaningful representation, and then decode it back such that the reconstructed input is similar as possible to the original one. This chapter surveys the different types of autoencoders that are mainly used today. It also describes various applications and use-cases of autoencoders.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\4PZ3MMVG\\Bank et al. - 2021 - Autoencoders.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RR5Q4DAM\\2003.html}
}

@online{barbieroModelingGeneralizationMachine2020,
  title = {Modeling {{Generalization}} in {{Machine Learning}}: {{A Methodological}} and {{Computational Study}}},
  shorttitle = {Modeling {{Generalization}} in {{Machine Learning}}},
  author = {Barbiero, Pietro and Squillero, Giovanni and Tonda, Alberto},
  date = {2020-06-28},
  eprint = {2006.15680},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.15680},
  url = {http://arxiv.org/abs/2006.15680},
  urldate = {2023-05-01},
  abstract = {As machine learning becomes more and more available to the general public, theoretical questions are turning into pressing practical issues. Possibly, one of the most relevant concerns is the assessment of our confidence in trusting machine learning predictions. In many real-world cases, it is of utmost importance to estimate the capabilities of a machine learning algorithm to generalize, i.e., to provide accurate predictions on unseen data, depending on the characteristics of the target problem. In this work, we perform a meta-analysis of 109 publicly-available classification data sets, modeling machine learning generalization as a function of a variety of data set characteristics, ranging from number of samples to intrinsic dimensionality, from class-wise feature skewness to \$F1\$ evaluated on test samples falling outside the convex hull of the training set. Experimental results demonstrate the relevance of using the concept of the convex hull of the training data in assessing machine learning generalization, by emphasizing the difference between interpolated and extrapolated predictions. Besides several predictable correlations, we observe unexpectedly weak associations between the generalization ability of machine learning models and all metrics related to dimensionality, thus challenging the common assumption that the \textbackslash textit\{curse of dimensionality\} might impair generalization in machine learning.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\2NQTCR8J\\Barbiero et al. - 2020 - Modeling Generalization in Machine Learning A Met.pdf;C\:\\Users\\Fab\\Zotero\\storage\\7IARUEVG\\2006.html}
}

@online{bartwronskiComparingImagesFrequency2021,
  title = {Comparing Images in Frequency Domain. “{{Spectral}} Loss” – Does It Make Sense?},
  author = {{bartwronski}},
  date = {2021-07-06T22:07:46+00:00},
  url = {https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss-does-it-make-sense/},
  urldate = {2023-02-20},
  abstract = {Recently, numerous academic papers in the machine learning / computer vision / image processing domains (re)introduce and discuss a “frequency loss function” or “spectral loss” – …},
  langid = {english},
  organization = {{Bart Wronski}}
}

@article{bauerDeepLearningRemedy2019,
  title = {On Deep Learning as a Remedy for the Curse of Dimensionality in Nonparametric Regression},
  author = {Bauer, Benedikt and Kohler, Michael},
  date = {2019-08},
  journaltitle = {The Annals of Statistics},
  volume = {47},
  number = {4},
  pages = {2261--2285},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/18-AOS1747},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-4/On-deep-learning-as-a-remedy-for-the-curse-of/10.1214/18-AOS1747.full},
  urldate = {2023-05-01},
  abstract = {Assuming that a smoothness condition and a suitable restriction on the structure of the regression function hold, it is shown that least squares estimates based on multilayer feedforward neural networks are able to circumvent the curse of dimensionality in nonparametric regression. The proof is based on new approximation results concerning multilayer feedforward neural networks with bounded weights and a bounded number of hidden neurons. The estimates are compared with various other approaches by using simulated data.},
  keywords = {62G08,62G20,curse of dimensionality,neural networks,Nonparametric regression,rate of convergence},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\UB8EXP4G\\Bauer and Kohler - 2019 - On deep learning as a remedy for the curse of dime.pdf}
}

@article{bengioCurseDimensionalityLocal,
  title = {The {{Curse}} of {{Dimensionality}} for {{Local Kernel Machines}}.},
  author = {Bengio, Yoshua and Delalleau, Olivier and Roux, Nicolas Le and Box, P O},
  abstract = {We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms based on local kernels are sensitive to the curse of dimensionality. These include local manifold learning algorithms such as Isomap and LLE, support vector classifiers with Gaussian or other local kernels, and graph-based semisupervised learning algorithms using a local similarity function. These algorithms are shown to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set. This makes them sensitive to the curse of dimensionality, well studied for classical non-parametric statistical learning. There is a large class of data distributions for which non-local solutions could be expressed compactly and potentially be learned with few examples, but which will require a large number of local bases and therefore a large number of training examples when using a local learning algorithm.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\L5YPB3VN\\Bengio et al. - The Curse of Dimensionality for Local Kernel Machi.pdf}
}

@article{bengioRepresentationLearningReview2013,
  title = {Representation {{Learning}}: {{A Review}} and {{New Perspectives}}},
  shorttitle = {Representation {{Learning}}},
  author = {Bengio, Y. and Courville, Aaron and Vincent, Pascal},
  date = {2013-08-01},
  journaltitle = {IEEE transactions on pattern analysis and machine intelligence},
  shortjournal = {IEEE transactions on pattern analysis and machine intelligence},
  volume = {35},
  pages = {1798--1828},
  doi = {10.1109/TPAMI.2013.50},
  abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MVXRT5Y7\\Bengio et al. - 2013 - Representation Learning A Review and New Perspect.pdf}
}

@online{bhandariStandardNormalDistribution2020,
  title = {The {{Standard Normal Distribution}} | {{Calculator}}, {{Examples}} \& {{Uses}}},
  author = {Bhandari, Pritha},
  date = {2020-11-05T15:14:16+00:00},
  url = {https://www.scribbr.com/statistics/standard-normal-distribution/},
  urldate = {2023-03-30},
  abstract = {The standard normal distribution, also called the z-distribution, is a special normal distribution where the mean is 0 and the standard deviation is 1.},
  langid = {american},
  organization = {{Scribbr}},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\U8GSDBAT\\standard-normal-distribution.html}
}

@online{bhargavladGuidePytorchLearning,
  title = {Guide to {{Pytorch Learning Rate Scheduling}}},
  author = {{Bhargav Lad}},
  url = {https://kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling},
  urldate = {2023-05-10},
  abstract = {Explore and run machine learning code with Kaggle Notebooks | Using data from No attached data sources},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\HRT4V5GI\\guide-to-pytorch-learning-rate-scheduling.html}
}

@online{bhatiSegmentalContrastivePredictive2021b,
  title = {Segmental {{Contrastive Predictive Coding}} for {{Unsupervised Word Segmentation}}},
  author = {Bhati, Saurabhchand and Villalba, Jesús and Żelasko, Piotr and Moro-Velazquez, Laureano and Dehak, Najim},
  date = {2021-06-03},
  eprint = {2106.02170},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2106.02170},
  url = {http://arxiv.org/abs/2106.02170},
  urldate = {2023-04-06},
  abstract = {Automatic detection of phoneme or word-like units is one of the core objectives in zero-resource speech processing. Recent attempts employ self-supervised training methods, such as contrastive predictive coding (CPC), where the next frame is predicted given past context. However, CPC only looks at the audio signal's frame-level structure. We overcome this limitation with a segmental contrastive predictive coding (SCPC) framework that can model the signal structure at a higher level e.g. at the phoneme level. In this framework, a convolutional neural network learns frame-level representation from the raw waveform via noise-contrastive estimation (NCE). A differentiable boundary detector finds variable-length segments, which are then used to optimize a segment encoder via NCE to learn segment representations. The differentiable boundary detector allows us to train frame-level and segment-level encoders jointly. Typically, phoneme and word segmentation are treated as separate tasks. We unify them and experimentally show that our single model outperforms existing phoneme and word segmentation methods on TIMIT and Buckeye datasets. We analyze the impact of boundary threshold and when is the right time to include the segmental loss in the learning process.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\LXSRLX2U\\Bhati et al. - 2021 - Segmental Contrastive Predictive Coding for Unsupe.pdf;C\:\\Users\\Fab\\Zotero\\storage\\8HRLZWUD\\2106.html}
}

@inproceedings{bjorckUnderstandingBatchNormalization2018,
  title = {Understanding {{Batch Normalization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/36072923bfc3cf47745d704feb489480-Abstract.html},
  urldate = {2023-04-25},
  abstract = {Batch normalization (BN) is a technique to normalize activations in intermediate layers of deep neural networks. Its tendency to improve accuracy and speed up training have established BN as a favorite technique in deep learning. Yet, despite its enormous success, there remains little consensus on the exact reason and mechanism behind these improvements. In this paper we take a step towards a better understanding of BN, following an empirical approach. We conduct several experiments, and show that BN primarily enables training with larger learning rates, which is the cause for faster convergence and better generalization. For networks without BN we demonstrate how large gradient updates can result in diverging loss and activations growing uncontrollably with network depth, which limits possible learning rates. BN avoids this problem by constantly correcting activations to be zero-mean and of unit standard deviation, which enables larger gradient steps, yields faster convergence and may help bypass sharp local minima. We further show various ways in which gradients and activations of deep unnormalized networks are ill-behaved. We contrast our results against recent findings in random matrix theory, shedding new light on classical initialization schemes and their consequences.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\YSZAW48P\\Bjorck et al. - 2018 - Understanding Batch Normalization.pdf}
}

@online{braunConsolidatedViewLoss2020,
  title = {A Consolidated View of Loss Functions for Supervised Deep Learning-Based Speech Enhancement},
  author = {Braun, Sebastian and Tashev, Ivan},
  date = {2020-09-25},
  eprint = {2009.12286},
  eprinttype = {arxiv},
  eprintclass = {eess},
  url = {http://arxiv.org/abs/2009.12286},
  urldate = {2023-05-17},
  abstract = {Deep learning-based speech enhancement for real-time applications recently made large advancements. Due to the lack of a tractable perceptual optimization target, many myths around training losses emerged, whereas the contribution to success of the loss functions in many cases has not been investigated isolated from other factors such as network architecture, features, or training procedures. In this work, we investigate a wide variety of loss spectral functions for a recurrent neural network architecture suitable to operate in online frame-by-frame processing. We relate magnitude-only with phase-aware losses, ratios, correlation metrics, and compressed metrics. Our results reveal that combining magnitude-only with phase-aware objectives always leads to improvements, even when the phase is not enhanced. Furthermore, using compressed spectral values also yields a significant improvement. On the other hand, phase-sensitive improvement is best achieved by linear domain losses such as mean absolute error.},
  pubstate = {preprint},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\I7DNXDF2\\Braun and Tashev - 2020 - A consolidated view of loss functions for supervis.pdf;C\:\\Users\\Fab\\Zotero\\storage\\SMFD3BZY\\2009.html}
}

@online{burgessUnderstandingDisentanglingBeta2018,
  title = {Understanding Disentangling in \$\textbackslash beta\$-{{VAE}}},
  author = {Burgess, Christopher P. and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  date = {2018-04-10},
  eprint = {1804.03599},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1804.03599},
  url = {http://arxiv.org/abs/1804.03599},
  urldate = {2023-04-22},
  abstract = {We present new intuitions and theoretical assessments of the emergence of disentangled representation in variational autoencoders. Taking a rate-distortion theory perspective, we show the circumstances under which representations aligned with the underlying generative factors of variation of data emerge when optimising the modified ELBO bound in \$\textbackslash beta\$-VAE, as training progresses. From these insights, we propose a modification to the training regime of \$\textbackslash beta\$-VAE, that progressively increases the information capacity of the latent code during training. This modification facilitates the robust learning of disentangled representations in \$\textbackslash beta\$-VAE, without the previous trade-off in reconstruction accuracy.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NF379PPK\\Burgess et al. - 2018 - Understanding disentangling in $beta$-VAE.pdf;C\:\\Users\\Fab\\Zotero\\storage\\24YSE2M4\\1804.html}
}

@article{caporaleSpikeTimingdependentPlasticity2008,
  title = {Spike Timing-Dependent Plasticity: A {{Hebbian}} Learning Rule},
  shorttitle = {Spike Timing-Dependent Plasticity},
  author = {Caporale, Natalia and Dan, Yang},
  date = {2008},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu Rev Neurosci},
  volume = {31},
  eprint = {18275283},
  eprinttype = {pmid},
  pages = {25--46},
  issn = {0147-006X},
  doi = {10.1146/annurev.neuro.31.060407.125639},
  abstract = {Spike timing-dependent plasticity (STDP) as a Hebbian synaptic learning rule has been demonstrated in various neural circuits over a wide spectrum of species, from insects to humans. The dependence of synaptic modification on the order of pre- and postsynaptic spiking within a critical window of tens of milliseconds has profound functional implications. Over the past decade, significant progress has been made in understanding the cellular mechanisms of STDP at both excitatory and inhibitory synapses and of the associated changes in neuronal excitability and synaptic integration. Beyond the basic asymmetric window, recent studies have also revealed several layers of complexity in STDP, including its dependence on dendritic location, the nonlinear integration of synaptic modification induced by complex spike trains, and the modulation of STDP by inhibitory and neuromodulatory inputs. Finally, the functional consequences of STDP have been examined directly in an increasing number of neural circuits in vivo.},
  langid = {english},
  keywords = {Action Potentials,Animals,Brain,Dendrites,Humans,Learning,Neural Inhibition,Neuronal Plasticity,Neurons,Synaptic Transmission,Time Factors}
}

@article{chengExploringHierarchicalConvolutional2018a,
  title = {Exploring {{Hierarchical Convolutional Features}} for {{Hyperspectral Image Classification}}},
  author = {Cheng, Gong and Li, Zhenpeng and Han, Junwei and Yao, Xiwen and Guo, Lei},
  date = {2018-11},
  journaltitle = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {56},
  number = {11},
  pages = {6712--6722},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2018.2841823},
  abstract = {Hyperspectral image (HSI) classification is an active and important research task driven by many practical applications. To leverage deep learning models especially convolutional neural networks (CNNs) for HSI classification, this paper proposes a simple yet effective method to extract hierarchical deep spatial feature for HSI classification by exploring the power of off-the-shelf CNN models, without any additional retraining or fine-tuning on the target data set. To obtain better classification accuracy, we further propose a unified metric learning-based framework to alternately learn discriminative spectral-spatial features, which have better representation capability and train support vector machine (SVM) classifiers. To this end, we design a new objective function that explicitly embeds a metric learning regularization term into SVM training. The metric learning regularization term is used to learn a powerful spectral-spatial feature representation by fusing spectral feature and deep spatial feature, which has small intraclass scatter but big between class separation. By transforming HSI data into new spectral-spatial feature space through CNN and metric learning, we can pull the pixels from the same class closer, while pushing the different class pixels farther away. In the experiments, we comprehensively evaluate the proposed method on three commonly used HSI benchmark data sets. State-of-the-art results are achieved when compared with the existing HSI classification methods.},
  eventtitle = {{{IEEE Transactions}} on {{Geoscience}} and {{Remote Sensing}}},
  keywords = {Convolutional neural networks (CNNs),deep learning,Feature extraction,hyperspectral image (HSI) classification,Hyperspectral imaging,Machine learning,Measurement,metric learning,Semantics,spectral–spatial feature,Support vector machines,Training},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\L4SISI68\\Cheng et al. - 2018 - Exploring Hierarchical Convolutional Features for .pdf;C\:\\Users\\Fab\\Zotero\\storage\\QCXXXLX5\\8393448.html}
}

@online{chenInfoGANInterpretableRepresentation2016,
  title = {{{InfoGAN}}: {{Interpretable Representation Learning}} by {{Information Maximizing Generative Adversarial Nets}}},
  shorttitle = {{{InfoGAN}}},
  author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  date = {2016-06-11},
  eprint = {1606.03657},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1606.03657},
  url = {http://arxiv.org/abs/1606.03657},
  urldate = {2023-05-22},
  abstract = {This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\J6IGNF38\\Chen et al. - 2016 - InfoGAN Interpretable Representation Learning by .pdf;C\:\\Users\\Fab\\Zotero\\storage\\AJFB64I3\\1606.html}
}

@online{chungUnknownExamplesMachine2019,
  title = {Unknown {{Examples}} \& {{Machine Learning Model Generalization}}},
  author = {Chung, Yeounoh and Haas, Peter J. and Upfal, Eli and Kraska, Tim},
  date = {2019-10-11},
  eprint = {1808.08294},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1808.08294},
  url = {http://arxiv.org/abs/1808.08294},
  urldate = {2023-05-01},
  abstract = {Over the past decades, researchers and ML practitioners have come up with better and better ways to build, understand and improve the quality of ML models, but mostly under the key assumption that the training data is distributed identically to the testing data. In many real-world applications, however, some potential training examples are unknown to the modeler, due to sample selection bias or, more generally, covariate shift, i.e., a distribution shift between the training and deployment stage. The resulting discrepancy between training and testing distributions leads to poor generalization performance of the ML model and hence biased predictions. We provide novel algorithms that estimate the number and properties of these unknown training examples---unknown unknowns. This information can then be used to correct the training set, prior to seeing any test data. The key idea is to combine species-estimation techniques with data-driven methods for estimating the feature values for the unknown unknowns. Experiments on a variety of ML models and datasets indicate that taking the unknown examples into account can yield a more robust ML model that generalizes better.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\WNYCILW3\\Chung et al. - 2019 - Unknown Examples & Machine Learning Model Generali.pdf;C\:\\Users\\Fab\\Zotero\\storage\\W4V8DF6H\\1808.html}
}

@book{cinelliVariationalMethodsMachine2021,
  title = {Variational {{Methods}} for {{Machine Learning}} with {{Applications}} to {{Deep Networks}}},
  author = {Cinelli, Lucas Pinheiro and Marins, Matheus Araújo and Barros da Silva, Eduardo Antônio and Netto, Sérgio Lima},
  date = {2021},
  edition = {1st ed. 2021 edition},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-70679-1},
  url = {https://link.springer.com/10.1007/978-3-030-70679-1},
  urldate = {2023-04-13},
  abstract = {This book provides a straightforward look at the concepts, algorithms and advantages of Bayesian Deep Learning and Deep Generative Models. Starting from the model-based approach to Machine Learning, the authors motivate Probabilistic Graphical Models and show how Bayesian inference naturally lends itself to this framework. The authors present detailed explanations of the main modern algorithms on variational approximations for Bayesian inference in neural networks. Each algorithm of this selected set develops a distinct aspect of the theory. The book builds from the ground-up well-known deep generative models, such as Variational Autoencoder and subsequent theoretical developments. By also exposing the main issues of the algorithms together with different methods to mitigate such issues, the book supplies the necessary knowledge on generative models for the reader to handle a wide range of data types: sequential or not, continuous or not, labelled or not. The book is self-contained, promptly covering all necessary theory so that the reader does not have to search for additional information elsewhere.Offers a concise self-contained resource, covering the basic concepts to the algorithms for Bayesian Deep Learning;Presents Statistical Inference concepts, offering a set of elucidative examples, practical aspects, and pseudo-codes;Every chapter includes hands-on examples and exercises and a website features lecture slides, additional examples, and other support material.},
  isbn = {978-3-030-70678-4 978-3-030-70679-1},
  langid = {english},
  keywords = {Approximate inference,Artificial intelligence,Bayesian deep learning,Bayesian neural network,Computer vision,Deep neural networks,Expectation propagation,Machine theory,Variational autoencoder,Variational inference},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\KVTZZ3EA\\Cinelli et al. - 2021 - Variational Methods for Machine Learning with Appl.pdf}
}

@book{coverELEMENTSINFORMATIONTHEORY,
  title = {{{ELEMENTS OF INFORMATION THEORY}}},
  author = {Cover, Thomas M and Thomas, Joy A},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\EEF9ZL96\\Cover and Thomas - ELEMENTS OF INFORMATION THEORY.pdf}
}

@video{datasciencecoursesAliGhodsiLec2017,
  entrysubtype = {video},
  title = {Ali {{Ghodsi}}, {{Lec}} : {{Deep Learning}}, {{Variational Autoencoder}}, {{Oct}} 12 2017 [{{Lect}} 6.2]},
  shorttitle = {Ali {{Ghodsi}}, {{Lec}}},
  editor = {{Data Science Courses}},
  editortype = {director},
  date = {2017-10-15},
  url = {https://www.youtube.com/watch?v=uaaqyVS9-rM},
  urldate = {2023-04-07},
  abstract = {Variational Autoencoder}
}

@incollection{davidfosterVariationalAutoencoders2023,
  title = {3. {{Variational Autoencoders}}},
  booktitle = {Generative {{Deep Learning}}, 2nd {{Edition}}},
  author = {{David Foster}},
  date = {2023-05},
  edition = {2},
  url = {https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/},
  urldate = {2023-03-30},
  abstract = {Generative modeling is one of the hottest topics in AI. It's now possible to teach a machine to excel at human endeavors such as painting, writing, and composing music. With this practical book, machine learning engineers and data scientists will discover how to re-create some of the most impressive examples of generative deep learning models such as variational autoencoders (VAEs), generative adversarial networks (GANs), Transformers, normalizing flows, energy based models, and diffusion models. Author David Foster demonstrates the inner workings of each technique, starting with the basics of deep learning before advancing to some of the most cutting-edge algorithms in the field. Through tips and tricks, you'll understand how to make your models learn more efficiently and become more creative. Discover how VAEs can change facial expressions in photos Build practical GAN examples from scratch to generate images based on your own dataset Create autoregressive generative models, such as LSTMs for text generation and PixelCNN models for image generation Build music generation models, using Transformers and MuseGAN Explore the inner workings of state-of-the-art architectures such as StyleGANGPT-3, and DDIM Dive into the the detail of multimodal models such as DALL.E 2 and Imagen for text-to-image generation Understand how generative world models can help agents accomplish tasks within a reinforcement learning setting Understand how the future of generative modeling might evolve, including how businesses will need to adapt to take advantage of the new technologies},
  isbn = {978-1-09-813418-1},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\WIL9MQ4N\\9781098134174.html}
}

@online{dehaanContrastivePredictiveCoding2021,
  title = {Contrastive {{Predictive Coding}} for {{Anomaly Detection}}},
  author = {family=Haan, given=Puck, prefix=de, useprefix=true and Löwe, Sindy},
  date = {2021-07-16},
  eprint = {2107.07820},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2107.07820},
  url = {http://arxiv.org/abs/2107.07820},
  urldate = {2023-04-06},
  abstract = {Reliable detection of anomalies is crucial when deploying machine learning models in practice, but remains challenging due to the lack of labeled data. To tackle this challenge, contrastive learning approaches are becoming increasingly popular, given the impressive results they have achieved in self-supervised representation learning settings. However, while most existing contrastive anomaly detection and segmentation approaches have been applied to images, none of them can use the contrastive losses directly for both anomaly detection and segmentation. In this paper, we close this gap by making use of the Contrastive Predictive Coding model (arXiv:1807.03748). We show that its patch-wise contrastive loss can directly be interpreted as an anomaly score, and how this allows for the creation of anomaly segmentation masks. The resulting model achieves promising results for both anomaly detection and segmentation on the challenging MVTec-AD dataset.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\32XAAULP\\de Haan and Löwe - 2021 - Contrastive Predictive Coding for Anomaly Detectio.pdf;C\:\\Users\\Fab\\Zotero\\storage\\HTAD9LUH\\2107.html}
}

@inproceedings{deldariTimeSeriesChange2021,
  title = {Time {{Series Change Point Detection}} with {{Self-Supervised Contrastive Predictive Coding}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Deldari, Shohreh and Smith, Daniel V. and Xue, Hao and Salim, Flora D.},
  date = {2021-06-03},
  series = {{{WWW}} '21},
  pages = {3124--3135},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3442381.3449903},
  url = {https://dl.acm.org/doi/10.1145/3442381.3449903},
  urldate = {2023-04-06},
  abstract = {Change Point Detection (CPD) methods identify the times associated with changes in the trends and properties of time series data in order to describe the underlying behaviour of the system. For instance, detecting the changes and anomalies associated with web service usage, application usage or human behaviour can provide valuable insights for downstream modelling tasks. We propose a novel approach for self-supervised Time Series Change Point detection method based on Contrastive Predictive coding (TS − CP2). TS − CP2 is the first approach to employ a contrastive learning strategy for CPD by learning an embedded representation that separates pairs of embeddings of time adjacent intervals from pairs of interval embeddings separated across time. Through extensive experiments on three diverse, widely used time series datasets, we demonstrate that our method outperforms five state-of-the-art CPD methods, which include unsupervised and semi-supervised approaches. TS − CP2 is shown to improve the performance of methods that use either handcrafted statistical or temporal features by 79.4\% and deep learning-based methods by 17.0\% with respect to the F1-score averaged across the three datasets.},
  isbn = {978-1-4503-8312-7},
  keywords = {Anomaly detection,Contrastive learning,Time series change point detection,Unsupervised learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\7K5W3KIP\\Deldari et al. - 2021 - Time Series Change Point Detection with Self-Super.pdf}
}

@online{doerschTutorialVariationalAutoencoders2021,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  date = {2021-01-03},
  eprint = {1606.05908},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1606.05908},
  url = {http://arxiv.org/abs/1606.05908},
  urldate = {2023-04-07},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GRM99QC6\\Doersch - 2021 - Tutorial on Variational Autoencoders.pdf;C\:\\Users\\Fab\\Zotero\\storage\\484AFYZ3\\1606.html}
}

@online{fortuinSOMVAEInterpretableDiscrete2019,
  title = {{{SOM-VAE}}: {{Interpretable Discrete Representation Learning}} on {{Time Series}}},
  shorttitle = {{{SOM-VAE}}},
  author = {Fortuin, Vincent and Hüser, Matthias and Locatello, Francesco and Strathmann, Heiko and Rätsch, Gunnar},
  date = {2019-01-04},
  eprint = {1806.02199},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1806.02199},
  url = {http://arxiv.org/abs/1806.02199},
  urldate = {2023-05-26},
  abstract = {High-dimensional time series are common in many domains. Since human cognition is not optimized to work well in high-dimensional spaces, these areas could benefit from interpretable low-dimensional representations. However, most representation learning algorithms for time series data are difficult to interpret. This is due to non-intuitive mappings from data features to salient properties of the representation and non-smoothness over time. To address this problem, we propose a new representation learning framework building on ideas from interpretable discrete dimensionality reduction and deep generative modeling. This framework allows us to learn discrete representations of time series, which give rise to smooth and interpretable embeddings with superior clustering performance. We introduce a new way to overcome the non-differentiability in discrete representation learning and present a gradient-based version of the traditional self-organizing map algorithm that is more performant than the original. Furthermore, to allow for a probabilistic interpretation of our method, we integrate a Markov model in the representation space. This model uncovers the temporal transition structure, improves clustering performance even further and provides additional explanatory insights as well as a natural representation of uncertainty. We evaluate our model in terms of clustering performance and interpretability on static (Fashion-)MNIST data, a time series of linearly interpolated (Fashion-)MNIST images, a chaotic Lorenz attractor system with two macro states, as well as on a challenging real world medical time series application on the eICU data set. Our learned representations compare favorably with competitor methods and facilitate downstream tasks on the real world data.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GXT72DRW\\Fortuin et al. - 2019 - SOM-VAE Interpretable Discrete Representation Lea.pdf;C\:\\Users\\Fab\\Zotero\\storage\\KR46FTA6\\1806.html}
}

@article{gamperSoundSampleDetection2013,
  title = {Sound {{Sample Detection}} and {{Numerosity Estimation Using Auditory Display}}},
  author = {Gamper, Hannes and Dicke, Christina and Billinghurst, Mark and Puolamäki, Kai},
  date = {2013-02-01},
  journaltitle = {ACM Transactions on Applied Perception (TAP)},
  shortjournal = {ACM Transactions on Applied Perception (TAP)},
  volume = {10},
  doi = {10.1145/2422105.2422109},
  abstract = {This article investigates the effect of various design parameters of auditory information display on user performance in two basic information retrieval tasks. We conducted a user test with 22 participants in which sets of sound samples were presented. In the first task, the test participants were asked to detect a given sample among a set of samples. In the second task, the test participants were asked to estimate the relative number of instances of a given sample in two sets of samples. We found that the stimulus onset asynchrony (SOA) of the sound samples had a significant effect on user performance in both tasks. For the sample detection task, the average error rate was about 10\% with an SOA of 100 ms. For the numerosity estimation task, an SOA of at least 200 ms was necessary to yield average error rates lower than 30\%. Other parameters, including the samples' sound type (synthesized speech or earcons) and spatial quality (multichannel loudspeaker or diotic headphone playback), had no substantial effect on user performance. These results suggest that diotic, or indeed monophonic, playback with appropriately chosen SOA may be sufficient in practical applications for users to perform the given information retrieval tasks, if information about the sample location is not relevant. If location information was provided through spatial playback of the samples, test subjects were able to simultaneously detect and localize a sample with reasonable accuracy.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\3CS3IIWR\\Gamper et al. - 2013 - Sound Sample Detection and Numerosity Estimation U.pdf}
}

@article{glorfeldMethodologySimplificationInterpretation1996,
  title = {A Methodology for Simplification and Interpretation of Backpropagation-Based Neural Network Models},
  author = {Glorfeld, L. W.},
  date = {1996},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Syst. Appl.},
  volume = {10},
  number = {1},
  pages = {37--54},
  publisher = {{Pergamon-Elsevier Science Ltd}},
  location = {{Oxford}},
  issn = {0957-4174},
  doi = {10.1016/0957-4174(95)00032-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0957417495000321},
  urldate = {2023-05-21},
  abstract = {A new methodology for building inductive expert systems known as neural networks has emerged as one of the most promising applications of artificial intelligence in the 1990s. The primary advantages of a neural network approach for modeling expert decision processes are: (I) the ability of the network to learn from examples of experts' decisions that avoids the costly, time consuming, and error prone task of trying to directly extract knowledge of a problem domain from an expert and (2) the ability of the network to handle noisy, incomplete, and distorted data that are typically found in decision making under conditions of uncertainty. Unfortunately, a major limitation of neural network-based models has been the opacity of the inference process. Unlike conventional expert system decision support tools, decision makers are generally unable to understand the basis of neural network decisions. This problem often makes such systems undesirable for decision support applications. A new methodology is presented that allows the development of highly simplified backpropagation neural network models. This methodology simplifies network models by using a backward selection process to eliminate input variables that are not contributing to the networks ability to produce accurate predictions. Elimination of unnecessary input variables directly reduces the number of network parameters that must be estimated and consequently the complexity of the network structure. A primary benefit of this development methodology is that it is based on a variable importance measure that addresses the problem of producing an interpretation of a neural network's functioning. Decision makers may easily understand the resulting networks in terms of the proportional contribution each input variable is making in the production of accurate predictions. Furthermore, in actual application the accuracy of these simplified models should be comparable to or better than the more complex models developed with the standard approach. This new methodology is demonstrated by two classification problems based on sets of actual data.},
  langid = {english},
  keywords = {predictions},
  annotation = {WOS:A1996TR49600004}
}

@article{gneccoWeightdecayTechniqueLearning2009,
  title = {The Weight-Decay Technique in Learning from Data: {{An}} Optimization Point of View},
  shorttitle = {The Weight-Decay Technique in Learning from Data},
  author = {Gnecco, Giorgio and Sanguineti, Marcello},
  date = {2009-02-01},
  journaltitle = {Computational Management Science},
  shortjournal = {Computational Management Science},
  volume = {6},
  pages = {53--79},
  doi = {10.1007/s10287-008-0072-5},
  abstract = {The technique known as “weight decay” in the literature about learning from data is investigated using tools from regularization theory. Weight-decay regularization is compared with Tikhonov’s regularization of the learning problem and with a mixed regularized learning technique. The accuracies of suboptimal solutions to weight-decay learning are estimated for connectionistic models with a-priori fixed numbers of computational units.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\37SWEYS5\\Gnecco and Sanguineti - 2009 - The weight-decay technique in learning from data .pdf}
}

@article{grossuttiDeepLearningInfrared2022,
  title = {Deep {{Learning}} and {{Infrared Spectroscopy}}: {{Representation Learning}} with a {{Beta-Variational Autoencoder}}},
  shorttitle = {Deep {{Learning}} and {{Infrared Spectroscopy}}},
  author = {Grossutti, Michael and D’Amico, Joseph and Quintal, Jonathan and MacFarlane, Hugh and Quirk, Amanda and Dutcher, John R.},
  date = {2022-06-30},
  journaltitle = {The Journal of Physical Chemistry Letters},
  shortjournal = {J. Phys. Chem. Lett.},
  volume = {13},
  number = {25},
  pages = {5787--5793},
  publisher = {{American Chemical Society}},
  doi = {10.1021/acs.jpclett.2c01328},
  url = {https://doi.org/10.1021/acs.jpclett.2c01328},
  urldate = {2023-04-12},
  abstract = {Infrared (IR) spectra contain detailed and extensive information about the chemical composition and bonding environment in a sample. However, this information is difficult to extract from complex heterogeneous systems because of overlapping absorptions due to different generative factors. We implement a deep learning approach to study the complex spectroscopic changes that occur in cross-linked polyethylene (PEX-a) pipe by training a Beta-variational autoencoder (Beta-VAE) on a database of PEX-a pipe spectra. We show that the Beta-VAE outperforms principal component analysis (PCA) and learns interpretable and independent representations of the generative factors of variance in the spectra. We apply the Beta-VAE encoder to a hyperspectrum of a crack in the wall of a pipe to evaluate the spatial distribution of these learned representations. This study shows how deep learning architectures like Beta-VAE can enhance the analysis of spectroscopic data of complex heterogeneous systems.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\J7NTSUB7\\Grossutti et al. - 2022 - Deep Learning and Infrared Spectroscopy Represent.pdf;C\:\\Users\\Fab\\Zotero\\storage\\FS248ZH7\\acs.jpclett.html}
}

@article{guoDeepMultimodalRepresentation2019,
  title = {Deep {{Multimodal Representation Learning}}: {{A Survey}}},
  shorttitle = {Deep {{Multimodal Representation Learning}}},
  author = {Guo, Wenzhong and Wang, Jianwen and Wang, Shiping},
  date = {2019},
  journaltitle = {IEEE Access},
  volume = {7},
  pages = {63373--63394},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2916887},
  abstract = {Multimodal representation learning, which aims to narrow the heterogeneity gap among different modalities, plays an indispensable role in the utilization of ubiquitous multimodal data. Due to the powerful representation ability with multiple levels of abstraction, deep learning-based multimodal representation learning has attracted much attention in recent years. In this paper, we provided a comprehensive survey on deep multimodal representation learning which has never been concentrated entirely. To facilitate the discussion on how the heterogeneity gap is narrowed, according to the underlying structures in which different modalities are integrated, we category deep multimodal representation learning methods into three frameworks: joint representation, coordinated representation, and encoder-decoder. Additionally, we review some typical models in this area ranging from conventional models to newly developed technologies. This paper highlights on the key issues of newly developed technologies, such as encoder-decoder model, generative adversarial networks, and attention mechanism in a multimodal representation learning perspective, which, to the best of our knowledge, have never been reviewed previously, even though they have become the major focuses of much contemporary research. For each framework or model, we discuss its basic structure, learning objective, application scenes, key issues, advantages, and disadvantages, such that both novel and experienced researchers can benefit from this survey. Finally, we suggest some important directions for future work.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Data mining,Decoding,Deep learning,deep multimodal fusion,Feature extraction,multimodal adversarial learning,multimodal deep learning,Multimodal representation learning,multimodal translation,Semantics,Speech recognition,Task analysis},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\T86F6KVF\\Guo et al. - 2019 - Deep Multimodal Representation Learning A Survey.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RGAD43VL\\8715409.html}
}

@article{guoVariationalAutoencoderOptimizing2020,
  title = {Variational {{Autoencoder With Optimizing Gaussian Mixture Model Priors}}},
  author = {Guo, Chunsheng and Zhou, Jialuo and Chen, Huahua and Ying, Na and Zhang, Jianwu and Zhou, Di},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {43992--44005},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2977671},
  abstract = {The latent variable prior of the variational autoencoder (VAE) often utilizes a standard Gaussian distribution because of the convenience in calculation, but has an underfitting problem. This paper proposes a variational autoencoder with optimizing Gaussian mixture model priors. This method utilizes a Gaussian mixture model to construct prior distribution, and utilizes the Kullback-Leibler (KL) distance between posterior and prior distribution to implement an iterative optimization of the prior distribution based on the data. The greedy algorithm is used to solve the KL distance for defining the approximate variational lower bound solution of the loss function, and for realizing the VAE with optimizing Gaussian mixture model priors. Compared with the standard VAE method, the proposed method obtains state-of-the-art results on MNIST, Omniglot, and Frey Face datasets, which shows that the VAE with optimizing Gaussian mixture model priors can learn a better model.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Aggregates,Gaussian distribution,Gaussian mixture model,Kullback-Leibler distance,Neural networks,Standards,Training,Variational autoencoder},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MPXMN3X9\\Guo et al. - 2020 - Variational Autoencoder With Optimizing Gaussian M.pdf;C\:\\Users\\Fab\\Zotero\\storage\\97EH2E8A\\9020116.html}
}

@inproceedings{heatonEmpiricalAnalysisFeature2016,
  title = {An Empirical Analysis of Feature Engineering for Predictive Modeling},
  booktitle = {{{SoutheastCon}} 2016},
  author = {Heaton, Jeff},
  date = {2016-03},
  pages = {1--6},
  issn = {1558-058X},
  doi = {10.1109/SECON.2016.7506650},
  abstract = {Machine learning models, such as neural networks, decision trees, random forests and gradient boosting machines accept a feature vector and provide a prediction. These models learn in a supervised fashion where a set of feature vectors with expected output is provided. It is very common practice to engineer new features from the provided feature set. Such engineered features will either augment, or replace portions of the existing feature vector. These engineered features are essentially calculated fields, based on the values of the other features. Engineering such features is primarily a manual, time-consuming task. Additionally, each type of model will respond differently to different types of engineered features. This paper reports on empirical research to demonstrate what types of engineered features are best suited to which machine learning model type. This is accomplished by generating several datasets that are designed to benefit from a particular type of engineered feature. The experiment demonstrates to what degree the machine learning model is capable of synthesizing the needed feature on its own. If a model is capable of synthesizing an engineered feature, it is not necessary to provide that feature. The research demonstrated that the studied models do indeed perform differently with various types of engineered features.},
  eventtitle = {{{SoutheastCon}} 2016},
  keywords = {Analytical models,Biological neural networks,Linear regression,Mathematical model,Neurons,Support vector machines},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\5MFP6G4S\\Heaton - 2016 - An empirical analysis of feature engineering for p.pdf;C\:\\Users\\Fab\\Zotero\\storage\\XYCK87UF\\7506650.html}
}

@inproceedings{henaffDataEfficientImageRecognition2020,
  title = {Data-{{Efficient Image Recognition}} with {{Contrastive Predictive Coding}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Henaff, Olivier},
  date = {2020-11-21},
  pages = {4182--4192},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/henaff20a.html},
  urldate = {2023-04-06},
  abstract = {Human observers can learn to recognize new categories of images from a handful of examples, yet doing so with artificial ones remains an open challenge. We hypothesize that data-efficient recognition is enabled by representations which make the variability in natural signals more predictable. We therefore revisit and improve Contrastive Predictive Coding, an unsupervised objective for learning such representations. This new implementation produces features which support state-of-the-art linear classification accuracy on the ImageNet dataset. When used as input for non-linear classification with deep neural networks, this representation allows us to use 2-5x less labels than classifiers trained directly on image pixels. Finally, this unsupervised representation substantially improves transfer learning to object detection on the PASCAL VOC dataset, surpassing fully supervised pre-trained ImageNet classifiers.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\EIZ3GV98\\Henaff - 2020 - Data-Efficient Image Recognition with Contrastive .pdf;C\:\\Users\\Fab\\Zotero\\storage\\RAJYDHYM\\Henaff - 2020 - Data-Efficient Image Recognition with Contrastive .pdf}
}

@inproceedings{higginsBetaVAELearningBasic2022,
  title = {Beta-{{VAE}}: {{Learning Basic Visual Concepts}} with a {{Constrained Variational Framework}}},
  shorttitle = {Beta-{{VAE}}},
  author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  date = {2022-07-21},
  url = {https://openreview.net/forum?id=Sy2fzU9gl},
  urldate = {2023-04-22},
  abstract = {Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter beta that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that beta-VAE with appropriately tuned beta {$>$} 1 qualitatively outperforms VAE (beta = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a variety of datasets (celebA, faces and chairs). Furthermore, we devise a protocol to quantitatively compare the degree of disentanglement learnt by different models, and show that our approach also significantly outperforms all baselines quantitatively. Unlike InfoGAN, beta-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter, which can be directly optimised through a hyper parameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\KVW7LUBW\\Higgins et al. - 2022 - beta-VAE Learning Basic Visual Concepts with a Co.pdf}
}

@online{hjelmLearningDeepRepresentations2019,
  title = {Learning Deep Representations by Mutual Information Estimation and Maximization},
  author = {Hjelm, R. Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
  date = {2019-02-22},
  eprint = {1808.06670},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1808.06670},
  url = {http://arxiv.org/abs/1808.06670},
  urldate = {2023-05-23},
  abstract = {In this work, we perform unsupervised learning of representations by maximizing mutual information between an input and the output of a deep neural network encoder. Importantly, we show that structure matters: incorporating knowledge about locality of the input to the objective can greatly influence a representation's suitability for downstream tasks. We further control characteristics of the representation by matching to a prior distribution adversarially. Our method, which we call Deep InfoMax (DIM), outperforms a number of popular unsupervised learning methods and competes with fully-supervised learning on several classification tasks. DIM opens new avenues for unsupervised learning of representations and is an important step towards flexible formulations of representation-learning objectives for specific end-goals.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\5TN6QCA2\\Hjelm et al. - 2019 - Learning deep representations by mutual informatio.pdf;C\:\\Users\\Fab\\Zotero\\storage\\C275LSAR\\1808.html}
}

@article{hochreiterVanishingGradientProblem1998,
  title = {The {{Vanishing Gradient Problem During Learning Recurrent Neural Nets}}  and {{Problem Solutions}}},
  author = {Hochreiter, Sepp},
  date = {1998-04},
  journaltitle = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  shortjournal = {Int. J. Unc. Fuzz. Knowl. Based Syst.},
  volume = {06},
  number = {02},
  pages = {107--116},
  publisher = {{World Scientific Publishing Co.}},
  issn = {0218-4885},
  doi = {10.1142/S0218488598000094},
  url = {https://www.worldscientific.com/doi/abs/10.1142/s0218488598000094},
  urldate = {2023-05-25},
  abstract = {Recurrent nets are in principle capable to store past inputs to produce the currently desired output. Because of this property recurrent nets are used in time series prediction and process control. Practical applications involve temporal dependencies spanning many time steps, e.g. between relevant inputs and desired outputs. In this case, however, gradient based learning methods take too much time. The extremely increased learning time arises because the error vanishes as it gets propagated back. In this article the de-caying error flow is theoretically analyzed. Then methods trying to overcome vanishing gradients are briefly discussed. Finally, experiments comparing conventional algorithms and alternative methods are presented. With advanced methods long time lag problems can be solved in reasonable time.},
  keywords = {long short-term memory,long-term dependencies,Recurrent neural nets,vanishing gradient}
}

@article{hoRealWorldWeightCrossEntropyLoss2020,
  title = {The {{Real-World-Weight Cross-Entropy Loss Function}}: {{Modeling}} the {{Costs}} of {{Mislabeling}}},
  shorttitle = {The {{Real-World-Weight Cross-Entropy Loss Function}}},
  author = {Ho, Yaoshiang and Wookey, Samuel},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {4806--4813},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2962617},
  abstract = {In this paper, we propose a new metric to measure goodness-of-fit for classifiers: the Real World Cost function. This metric factors in information about a real world problem, such as financial impact, that other measures like accuracy or F1 do not. This metric is also more directly interpretable for users. To optimize for this metric, we introduce the Real-World-Weight Cross-Entropy loss function, in both binary classification and single-label multiclass classification variants. Both variants allow direct input of real world costs as weights. For single-label, multiclass classification, our loss function also allows direct penalization of probabilistic false positives, weighted by label, during the training of a machine learning model. We compare the design of our loss function to the binary cross-entropy and categorical cross-entropy functions, as well as their weighted variants, to discuss the potential for improvement in handling a variety of known shortcomings of machine learning, ranging from imbalanced classes to medical diagnostic error to reinforcement of social bias. We create scenarios that emulate those issues using the MNIST data set and demonstrate empirical results of our new loss function. Finally, we discuss our intuition about why this approach works and sketch a proof based on Maximum Likelihood Estimation.},
  eventtitle = {{{IEEE Access}}},
  keywords = {class imbalance,cross-entropy,ethnic stereotypes,Machine learning,maximum likelihood estimation,Maximum likelihood estimation,Measurement,Neural networks,oversampling,Probabilistic logic,social bias,softmax,Standards,Training,undersampling},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\VFNWI6LZ\\Ho and Wookey - 2020 - The Real-World-Weight Cross-Entropy Loss Function.pdf;C\:\\Users\\Fab\\Zotero\\storage\\FEYUFSWC\\8943952.html}
}

@article{huHandlingVanishingGradient2021,
  title = {Handling {{Vanishing Gradient Problem Using Artificial Derivative}}},
  author = {Hu, Zheng and Zhang, Jiaojiao and Ge, Yun},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {22371--22377},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3054915},
  abstract = {Sigmoid function and ReLU are commonly used activation functions in neural networks (NN). However, sigmoid function is vulnerable to the vanishing gradient problem, while ReLU has a special vanishing gradient problem that is called dying ReLU problem. Though many studies provided methods to alleviate this problem, there has not been an efficient feasible solution. Hence, we proposed a method replacing the original derivative function with an artificial derivative in a pertinent way. Our method optimized gradients of activation functions without varying activation functions nor introducing extra layers. Our investigations demonstrated that the method can effectively alleviate the vanishing gradient problem for both ReLU and sigmoid function with few computational cost.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Activation function,artificial derivative,Artificial neural networks,Computational efficiency,Logistics,ReLU,sigmoid function,Task analysis,Testing,Training,vanishing gradient},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\LRL4A6MM\\Hu et al. - 2021 - Handling Vanishing Gradient Problem Using Artifici.pdf;C\:\\Users\\Fab\\Zotero\\storage\\VA3XQCNE\\9336631.html}
}

@inproceedings{indykApproximateNearestNeighbors1998,
  title = {Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality},
  shorttitle = {Approximate Nearest Neighbors},
  booktitle = {Proceedings of the Thirtieth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Indyk, Piotr and Motwani, Rajeev},
  date = {1998-05-23},
  series = {{{STOC}} '98},
  pages = {604--613},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/276698.276876},
  url = {https://dl.acm.org/doi/10.1145/276698.276876},
  urldate = {2023-05-01},
  isbn = {978-0-89791-962-3},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\LL8WFGB9\\Indyk and Motwani - 1998 - Approximate nearest neighbors towards removing th.pdf}
}

@online{ioffeBatchNormalizationAccelerating2015,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  date = {2015-03-02},
  eprint = {1502.03167},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1502.03167},
  url = {http://arxiv.org/abs/1502.03167},
  urldate = {2023-04-19},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\AXZ49JIK\\Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf;C\:\\Users\\Fab\\Zotero\\storage\\XEH27CBD\\1502.html}
}

@article{jainArtificialNeuralNetworks1996,
  title = {Artificial Neural Networks: A Tutorial},
  shorttitle = {Artificial Neural Networks},
  author = {Jain, A.K. and Mao, Jianchang and Mohiuddin, K.M.},
  date = {1996-03},
  journaltitle = {Computer},
  volume = {29},
  number = {3},
  pages = {31--44},
  issn = {1558-0814},
  doi = {10.1109/2.485891},
  abstract = {Artificial neural nets (ANNs) are massively parallel systems with large numbers of interconnected simple processors. The article discusses the motivations behind the development of ANNs and describes the basic biological neuron and the artificial computational model. It outlines network architectures and learning processes, and presents some of the most commonly used ANN models. It concludes with character recognition, a successful ANN application.},
  eventtitle = {Computer},
  keywords = {Artificial neural networks,Biological neural networks,Biological system modeling,Biology computing,Computer architecture,Concurrent computing,Humans,Integrated circuit interconnections,Parallel processing,Tutorial},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\THK29UCH\\485891.html}
}

@article{johanssonGeneralizationBoundsRepresentation2022,
  title = {Generalization Bounds and Representation Learning for Estimation of Potential Outcomes and Causal Effects},
  author = {Johansson, Fredrik D. and Shalit, Uri and Kallus, Nathan and Sontag, David},
  date = {2022-01-01},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {23},
  number = {1},
  pages = {166:7489--166:7538},
  issn = {1532-4435},
  abstract = {Practitioners in diverse fields such as healthcare, economics and education are eager to apply machine learning to improve decision making. The cost and impracticality of performing experiments and a recent monumental increase in electronic record keeping has brought attention to the problem of evaluating decisions based on non-experimental observational data. This is the setting of this work. In particular, we study estimation of individual-level potential outcomes and causal effects--such as a single patient's response to alternative medication--from recorded contexts, decisions and outcomes. We give generalization bounds on the error in estimated outcomes based on distributional distance measures between re-weighted samples of groups receiving different treatments. We provide conditions under which our bounds are tight and show how they relate to results for unsupervised domain adaptation. Led by our theoretical results, we devise algorithms which learn representations and weighting functions that minimize our bounds by regularizing the representation's induced treatment group distance, and encourage sharing of information between treatment groups. Finally, an experimental evaluation on real and synthetic data shows the value of our proposed representation architecture and regularization scheme.},
  keywords = {causal effects,domain adaptation,generalization theory,overlap},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\8F566L8M\\Johansson et al. - 2022 - Generalization bounds and representation learning .pdf}
}

@inproceedings{kaadoudExplainableAINarrative2021,
  title = {Explainable {{AI}}: A Narrative Review at the Crossroad of {{Knowledge Discovery}}, {{Knowledge Representation}} and {{Representation Learning}}},
  shorttitle = {Explainable {{AI}}},
  author = {Kaadoud, Ikram Chraibi and Fahed, Lina and Lenca, Philippe},
  date = {2021-08-19},
  volume = {2995},
  pages = {28},
  publisher = {{ceur-ws.org}},
  url = {https://hal.science/hal-03343687},
  urldate = {2023-05-22},
  abstract = {EXplainable Artificial Intelligence (XAI) has recently become a very active domain, mainly due to the extensive development of black-box models such as neural networks. Recent XAI objectives have been defined in the state-of-the-art, for which specific approaches have been proposed. Implicit links can be found between XAI and other domains, especially related to knowledge and neural networks. We here aim to highlight these implicit links. We present a narrative review of research works in two domains: (i) Knowledge domain with focus on Knowledge Discovery and Representation, and (ii) Representation Learning. We discuss the similarity and joining points between these domains and XAI. We conclude that, in order to make black-boxes more transparent, XAI approaches should be more inspired and take advantage of past and recent works in Knowledge and Representation Learning domains. Through this paper, we offer an entry point to the domain of XAI for both multidisciplinary researchers and specialists in AI, as well for AI knowledgeable users.},
  eventtitle = {{{MRC}} 2021: {{Twelfth International Workshop Modelling}} and {{Reasoning}} in {{Context}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\DQIBFF43\\Kaadoud et al. - 2021 - Explainable AI a narrative review at the crossroa.pdf}
}

@online{karagiannakosHowGenerateImages2018,
  title = {How to {{Generate Images}} Using {{Autoencoders}}},
  author = {Karagiannakos, Sergios},
  date = {2018-09-09},
  url = {https://theaisummer.com/Autoencoder/},
  urldate = {2023-04-07},
  abstract = {Learn what autoencoders are and build one to generate new images},
  langid = {english},
  organization = {{AI Summer}}
}

@inproceedings{karamanolakisItemRecommendationVariational2018,
  title = {Item {{Recommendation}} with {{Variational Autoencoders}} and {{Heterogeneous Priors}}},
  booktitle = {Proceedings of the 3rd {{Workshop}} on {{Deep Learning}} for {{Recommender Systems}}},
  author = {Karamanolakis, Giannis and Cherian, Kevin Raji and Narayan, Ananth Ravi and Yuan, Jie and Tang, Da and Jebara, Tony},
  date = {2018-10-06},
  series = {{{DLRS}} 2018},
  pages = {10--14},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3270323.3270329},
  url = {https://dl.acm.org/doi/10.1145/3270323.3270329},
  urldate = {2023-05-22},
  abstract = {In recent years, Variational Autoencoders (VAEs) have been shown to be highly effective in both standard collaborative filtering applications and extensions such as incorporation of implicit feedback. We extend VAEs to collaborative filtering with side information, for instance when ratings are combined with explicit text feedback from the user. Instead of using a user-agnostic standard Gaussian prior, we incorporate user-dependent priors in the latent VAE space to encode users' preferences as functions of the review text. Taking into account both the rating and the text information to represent users in this multimodal latent space is promising to improve recommendation quality. Our proposed model is shown to outperform the existing VAE models for collaborative filtering (up to 29.41\% relative improvement in ranking metric) along with other baselines that incorporate both user ratings and text for item recommendation.},
  isbn = {978-1-4503-6617-5},
  keywords = {Deep Learning,Item Recommendation,Probabilistic Modeling,Text Mining,Variational Autoencoders},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\WZCUUWN7\\Karamanolakis et al. - 2018 - Item Recommendation with Variational Autoencoders .pdf}
}

@online{kingmaAutoEncodingVariationalBayes2022,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2022-12-10},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1312.6114},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2023-04-04},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\58JTVZV4\\Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf;C\:\\Users\\Fab\\Zotero\\storage\\C5TQ888L\\1312.html}
}

@online{kingmaImprovingVariationalInference2017,
  title = {Improving {{Variational Inference}} with {{Inverse Autoregressive Flow}}},
  author = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  date = {2017-01-30},
  eprint = {1606.04934},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1606.04934},
  urldate = {2023-05-22},
  abstract = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow (IAF), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that IAF significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with IAF, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\344PDSGW\\Kingma et al. - 2017 - Improving Variational Inference with Inverse Autor.pdf;C\:\\Users\\Fab\\Zotero\\storage\\SVG5N4FD\\1606.html}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {4},
  eprint = {1906.02691},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {http://arxiv.org/abs/1906.02691},
  urldate = {2023-03-30},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\RVFG7F9F\\Kingma and Welling - 2019 - An Introduction to Variational Autoencoders.pdf;C\:\\Users\\Fab\\Zotero\\storage\\AQ83KMRQ\\1906.html}
}

@article{kroghWhatAreArtificial2008,
  title = {What Are Artificial Neural Networks?},
  author = {Krogh, Anders},
  date = {2008-02},
  journaltitle = {Nature Biotechnology},
  shortjournal = {Nat Biotechnol},
  volume = {26},
  number = {2},
  pages = {195--197},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt1386},
  url = {https://www.nature.com/articles/nbt1386},
  urldate = {2023-05-01},
  abstract = {Artificial neural networks have been applied to problems ranging from speech recognition to prediction of protein secondary structure, classification of cancers and gene prediction. How do they work and what might they be good for?},
  issue = {2},
  langid = {english},
  keywords = {Agriculture,Bioinformatics,Biomedical Engineering/Biotechnology,Biomedicine,Biotechnology,general,Life Sciences},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GHSMHC6Z\\Krogh - 2008 - What are artificial neural networks.pdf}
}

@online{kukackaRegularizationDeepLearning2017,
  title = {Regularization for {{Deep Learning}}: {{A Taxonomy}}},
  shorttitle = {Regularization for {{Deep Learning}}},
  author = {Kukačka, Jan and Golkov, Vladimir and Cremers, Daniel},
  date = {2017-10-29},
  eprint = {1710.10686},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1710.10686},
  url = {http://arxiv.org/abs/1710.10686},
  urldate = {2023-05-26},
  abstract = {Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.},
  pubstate = {preprint},
  keywords = {62M45,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,I.2.6,I.5,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\843M2H9C\\Kukačka et al. - 2017 - Regularization for Deep Learning A Taxonomy.pdf;C\:\\Users\\Fab\\Zotero\\storage\\CXTLG6R4\\1710.html}
}

@online{laiContrastivePredictiveCoding2019,
  title = {Contrastive {{Predictive Coding Based Feature}} for {{Automatic Speaker Verification}}},
  author = {Lai, Cheng-I.},
  date = {2019-04-01},
  eprint = {1904.01575},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.1904.01575},
  url = {http://arxiv.org/abs/1904.01575},
  urldate = {2023-04-06},
  abstract = {This thesis describes our ongoing work on Contrastive Predictive Coding (CPC) features for speaker verification. CPC is a recently proposed representation learning framework based on predictive coding and noise contrastive estimation. We focus on incorporating CPC features into the standard automatic speaker verification systems, and we present our methods, experiments, and analysis. This thesis also details necessary background knowledge in past and recent work on automatic speaker verification systems, conventional speech features, and the motivation and techniques behind CPC.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\XISIK4LT\\Lai - 2019 - Contrastive Predictive Coding Based Feature for Au.pdf;C\:\\Users\\Fab\\Zotero\\storage\\LXU26RFN\\1904.html}
}

@inproceedings{langDimensionalityReductionPrior1989,
  title = {Dimensionality {{Reduction}} and {{Prior Knowledge}} in {{E-Set Recognition}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lang, Kevin and Hinton, Geoffrey E},
  date = {1989},
  volume = {2},
  publisher = {{Morgan-Kaufmann}},
  url = {https://proceedings.neurips.cc/paper/1989/hash/289dff07669d7a23de0ef88d2f7129e7-Abstract.html},
  urldate = {2023-05-27},
  abstract = {It is  well known  that  when an  automatic  learning algorithm  is  applied  to a  fixed  corpus  of data,  the size of the corpus  places  an  upper bound  on  the  number  of degrees  of freedom  that  the  model  can  contain  if  it  is  to generalize  well.  Because  the  amount  of hardware  in  a  neural  network  typically  increases  with  the  dimensionality  of  its  inputs,  it  can be challenging to build a high-performance network for classifying  large input patterns.  In this paper, several techniques for addressing this  problem  are  discussed  in  the context of an  isolated  word  recognition  task.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\WF6AYUIK\\Lang and Hinton - 1989 - Dimensionality Reduction and Prior Knowledge in E-.pdf}
}

@online{latifDeepRepresentationLearning2021,
  title = {Deep {{Representation Learning}} in {{Speech Processing}}: {{Challenges}}, {{Recent Advances}}, and {{Future Trends}}},
  shorttitle = {Deep {{Representation Learning}} in {{Speech Processing}}},
  author = {Latif, Siddique and Rana, Rajib and Khalifa, Sara and Jurdak, Raja and Qadir, Junaid and Schuller, Björn W.},
  date = {2021-09-24},
  eprint = {2001.00378},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2001.00378},
  url = {http://arxiv.org/abs/2001.00378},
  urldate = {2023-05-23},
  abstract = {Research on speech processing has traditionally considered the task of designing hand-engineered acoustic features (feature engineering) as a separate distinct problem from the task of designing efficient machine learning (ML) models to make prediction and classification decisions. There are two main drawbacks to this approach: firstly, the feature engineering being manual is cumbersome and requires human knowledge; and secondly, the designed features might not be best for the objective at hand. This has motivated the adoption of a recent trend in speech community towards utilisation of representation learning techniques, which can learn an intermediate representation of the input signal automatically that better suits the task at hand and hence lead to improved performance. The significance of representation learning has increased with advances in deep learning (DL), where the representations are more useful and less dependent on human knowledge, making it very conducive for tasks like classification, prediction, etc. The main contribution of this paper is to present an up-to-date and comprehensive survey on different techniques of speech representation learning by bringing together the scattered research across three distinct research areas including Automatic Speech Recognition (ASR), Speaker Recognition (SR), and Speaker Emotion Recognition (SER). Recent reviews in speech have been conducted for ASR, SR, and SER, however, none of these has focused on the representation learning from speech -- a gap that our survey aims to bridge.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\VVD4298I\\Latif et al. - 2021 - Deep Representation Learning in Speech Processing.pdf;C\:\\Users\\Fab\\Zotero\\storage\\LLNAMCRA\\2001.html}
}

@article{le-khacContrastiveRepresentationLearning2020,
  title = {Contrastive {{Representation Learning}}: {{A Framework}} and {{Review}}},
  shorttitle = {Contrastive {{Representation Learning}}},
  author = {Le-Khac, Phuc H. and Healy, Graham and Smeaton, Alan F.},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {193907--193934},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3031549},
  abstract = {Contrastive Learning has recently received interest due to its success in self-supervised representation learning in the computer vision domain. However, the origins of Contrastive Learning date as far back as the 1990s and its development has spanned across many fields and domains including Metric Learning and natural language processing. In this paper, we provide a comprehensive literature review and we propose a general Contrastive Representation Learning framework that simplifies and unifies many different contrastive learning methods. We also provide a taxonomy for each of the components of contrastive learning in order to summarise it and distinguish it from other forms of machine learning. We then discuss the inductive biases which are present in any contrastive learning system and we analyse our framework under different views from various sub-fields of Machine Learning. Examples of how contrastive learning has been applied in computer vision, natural language processing, audio processing, and others, as well as in Reinforcement Learning are also presented. Finally, we discuss the challenges and some of the most promising future research directions ahead.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Computational modeling,Contrastive learning,Data models,deep learning,Feature extraction,Learning systems,machine learning,Machine learning,Natural language processing,representation learning,self-supervised learning,Task analysis,unsupervised learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GRTCEVRE\\Le-Khac et al. - 2020 - Contrastive Representation Learning A Framework a.pdf;C\:\\Users\\Fab\\Zotero\\storage\\WWSBG6JX\\stamp.html}
}

@incollection{lecunEfficientBackProp1998,
  title = {Efficient {{BackProp}}},
  booktitle = {Neural {{Networks}}: {{Tricks}} of the {{Trade}}},
  author = {LeCun, Yann and Bottou, Leon and Orr, Genevieve B. and Müller, Klaus -Robert},
  editor = {Orr, Genevieve B. and Müller, Klaus-Robert},
  date = {1998},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {9--50},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-49430-8},
  url = {https://doi.org/10.1007/3-540-49430-8},
  urldate = {2023-04-25},
  abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observedb y practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposedin serious technical publications. This paper gives some of those tricks, ando.ers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most “classical” second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
  isbn = {978-3-540-49430-0},
  langid = {english},
  keywords = {Conjugate Gradient,Handwritten Digit,Learning Rate,Neural Information Processing System,Newton Algorithm},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\UQZKDQAQ\\LeCun et al. - 1998 - Efficient BackProp.pdf}
}

@inproceedings{leeMetaGMVAEMixtureGaussian2021,
  title = {Meta-{{GMVAE}}: {{Mixture}} of {{Gaussian VAE}} for {{Unsupervised Meta-Learning}}},
  shorttitle = {Meta-{{GMVAE}}},
  author = {Lee, Dong Bok and Min, Dongchan and Lee, Seanie and Hwang, Sung Ju},
  date = {2021-01-12},
  url = {https://openreview.net/forum?id=wS0UFjsNYjn},
  urldate = {2023-05-22},
  abstract = {Unsupervised learning aims to learn meaningful representations from unlabeled data which can captures its intrinsic structure, that can be transferred to downstream tasks. Meta-learning, whose objective is to learn to generalize across tasks such that the learned model can rapidly adapt to a novel task, shares the spirit of unsupervised learning in that the both seek to learn more effective and efficient learning procedure than learning from scratch. The fundamental difference of the two is that the most meta-learning approaches are supervised, assuming full access to the labels. However, acquiring labeled dataset for meta-training not only is costly as it requires human efforts in labeling but also limits its applications to pre-defined task distributions. In this paper, we propose a principled unsupervised meta-learning model, namely Meta-GMVAE, based on Variational Autoencoder (VAE) and set-level variational inference. Moreover, we introduce a mixture of Gaussian (GMM) prior, assuming that each modality represents each class-concept in a randomly sampled episode, which we optimize with Expectation-Maximization (EM). Then, the learned model can be used for downstream few-shot classification tasks, where we obtain task-specific parameters by performing semi-supervised EM on the latent representations of the support and query set, and predict labels of the query set by computing aggregated posteriors. We validate our model on Omniglot and Mini-ImageNet datasets by evaluating its performance on downstream few-shot classification tasks. The results show that our model obtain impressive performance gains over existing unsupervised meta-learning baselines, even outperforming supervised MAML on a certain setting.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\ZZDZA3MH\\Lee et al. - 2021 - Meta-GMVAE Mixture of Gaussian VAE for Unsupervis.pdf}
}

@article{linskerSelfOrganizationPerceptualNetwork1988,
  title = {Self-{{Organization}} in a {{Perceptual Network}}.},
  author = {Linsker, Ralph},
  date = {1988-03-01},
  journaltitle = {IEEE Computer},
  shortjournal = {IEEE Computer},
  volume = {21},
  pages = {105--117},
  doi = {10.1109/2.36},
  abstract = {In this article, the author briefly summarizes the network ideas from an earlier publication and reviews some of the main results. This sets the stage for exploring why a feature-analyzing function emerges. He then shows that even a single developing cell of a layered network exhibits a remarkable set of optimization properties. These properties are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representations in artificial intelligence, and information theory. Next, he uses these results to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle he proposes is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. He illustrates how this principle works for some very simple cases. Much more work will be needed to apply the principle to practical computations of biologically important cases, but the approach appears very promising. He concludes with some speculative comments on why this principle, or some variant of it, may be important for the emergence of perceptual function in biological and synthetic systems.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\4UV3LQ8S\\Linsker - 1988 - Self-Organization in a Perceptual Network..pdf}
}

@article{liSupervisedSpeechEnhancement2020,
  title = {A {{Supervised Speech Enhancement Approach}} with {{Residual Noise Control}} for {{Voice Communication}}},
  author = {Li, Andong and Peng, Renhua and Zheng, Chengshi and Li, Xiaodong},
  date = {2020-01},
  journaltitle = {Applied Sciences},
  volume = {10},
  number = {8},
  pages = {2894},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app10082894},
  url = {https://www.mdpi.com/2076-3417/10/8/2894},
  urldate = {2023-05-17},
  abstract = {For voice communication, it is important to extract the speech from its noisy version without introducing unnaturally artificial noise. By studying the subband mean-squared error (MSE) of the speech for unsupervised speech enhancement approaches and revealing its relationship with the existing loss function for supervised approaches, this paper derives a generalized loss function that takes residual noise control into account with a supervised approach. Our generalized loss function contains the well-known MSE loss function and many other often-used loss functions as special cases. Compared with traditional loss functions, our generalized loss function is more flexible to make a good trade-off between speech distortion and noise reduction. This is because a group of well-studied noise shaping schemes can be introduced to control residual noise for practical applications. Objective and subjective test results verify the importance of residual noise control for the supervised speech enhancement approach.},
  issue = {8},
  langid = {english},
  keywords = {deep learning,generalized loss function,noise shaping,residual noise control,speech distortion},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\WYQYF48Y\\Li et al. - 2020 - A Supervised Speech Enhancement Approach with Resi.pdf}
}

@article{liuImprovedHierarchicalVariational2023,
  title = {An Improved Hierarchical Variational Autoencoder for Cell–Cell Communication Estimation Using Single-Cell {{RNA-seq}} Data},
  author = {Liu, Shuhui and Zhang, Yupei and Peng, Jiajie and Shang, Xuequn},
  date = {2023-02-07},
  journaltitle = {Briefings in Functional Genomics},
  shortjournal = {Briefings in Functional Genomics},
  pages = {elac056},
  issn = {2041-2657},
  doi = {10.1093/bfgp/elac056},
  url = {https://doi.org/10.1093/bfgp/elac056},
  urldate = {2023-05-22},
  abstract = {Analysis of cell–cell communication (CCC) in the tumor micro-environment helps decipher the underlying mechanism of cancer progression and drug tolerance. Currently, single-cell RNA-Seq data are available on a large scale, providing an unprecedented opportunity to predict cellular communications. There have been many achievements and applications in inferring cell–cell communication based on the known interactions between molecules, such as ligands, receptors and extracellular matrix. However, the prior information is not quite adequate and only involves a fraction of cellular communications, producing many false-positive or false-negative results. To this end, we propose an improved hierarchical variational autoencoder (HiVAE) based model to fully use single-cell RNA-seq data for automatically estimating CCC. Specifically, the HiVAE model is used to learn the potential representation of cells on known ligand–receptor genes and all genes in single-cell RNA-seq data, respectively, which are then utilized for cascade integration. Subsequently, transfer entropy is employed to measure the transmission of information flow between two cells based on the learned representations, which are regarded as directed communication relationships. Experiments are conducted on single-cell RNA-seq data of the human skin disease dataset and the melanoma dataset, respectively. Results show that the HiVAE model is effective in learning cell representations, and transfer entropy could be used to estimate the communication scores between cell types.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\67DFBQLY\\Liu et al. - 2023 - An improved hierarchical variational autoencoder f.pdf;C\:\\Users\\Fab\\Zotero\\storage\\K67GRI8B\\7030842.html}
}

@online{lowePuttingEndEndtoEnd2020,
  title = {Putting {{An End}} to {{End-to-End}}: {{Gradient-Isolated Learning}} of {{Representations}}},
  shorttitle = {Putting {{An End}} to {{End-to-End}}},
  author = {Löwe, Sindy and O'Connor, Peter and Veeling, Bastiaan S.},
  date = {2020-01-27},
  eprint = {1905.11786},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1905.11786},
  url = {http://arxiv.org/abs/1905.11786},
  urldate = {2022-10-05},
  abstract = {We propose a novel deep learning method for local self-supervised representation learning that does not require labels nor end-to-end backpropagation but exploits the natural order in data instead. Inspired by the observation that biological neural networks appear to learn without backpropagating a global error signal, we split a deep neural network into a stack of gradient-isolated modules. Each module is trained to maximally preserve the information of its inputs using the InfoNCE bound from Oord et al. [2018]. Despite this greedy training, we demonstrate that each module improves upon the output of its predecessor, and that the representations created by the top module yield highly competitive results on downstream classification tasks in the audio and visual domain. The proposal enables optimizing modules asynchronously, allowing large-scale distributed training of very deep neural networks on unlabelled datasets.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NKST6QEI\\Löwe et al. - 2020 - Putting An End to End-to-End Gradient-Isolated Le.pdf;C\:\\Users\\Fab\\Zotero\\storage\\DGLLIKIT\\1905.html}
}

@article{lucasUnderstandingPosteriorCollapse2022,
  title = {Understanding {{Posterior Collapse}} in {{Generative Latent Variable Models}}},
  author = {Lucas, James and Tucker, George and Grosse, Roger and Norouzi, Mohammad},
  date = {2022-07-11},
  url = {https://openreview.net/forum?id=r1xaVLUYuE},
  urldate = {2023-04-22},
  abstract = {Posterior collapse in Variational Autoencoders (VAEs) arises when the variational distribution closely matches the uninformative prior for a subset of latent variables. This paper presents a simple and intuitive explanation for posterior collapse through the analysis of linear VAEs and their direct correspondence with Probabilistic PCA (pPCA). We identify how local maxima can emerge from the marginal log-likelihood of pPCA, which yields similar local maxima for the evidence lower bound (ELBO). We show that training a linear VAE with variational inference recovers a uniquely identifiable global maximum corresponding to the principal component directions. We provide empirical evidence that the presence of local maxima causes posterior collapse in deep non-linear VAEs. Our findings help to explain a wide range of heuristic approaches in the literature that attempt to diminish the effect of the KL term in the ELBO to reduce posterior collapse.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\9RLA5RXB\\Lucas et al. - 2022 - Understanding Posterior Collapse in Generative Lat.pdf}
}

@article{luongDesigningInterpretableRecurrent2021,
  title = {Designing {{Interpretable Recurrent Neural Networks}} for {{Video Reconstruction}} via {{Deep Unfolding}}},
  author = {Luong, Huynh Van and Joukovsky, Boris and Deligiannis, Nikos},
  date = {2021},
  journaltitle = {Ieee Transactions on Image Processing},
  shortjournal = {IEEE Trans. Image Process.},
  volume = {30},
  pages = {4099--4113},
  publisher = {{Ieee-Inst Electrical Electronics Engineers Inc}},
  location = {{Piscataway}},
  issn = {1057-7149},
  doi = {10.1109/TIP.2021.3069296},
  url = {http://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DynamicDOIArticle&SrcApp=WOS&KeyAID=10.1109%2FTIP.2021.3069296&DestApp=DOI&SrcAppSID=EUW1ED0EC2mMtqu9x5Eo9sqmWEy6d&SrcJTitle=IEEE+TRANSACTIONS+ON+IMAGE+PROCESSING&DestDOIRegistrantName=Institute+of+Electrical+and+Electronics+Engineers},
  urldate = {2022-11-05},
  abstract = {Deep unfolding methods design deep neural networks as learned variations of optimization algorithms through the unrolling of their iterations. These networks have been shown to achieve faster convergence and higher accuracy than the original optimization methods. In this line of research, this paper presents novel interpretable deep recurrent neural networks (RNNs), designed by the unfolding of iterative algorithms that solve the task of sequential signal reconstruction (in particular, video reconstruction). The proposed networks are designed by accounting that video frames' patches have a sparse representation and the temporal difference between consecutive representations is also sparse. Specifically, we design an interpretable deep RNN (coined reweighted-RNN) by unrolling the iterations of a proximal method that solves a reweighted version of the l(1)-l(1) minimization problem. Due to the underlying minimization model, our reweighted-RNN has a different thresholding function (alias, different activation function) for each hidden unit in each layer. In this way, it has higher network expressivity than existing deep unfolding RNN models. We also present the derivative l(1)-l(1)-RNN model, which is obtained by unfolding a proximal method for the l(1)-l(1) minimization problem. We apply the proposed interpretable RNNs to the task of video frame reconstruction from low-dimensional measurements, that is, sequential video frame reconstruction. The experimental results on various datasets demonstrate that the proposed deep RNNs outperform various RNN models.},
  langid = {english},
  keywords = {Deep unfolding,inverse problems,recurrent neural   networks,reweighted l(1)-l(1) minimization,sequential frame reconstruction,sparse,thresholding algorithm},
  annotation = {WOS:000639653800002}
}

@online{luSemiSupervisedHistologyClassification2019,
  title = {Semi-{{Supervised Histology Classification}} Using {{Deep Multiple Instance Learning}} and {{Contrastive Predictive Coding}}},
  author = {Lu, Ming Y. and Chen, Richard J. and Wang, Jingwen and Dillon, Debora and Mahmood, Faisal},
  date = {2019-11-02},
  eprint = {1910.10825},
  eprinttype = {arxiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.1910.10825},
  url = {http://arxiv.org/abs/1910.10825},
  urldate = {2023-04-06},
  abstract = {Convolutional neural networks can be trained to perform histology slide classification using weak annotations with multiple instance learning (MIL). However, given the paucity of labeled histology data, direct application of MIL can easily suffer from overfitting and the network is unable to learn rich feature representations due to the weak supervisory signal. We propose to overcome such limitations with a two-stage semi-supervised approach that combines the power of data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and the interpretability and flexibility of regularized attention-based MIL. We apply our two-stage CPC + MIL semi-supervised pipeline to the binary classification of breast cancer histology images. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95\% and an area under the ROC curve of 0.968. We further evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework even with the feature encoder frozen.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Quantitative Biology - Tissues and Organs},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MRM6G54A\\Lu et al. - 2019 - Semi-Supervised Histology Classification using Dee.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RVZT5KGU\\1910.html}
}

@article{maatenVisualizingDataUsing2008,
  title = {Visualizing {{Data}} Using T-{{SNE}}},
  author = {family=Maaten, given=Laurens, prefix=van der, useprefix=false and Hinton, Geoffrey},
  date = {2008},
  journaltitle = {Journal of Machine Learning Research},
  volume = {9},
  number = {86},
  pages = {2579--2605},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v9/vandermaaten08a.html},
  urldate = {2023-05-14},
  abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images ofobjects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\BZFHRZBC\\Maaten and Hinton - 2008 - Visualizing Data using t-SNE.pdf}
}

@article{marblestoneIntegrationDeepLearning2016,
  title = {Toward an {{Integration}} of {{Deep Learning}} and {{Neuroscience}}},
  author = {Marblestone, Adam H. and Wayne, Greg and Kording, Konrad P.},
  date = {2016},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {10},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2016.00094},
  urldate = {2023-04-04},
  abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\LTDYZYN2\\Marblestone et al. - 2016 - Toward an Integration of Deep Learning and Neurosc.pdf}
}

@inproceedings{meghananiExplorationLogMelSpectrogram2021,
  title = {An {{Exploration}} of {{Log-Mel Spectrogram}} and {{MFCC Features}} for {{Alzheimer}}’s {{Dementia Recognition}} from {{Spontaneous Speech}}},
  booktitle = {2021 {{IEEE Spoken Language Technology Workshop}} ({{SLT}})},
  author = {Meghanani, Amit and C. S., Anoop and Ramakrishnan, A. G.},
  date = {2021-01},
  pages = {670--677},
  doi = {10.1109/SLT48900.2021.9383491},
  abstract = {In this work, we explore the effectiveness of log-Mel spectrogram and MFCC features for Alzheimer's dementia (AD) recognition on ADReSS challenge dataset. We use three different deep neural networks (DNN) for AD recognition and mini-mental state examination (MMSE) score prediction: (i) convolutional neural network followed by a long-short term memory network (CNN-LSTM), (ii) pre-trained ResNet18 network followed by LSTM (ResNet-LSTM), and (iii) pyramidal bidirectional LSTM followed by a CNN (pBLSTM-CNN). CNN-LSTM achieves an accuracy of 64.58\% with MFCC features and ResNet-LSTM achieves an accuracy of 62.5\% using log-Mel spectrograms. pBLSTM-CNN and ResNet-LSTM models achieve root mean square errors (RMSE) of 5.9 and 5.98 in the MMSE score prediction, using the log-Mel spectrograms. Our results beat the baseline accuracy (62.5\%) and RMSE (6.14) reported for acoustic features on ADReSS challenge dataset. The results suggest that log-Mel spectrograms and MFCCs are effective features for AD recognition problem when used with DNN models.},
  eventtitle = {2021 {{IEEE Spoken Language Technology Workshop}} ({{SLT}})},
  keywords = {Alzheimer,CNN,dementia,Dementia,log-Mel spectrogram,LSTM,Mel frequency cepstral coefficient,MFCC,MMSE,Neural networks,Predictive models,ResNet18,Root mean square,Spectrogram,Speech recognition,transfer learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\3FCSRUSM\\Meghanani et al. - 2021 - An Exploration of Log-Mel Spectrogram and MFCC Fea.pdf;C\:\\Users\\Fab\\Zotero\\storage\\UYISEU95\\9383491.html}
}

@thesis{meihanwangSpeechRepresentationLearning2019,
  title = {Speech Representation Learning without Backpropagation},
  author = {{Meihan Wang}},
  date = {2019/2020},
  institution = {{Vrije Universiteit Brussel}},
  abstract = {Backpropagation as a common method of training artificial neural networks has been widely used to complete speech recognition tasks. However, due to its cognitive implau sibility, a lot of researches are devoted to finding an alternative to this mechanism which can be used to solve the problem of audio signal feature learning in a way that is more similar to the real human brain activity. This thesis implements the “Greedy InfoMax” method proposed by L¨owe et al. (L¨owe et al., 2019) which trains each module of the neural network individually in a self supervised way by keeping the input information as much as possible and maximizing the cross-correlation between adjacent segments, and adapts it to a small self-recorded data set in order to verify whether “Greedy InfoMax” could still get ideal recognition results using simpler inputs. We make minor modifications to the original model (eliminate the use of backpropagation in the information integration processing stage) and re select the optimal values of the parameters according to the current database. After the phase of feature extraction, we take advantage of the t-SNE method to perform dimensionality reduction. This operation helps to embed the generated high-dimensional representations into a two-dimensional plane, and such visualization allows us to better observe and analyze what kind of information the neural network has learned. The results of the experiments prove the feasibility and e↵ectiveness of this approach}
}

@article{nalisnickApproximateInferenceDeep,
  title = {Approximate {{Inference}} for {{Deep Latent Gaussian Mixtures}}},
  author = {Nalisnick, Eric and Hertel, Lars and Smyth, Padhraic},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\P9E5FFFM\\Nalisnick et al. - Approximate Inference for Deep Latent Gaussian Mix.pdf}
}

@inproceedings{neyshaburExploringGeneralizationDeep2017,
  title = {Exploring {{Generalization}} in {{Deep Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Mcallester, David and Srebro, Nati},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper\_files/paper/2017/hash/10ce03a1ed01077e3e289f3e53c72813-Abstract.html},
  urldate = {2023-05-01},
  abstract = {With a goal of understanding what drives generalization in deep networks, we consider several recently suggested explanations, including norm-based control, sharpness and robustness. We study how these measures can ensure generalization, highlighting the importance of scale normalization, and making a connection between sharpness and PAC-Bayes theory.  We then investigate how well the measures explain different observed phenomena.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NHV5CAQX\\Neyshabur et al. - 2017 - Exploring Generalization in Deep Learning.pdf}
}

@inproceedings{NIPS2012_c399862d,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
  date = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper{\_}files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf}
}

@article{nowlanSimplifyingNeuralNetworks1992,
  title = {Simplifying {{Neural Networks}} by {{Soft Weight-Sharing}}},
  author = {Nowlan, Steven J. and Hinton, Geoffrey E.},
  date = {1992-07},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {4},
  number = {4},
  pages = {473--493},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.1992.4.4.473},
  url = {https://direct.mit.edu/neco/article/4/4/473-493/5653},
  urldate = {2023-05-27},
  abstract = {One way of simplifying neural networks so they generalize better is to add an extra term to the error function that will penalize complexity. Simple versions of this approach include penalizing the sum of the squares of the weights or penalizing the number of nonzero weights. We propose a more complicated penalty term in which the distribution of weight values is modeled as a mixture of multiple gaussians. A set of weights is simple if the weights have high probability density under the mixture model. This can be achieved by clustering the weights into subsets with the weights in each cluster having very similar values. Since we do not know the appropriate means or variances of the clusters in advance, we allow the parameters of the mixture model to adapt at the same time as the network learns. Simulations on two different problems demonstrate that this complexity term is more effective than previous complexity terms.},
  langid = {english}
}

@online{odaiboTutorialDerivingStandard2019,
  title = {Tutorial: {{Deriving}} the {{Standard Variational Autoencoder}} ({{VAE}}) {{Loss Function}}},
  shorttitle = {Tutorial},
  author = {Odaibo, Stephen},
  date = {2019-07-21},
  eprint = {1907.08956},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1907.08956},
  urldate = {2023-05-23},
  abstract = {In Bayesian machine learning, the posterior distribution is typically computationally intractable, hence variational inference is often required. In this approach, an evidence lower bound on the log likelihood of data is maximized during training. Variational Autoencoders (VAE) are one important example where variational inference is utilized. In this tutorial, we derive the variational lower bound loss function of the standard variational autoencoder. We do so in the instance of a gaussian latent prior and gaussian approximate posterior, under which assumptions the Kullback-Leibler term in the variational lower bound has a closed form solution. We derive essentially everything we use along the way; everything from Bayes' theorem to the Kullback-Leibler divergence.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\QJDAFHCH\\Odaibo - 2019 - Tutorial Deriving the Standard Variational Autoen.pdf;C\:\\Users\\Fab\\Zotero\\storage\\SNUF72L4\\1907.html}
}

@online{oordRepresentationLearningContrastive2019,
  title = {Representation {{Learning}} with {{Contrastive Predictive Coding}}},
  author = {family=Oord, given=Aaron, prefix=van den, useprefix=false and Li, Yazhe and Vinyals, Oriol},
  date = {2019-01-22},
  eprint = {1807.03748},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1807.03748},
  url = {http://arxiv.org/abs/1807.03748},
  urldate = {2022-10-16},
  abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\YRNBNG2M\\Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RP9HCEKT\\1807.html}
}

@online{PapersCodeMNIST,
  title = {Papers with {{Code}} - {{MNIST Dataset}}},
  url = {https://paperswithcode.com/dataset/mnist},
  urldate = {2023-03-30},
  abstract = {The MNIST database (Modified National Institute of Standards and Technology database) is a large collection of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger NIST Special Database 3 (digits written by employees of the United States Census Bureau) and Special Database 1 (digits written by high school students) which contain monochrome images of handwritten digits. The digits have been size-normalized and centered in a fixed-size image. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\CA79ISSF\\mnist.html}
}

@article{paszkeAutomaticDifferentiationPyTorch2017,
  title = {Automatic Differentiation in {{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  date = {2017-10-28},
  url = {https://openreview.net/forum?id=BJJsrmfCZ},
  urldate = {2023-05-07},
  abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd, and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\N7DC4HSH\\Paszke et al. - 2017 - Automatic differentiation in PyTorch.pdf}
}

@inproceedings{pervezSpectralSmoothingUnveils2021,
  title = {Spectral {{Smoothing Unveils Phase Transitions}} in {{Hierarchical Variational Autoencoders}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Pervez, Adeel and Gavves, Efstratios},
  date = {2021-07-01},
  pages = {8536--8545},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/pervez21a.html},
  urldate = {2023-05-22},
  abstract = {Variational autoencoders with deep hierarchies of stochastic layers have been known to suffer from the problem of posterior collapse, where the top layers fall back to the prior and become independent of input. We suggest that the hierarchical VAE objective explicitly includes the variance of the function parameterizing the mean and variance of the latent Gaussian distribution which itself is often a high variance function. Building on this we generalize VAE neural networks by incorporating a smoothing parameter motivated by Gaussian analysis to reduce higher frequency components and consequently the variance in parameterizing functions and show that this can help to solve the problem of posterior collapse. We further show that under such smoothing the VAE loss exhibits a phase transition, where the top layer KL divergence sharply drops to zero at a critical value of the smoothing parameter that is similar for the same model across datasets. We validate the phenomenon across model configurations and datasets.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\B8Z2JPRJ\\Pervez and Gavves - 2021 - Spectral Smoothing Unveils Phase Transitions in Hi.pdf;C\:\\Users\\Fab\\Zotero\\storage\\TWLQQUD4\\Pervez and Gavves - 2021 - Spectral Smoothing Unveils Phase Transitions in Hi.pdf}
}

@article{polyzotisDataLifecycleChallenges2018,
  title = {Data {{Lifecycle Challenges}} in {{Production Machine Learning}}: {{A Survey}}},
  shorttitle = {Data {{Lifecycle Challenges}} in {{Production Machine Learning}}},
  author = {Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
  date = {2018-12-11},
  journaltitle = {ACM SIGMOD Record},
  shortjournal = {SIGMOD Rec.},
  volume = {47},
  number = {2},
  pages = {17--28},
  issn = {0163-5808},
  doi = {10.1145/3299887.3299891},
  url = {https://dl.acm.org/doi/10.1145/3299887.3299891},
  urldate = {2023-05-01},
  abstract = {Machine learning has become an essential tool for gleaning knowledge from data and tackling a diverse set of computationally hard tasks. However, the accuracy of a machine learned model is deeply tied to the data that it is trained on. Designing and building robust processes and tools that make it easier to analyze, validate, and transform data that is fed into large-scale machine learning systems poses data management challenges. Drawn from our experience in developing data-centric infrastructure for a production machine learning platform at Google, we summarize some of the interesting research challenges that we encountered, and survey some of the relevant literature from the data management and machine learning communities. Specifically, we explore challenges in three main areas of focus - data understanding, data validation and cleaning, and data preparation. In each of these areas, we try to explore how different constraints are imposed on the solutions depending on where in the lifecycle of a model the problems are encountered and who encounters them.}
}

@inproceedings{przybyszewskiUseDomainKnowledge2017,
  title = {Use of Domain Knowledge and Feature Engineering in Helping {{AI}} to Play {{Hearthstone}}},
  booktitle = {2017 {{Federated Conference}} on {{Computer Science}} and {{Information Systems}} ({{FedCSIS}})},
  author = {Przybyszewski, Przemysław and Dziewiatkowski, Szymon and Jaszczur, Sebastian and Smiech, Mateusz and Szczuka, Marcin},
  date = {2017-09},
  pages = {143--148},
  doi = {10.15439/2017F567},
  abstract = {This paper describes two approaches to the AAIA'17 Data Mining Challenge. Both approaches are making extensive use of domain/background knowledge about the game to build better representation of classification problem by engineering new features. With newly constructed attributes both approaches resort to Artificial Neural Networks (ANN) to construct classification model. The resulting solutions are effective and meaningful.},
  eventtitle = {2017 {{Federated Conference}} on {{Computer Science}} and {{Information Systems}} ({{FedCSIS}})},
  keywords = {Crystals,Data mining,Entertainment industry,Games,Knowledge engineering,Neural networks},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\U4NDDGR2\\8104528.html}
}

@online{radkoffLossFunctionsAudio2021,
  title = {Loss {{Functions}} in {{Audio ML}}},
  author = {Radkoff, Evan},
  date = {2021-09-06T00:00:00+00:00},
  url = {https://soundsandwords.io//audio-loss-functions/},
  urldate = {2023-05-17},
  abstract = {An informal survey of objective functions used in Machine Learning in the audio domain.},
  organization = {{Sounds and Words}},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\Q6D34AB7\\audio-loss-functions.html}
}

@inproceedings{ranganathHierarchicalVariationalModels2016,
  title = {Hierarchical {{Variational Models}}},
  booktitle = {Proceedings of {{The}} 33rd {{International Conference}} on {{Machine Learning}}},
  author = {Ranganath, Rajesh and Tran, Dustin and Blei, David},
  date = {2016-06-11},
  pages = {324--333},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v48/ranganath16.html},
  urldate = {2023-05-22},
  abstract = {Black box variational inference allows researchers to easily prototype and evaluate an array of models. Recent advances allow such algorithms to scale to high dimensions. However, a central question remains: How to specify an expressive variational distribution that maintains efficient computation? To address this, we develop hierarchical variational models (HVMs). HVMs augment a variational approximation with a prior on its parameters, which allows it to capture complex structure for both discrete and continuous latent variables. The algorithm we develop is black box, can be used for any HVM, and has the same computational efficiency as the original approximation. We study HVMs on a variety of deep discrete latent variable models. HVMs generalize other expressive variational distributions and maintains higher fidelity to the posterior.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\KV8MHV8E\\Ranganath et al. - 2016 - Hierarchical Variational Models.pdf}
}

@online{raoUnderstandingGradientIsolatedLearning2020,
  title = {Understanding the {{Gradient-Isolated Learning}} of {{Representations}} and Intuition to the {{Greedy}}…},
  author = {Rao, Sumanth S.},
  date = {2020-01-28T04:15:53},
  url = {https://medium.com/analytics-vidhya/understanding-the-gradient-isolated-learning-of-representations-and-intuition-to-the-greedy-cb6c3598e317},
  urldate = {2022-11-13},
  abstract = {Since my association with Data Science and Machine learning, the one question that has always fascinated me is the humongous amount of…},
  langid = {english},
  organization = {{Analytics Vidhya}},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\D7XD89X5\\understanding-the-gradient-isolated-learning-of-representations-and-intuition-to-the-greedy-cb6.html}
}

@article{rePreferencesVeryLow2012,
  title = {Preferences for {{Very Low}} and {{Very High Voice Pitch}} in {{Humans}}},
  author = {Re, Daniel E. and O'Connor, Jillian J. M. and Bennett, Patrick J. and Feinberg, David R.},
  date = {2012-03-05},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS One},
  volume = {7},
  number = {3},
  eprint = {22403701},
  eprinttype = {pmid},
  pages = {e32719},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0032719},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3293852/},
  urldate = {2023-05-21},
  abstract = {Manipulations of voice pitch have been shown to alter attractiveness ratings, but whether preferences extend to very low or very high voice pitch is unknown. Here, we manipulated voice pitch in averaged men's and women's voices by 2 Hz intervals to create a range of male and female voices speaking monopthong vowel sounds and spanning a range of frequencies from normal to very low and very high pitch. With these voices, we used the method of constant stimuli to measure preferences for voice. Nineteen university students (ages: 20–25) participated in three experiments. On average, men preferred high-pitched women's voices to low-pitched women's voices across all frequencies tested. On average, women preferred men's voices lowered in pitch, but did not prefer very low men's voices. The results of this study may reflect selection pressures for men's and women's voices, and shed light on a perceptual link between voice pitch and vocal attractiveness.},
  pmcid = {PMC3293852},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NZWHIZ5Q\\Re et al. - 2012 - Preferences for Very Low and Very High Voice Pitch.pdf}
}

@online{rhodesVariationalNoiseContrastiveEstimation2019,
  title = {Variational {{Noise-Contrastive Estimation}}},
  author = {Rhodes, Benjamin and Gutmann, Michael},
  date = {2019-02-24},
  eprint = {1810.08010},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1810.08010},
  urldate = {2023-02-19},
  abstract = {Unnormalised latent variable models are a broad and flexible class of statistical models. However, learning their parameters from data is intractable, and few estimation techniques are currently available for such models. To increase the number of techniques in our arsenal, we propose variational noise-contrastive estimation (VNCE), building on NCE which is a method that only applies to unnormalised models. The core idea is to use a variational lower bound to the NCE objective function, which can be optimised in the same fashion as the evidence lower bound (ELBO) in standard variational inference (VI). We prove that VNCE can be used for both parameter estimation of unnormalised models and posterior inference of latent variables. The developed theory shows that VNCE has the same level of generality as standard VI, meaning that advances made there can be directly imported to the unnormalised setting. We validate VNCE on toy models and apply it to a realistic problem of estimating an undirected graphical model from incomplete data.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\4NUG94Z8\\Rhodes and Gutmann - 2019 - Variational Noise-Contrastive Estimation.pdf;C\:\\Users\\Fab\\Zotero\\storage\\E5RCECL5\\1810.html}
}

@online{ridgewaySurveyInductiveBiases2016,
  title = {A {{Survey}} of {{Inductive Biases}} for {{Factorial Representation-Learning}}},
  author = {Ridgeway, Karl},
  date = {2016-12-15},
  eprint = {1612.05299},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1612.05299},
  url = {http://arxiv.org/abs/1612.05299},
  urldate = {2023-05-22},
  abstract = {With the resurgence of interest in neural networks, representation learning has re-emerged as a central focus in artificial intelligence. Representation learning refers to the discovery of useful encodings of data that make domain-relevant information explicit. Factorial representations identify underlying independent causal factors of variation in data. A factorial representation is compact and faithful, makes the causal factors explicit, and facilitates human interpretation of data. Factorial representations support a variety of applications, including the generation of novel examples, indexing and search, novelty detection, and transfer learning. This article surveys various constraints that encourage a learning algorithm to discover factorial representations. I dichotomize the constraints in terms of unsupervised and supervised inductive bias. Unsupervised inductive biases exploit assumptions about the environment, such as the statistical distribution of factor coefficients, assumptions about the perturbations a factor should be invariant to (e.g. a representation of an object can be invariant to rotation, translation or scaling), and assumptions about how factors are combined to synthesize an observation. Supervised inductive biases are constraints on the representations based on additional information connected to observations. Supervisory labels come in variety of types, which vary in how strongly they constrain the representation, how many factors are labeled, how many observations are labeled, and whether or not we know the associations between the constraints and the factors they are related to. This survey brings together a wide variety of models that all touch on the problem of learning factorial representations and lays out a framework for comparing these models based on the strengths of the underlying supervised and unsupervised inductive biases.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\6TK2K2J3\\Ridgeway - 2016 - A Survey of Inductive Biases for Factorial Represe.pdf;C\:\\Users\\Fab\\Zotero\\storage\\LLZT95BB\\1612.html}
}

@inproceedings{rumelhartLearningInternalRepresentations1988,
  title = {Learning {{Internal Representations}} by {{Error Propagation}}},
  booktitle = {Readings in {{Cognitive Science}}},
  author = {Rumelhart, D.E. and Hinton, G.E. and Williams, R.J.},
  date = {1988},
  pages = {399--421},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-1-4832-1446-7.50035-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9781483214467500352},
  urldate = {2023-03-29},
  abstract = {Semantic Scholar extracted view of "Learning internal representations by error propagation" by D. Rumelhart et al.},
  isbn = {978-1-4832-1446-7},
  langid = {english}
}

@article{rustUsingRandomizationBreak1997,
  title = {Using {{Randomization}} to {{Break}} the {{Curse}} of {{Dimensionality}}},
  author = {Rust, John},
  date = {1997},
  journaltitle = {Econometrica},
  volume = {65},
  number = {3},
  eprint = {2171751},
  eprinttype = {jstor},
  pages = {487--516},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {0012-9682},
  doi = {10.2307/2171751},
  url = {https://www.jstor.org/stable/2171751},
  urldate = {2023-05-01},
  abstract = {This paper introduces random versions of successive approximations and multigrid algorithms for computing approximate solutions to a class of finite and infinite horizon Markovian decision problems (MDPs). We prove that these algorithms succeed in breaking the "curse of dimensionality" for a subclass of MDPs known as discrete decision processes (DDPs).},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\BKDEV87Y\\Rust - 1997 - Using Randomization to Break the Curse of Dimensio.pdf}
}

@inproceedings{santurkarHowDoesBatch2018,
  title = {How {{Does Batch Normalization Help Optimization}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/905056c1ac1dad141560467e0a99e1cf-Abstract.html},
  urldate = {2023-04-25},
  abstract = {Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers' input distributions during training to reduce the so-called "internal covariate shift". In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\ITSBCI6D\\Santurkar et al. - 2018 - How Does Batch Normalization Help Optimization.pdf}
}

@inproceedings{saunshiTheoreticalAnalysisContrastive2019,
  title = {A {{Theoretical Analysis}} of {{Contrastive Unsupervised Representation Learning}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Saunshi, Nikunj and Plevrakis, Orestis and Arora, Sanjeev and Khodak, Mikhail and Khandeparkar, Hrishikesh},
  date = {2019-05-24},
  pages = {5628--5637},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/saunshi19a.html},
  urldate = {2023-05-01},
  abstract = {Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically “similar" data points and “negative samples," the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\29Z9IKJJ\\Saunshi et al. - 2019 - A Theoretical Analysis of Contrastive Unsupervised.pdf;C\:\\Users\\Fab\\Zotero\\storage\\I5GQQZMB\\Saunshi et al. - 2019 - A Theoretical Analysis of Contrastive Unsupervised.pdf}
}

@article{scottFEATUREENGINEERINGTEXT,
  title = {{{FEATURE ENGINEERING FOR TEXT CLASSIFICATION}}},
  author = {Scott, Sam and Matwin, Stan},
  abstract = {Most research in text classification has used the “bag of words” representation of text. This paper examines some alternative ways to represent text based on syntactic and semantic relationships between words (phrases, synonyms and hypernyms). We describe the new representations and try to justify our suspicions that they could have improved the performance of a rule-based learner. The representations are evaluated using the RIPPER rule-based learner on the Reuters-21578 and DigiTrad test corpora, but on their own the new representations are not found to produce a significant performance improvement. Finally, we try combining classifiers based on different representations using a majority voting technique. This step does produce some performance improvement on both test collections. In general, our work supports the emerging consensus in the information retrieval community that more sophisticated Natural Language Processing techniques need to be developed before better text representations can be produced. We conclude that for now, research into new learning algorithms and methods for combining existing learners holds the most promise.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\BK3KJFBY\\Scott and Matwin - FEATURE ENGINEERING FOR TEXT CLASSIFICATION.pdf}
}

@article{shah92LearningGood,
  title = {[{{AN}} \#92]: {{Learning}} Good Representations with Contrastive Predictive Coding},
  shorttitle = {[{{AN}} \#92]},
  author = {Shah, Rohin},
  url = {https://www.lesswrong.com/posts/XE6LD2c9NtB7gMdEm/an-92-learning-good-representations-with-contrastive},
  urldate = {2023-04-04},
  abstract = {Newsletter \#92 • Alignment Newsletter is a weekly publication with recent content relevant to AI alignment around the world. Find all Alignment Newsletter resources here. In particular, you can look…},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\MMJNICYH\\an-92-learning-good-representations-with-contrastive.html}
}

@inproceedings{shenNaturalTTSSynthesis2018,
  title = {Natural {{TTS Synthesis}} by {{Conditioning Wavenet}} on {{MEL Spectrogram Predictions}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and Saurous, Rif A. and Agiomvrgiannakis, Yannis and Wu, Yonghui},
  date = {2018-04},
  pages = {4779--4783},
  issn = {2379-190X},
  doi = {10.1109/ICASSP.2018.8461368},
  abstract = {This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text. The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize time-domain waveforms from those spectrograms. Our model achieves a mean opinion score (MOS) of 4.53 comparable to a MOS of 4.58 for professionally recorded speech. To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the conditioning input to WaveNet instead of linguistic, duration, and F0 features. We further show that using this compact acoustic intermediate representation allows for a significant reduction in the size of the WaveNet architecture.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  keywords = {Acoustics,Decoding,Linguistics,Spectrogram,Tacotron 2,text-to-speech,Time-domain analysis,Training,Vocoders,WaveNet},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\AH8UM2PM\\Shen et al. - 2018 - Natural TTS Synthesis by Conditioning Wavenet on M.pdf;C\:\\Users\\Fab\\Zotero\\storage\\SSNFK352\\8461368.html}
}

@inproceedings{sivasankaranExplainingDeepLearning2021,
  title = {Explaining Deep Learning Models for Speech Enhancement},
  booktitle = {Interspeech 2021},
  author = {Sivasankaran, Sunit and Vincent, Emmanuel and Fohr, Dominique},
  date = {2021},
  pages = {696--700},
  publisher = {{Isca-Int Speech Communication Assoc}},
  location = {{Baixas}},
  issn = {2308-457X},
  doi = {10.21437/Interspeech.2021-1764},
  url = {http://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DOISource&SrcApp=UA&KeyAID=10.21437%2Finterspeech.2021-1764&DestApp=DOI&SrcAppSID=EUW1ED0EC2mMtqu9x5Eo9sqmWEy6d&SrcJTitle=INTERSPEECH+2021&DestDOIRegistrantName=International+Speech+Communication+Association},
  urldate = {2022-11-05},
  abstract = {We consider the problem of explaining the robustness of neural networks used to compute time-frequency masks for speech enhancement to mismatched noise conditions. We employ the Deep SHapley Additive exPlanations (DeepSHAP) feature attribution method to quantify the contribution of every time-frequency bin in the input noisy speech signal to every time-frequency bin in the output time-frequency mask. We define an objective metric - referred to as the speech relevance score-that summarizes the obtained SHAP values and show that it correlates with the enhancement performance, as measured by the word error rate on the CHiME-4 real evaluation dataset. We use the speech relevance score to explain the generalization ability of three speech enhancement models trained using synthetically generated speech-shaped noise, noise from a professional sound effects library, or real CHiME-4 noise. To the best of our knowledge, this is the first study on neural network explainability in the context of speech enhancement.},
  langid = {english},
  keywords = {Deep learning,explainable AI,feature attribution,recognition,separation,speech enhancement},
  annotation = {WOS:000841879500140},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\AHRHL8CM\\Sivasankaran et al. - 2021 - Explaining deep learning models for speech enhance.pdf}
}

@inproceedings{stackeEvaluationContrastivePredictive2020,
  title = {Evaluation of {{Contrastive Predictive Coding}} for {{Histopathology Applications}}},
  booktitle = {Proceedings of the {{Machine Learning}} for {{Health NeurIPS Workshop}}},
  author = {Stacke, Karin and Lundström, Claes and Unger, Jonas and Eilertsen, Gabriel},
  date = {2020-11-23},
  pages = {328--340},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v136/stacke20a.html},
  urldate = {2023-04-06},
  abstract = {Recent advances in self-supervised learning for image data are closing the gap between unsupervised and supervised learning. However, the effectiveness of self-supervised methods has primarily been demonstrated for natural images. If the results would extrapolate to histopathology images, there could be significant benefits due to the reduced need for annotated data. In this paper, Contrastive Predictive Coding (CPC), one of the most promising stateof-the-art self-supervised methods, is extensively evaluated on histology data by varying a range of different parameters, including training objective, resolution, and data setup. From the results, we are able to draw important conclusions on the usefulness of CPC for digital pathology. We show strong evidence of the limitations of the learned representation for tumor classification, where only low-level information learned early during training, in the first CPC layers, is used. Furthermore, in our experiments, diversifying the distribution of the dataset (i.e., data from multiple organs or medical centers) does not lead to the model learning a more general representation. This study deepens the understanding of how the CPC model’s objective relates to intrinsic characteristics of histology datasets and will help the development of effective self-supervised methods for histopathology.},
  eventtitle = {Machine {{Learning}} for {{Health}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\Y7A6ZGSE\\Stacke et al. - 2020 - Evaluation of Contrastive Predictive Coding for Hi.pdf}
}

@online{steinmetzAutomaticMultitrackMixing2020,
  title = {Automatic Multitrack Mixing with a Differentiable Mixing Console of Neural Audio Effects},
  author = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
  date = {2020-10-20},
  eprint = {2010.10291},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2010.10291},
  urldate = {2023-04-21},
  abstract = {We present auraloss1, a PyTorch package that implements time and frequency domain loss functions designed for audio generation tasks. The package provides a straightforward interface, as well as multichannel support. We demonstrate its application by using each loss function to train a model on the task of emulating an analog dynamic range compressor.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NR57CR4V\\Steinmetz et al. - 2020 - Automatic multitrack mixing with a differentiable .pdf}
}

@online{steinmetzAutomaticMultitrackMixing2020a,
  title = {Automatic Multitrack Mixing with a Differentiable Mixing Console of Neural Audio Effects},
  author = {Steinmetz, Christian J. and Pons, Jordi and Pascual, Santiago and Serrà, Joan},
  date = {2020-10-20},
  eprint = {2010.10291},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2010.10291},
  urldate = {2023-04-22},
  abstract = {We present auraloss1, a PyTorch package that implements time and frequency domain loss functions designed for audio generation tasks. The package provides a straightforward interface, as well as multichannel support. We demonstrate its application by using each loss function to train a model on the task of emulating an analog dynamic range compressor.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\2SUTWJAN\\Steinmetz et al. - 2020 - Automatic multitrack mixing with a differentiable .pdf}
}

@book{stuartrussellArtificialIntelligenceModern2022,
  title = {Artificial {{Intelligence}}: {{A Modern Approach}}, 4th {{US}} Ed.},
  author = {{Stuart Russell} and {Peter Norvig}},
  date = {2022},
  edition = {4},
  url = {https://aima.cs.berkeley.edu/},
  urldate = {2023-05-01},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\J3CUQAVY\\aima.cs.berkeley.edu.html}
}

@article{tianComprehensiveSurveyRegularization2022,
  title = {A Comprehensive Survey on Regularization Strategies in Machine Learning},
  author = {Tian, Yingjie and Zhang, Yuqi},
  date = {2022-04-01},
  journaltitle = {Information Fusion},
  shortjournal = {Information Fusion},
  volume = {80},
  pages = {146--166},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2021.11.005},
  url = {https://www.sciencedirect.com/science/article/pii/S156625352100230X},
  urldate = {2023-05-27},
  abstract = {In machine learning, the model is not as complicated as possible. Good generalization ability means that the model not only performs well on the training data set, but also can make good prediction on new data. Regularization imposes a penalty on model’s complexity or smoothness, allowing for good generalization to unseen data even when training on a finite training set or with an inadequate iteration. Deep learning has developed rapidly in recent years. Then the regularization has a broader definition: regularization is a technology aimed at improving the generalization ability of a model. This paper gave a comprehensive study and a state-of-the-art review of the regularization strategies in machine learning. Then the characteristics and comparisons of regularizations were presented. In addition, it discussed how to choose a regularization for the specific task. For specific tasks, it is necessary for regularization technology to have good mathematical characteristics. Meanwhile, new regularization techniques can be constructed by extending and combining existing regularization techniques. Finally, it concluded current opportunities and challenges of regularization technologies, as well as many open concerns and research trends.},
  langid = {english},
  keywords = {Generalization,Machine learning,Overfitting,Regularization},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\CY6F8AZC\\Tian and Zhang - 2022 - A comprehensive survey on regularization strategie.pdf;C\:\\Users\\Fab\\Zotero\\storage\\3D65IX4X\\S156625352100230X.html}
}

@article{tomczakLearningInformativeFeatures2016,
  title = {Learning {{Informative Features}} from {{Restricted Boltzmann Machines}}},
  author = {Tomczak, Jakub M.},
  date = {2016-12-01},
  journaltitle = {Neural Processing Letters},
  shortjournal = {Neural Process Lett},
  volume = {44},
  number = {3},
  pages = {735--750},
  issn = {1573-773X},
  doi = {10.1007/s11063-015-9491-9},
  url = {https://doi.org/10.1007/s11063-015-9491-9},
  urldate = {2023-05-26},
  abstract = {In recent years deep learning paradigm achieved important empirical success in a number of practical applications such as object recognition, speech recognition and natural language processing. A lot of effort has been put on understanding theoretical aspects of this success, however, still there is no common view on how deep architectures should be trained and thus many open questions remain. One hypothesis focuses on formulating good criterion (prior) that may help to learn a set of features capable of disentangling hidden factors. Following this line of thinking, in this paper, we propose to add a penalty (regularization) term to the log-likelihood function that enforces hidden units to maximize entropy and to be pairwise uncorrelated, for given observables. We hypothesize that the proposed framework for learning informative features results in more discriminative data representation that maintains its generative capabilities. In order to verify our hypothesis we apply the regularization term to the Restricted Boltzmann Machine (RBM) and carry out empirical study on three classification problems: character recognition, object recognition, and document classification. The experiments confirm that the proposed approach indeed increases discriminative and generative performance in comparison to RBM trained without any regularization and with the weight-decay, the sparse regularization, the max-norm regularization, Dropout and Dropconnect.},
  langid = {english},
  keywords = {Entropy-based regularization,Orthonormality regularization,Restricted Boltzmann machine,Unsupervised learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\HINGD9JE\\Tomczak - 2016 - Learning Informative Features from Restricted Bolt.pdf}
}

@inproceedings{tomczakVAEVampPrior2018,
  title = {{{VAE}} with a {{VampPrior}}},
  booktitle = {Proceedings of the {{Twenty-First International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Tomczak, Jakub and Welling, Max},
  date = {2018-03-31},
  pages = {1214--1223},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v84/tomczak18a.html},
  urldate = {2023-05-22},
  abstract = {Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder (VAE) framework with a new type of prior which we call "Variational Mixture of Posteriors" prior, or VampPrior for short. The VampPrior consists of a mixture distribution (e.g., a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture with a coupled prior and posterior, learns significantly better models. The model also avoids the usual local optima issues related to useless latent dimensions that plague VAEs. We provide empirical studies on six datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes, Frey Faces and Histopathology patches, and show that applying the hierarchical VampPrior delivers state-of-the-art results on all datasets in the unsupervised permutation invariant setting and the best results or comparable to SOTA methods for the approach with convolutional networks.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\2579CNM5\\Tomczak and Welling - 2018 - VAE with a VampPrior.pdf;C\:\\Users\\Fab\\Zotero\\storage\\3UJFAZY3\\Tomczak and Welling - 2018 - VAE with a VampPrior.pdf}
}

@online{tschannenRecentAdvancesAutoencoderBased2018,
  title = {Recent {{Advances}} in {{Autoencoder-Based Representation Learning}}},
  author = {Tschannen, Michael and Bachem, Olivier and Lucic, Mario},
  date = {2018-12-12},
  eprint = {1812.05069},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1812.05069},
  url = {http://arxiv.org/abs/1812.05069},
  urldate = {2023-04-13},
  abstract = {Learning useful representations with little or no supervision is a key challenge in artificial intelligence. We provide an in-depth review of recent advances in representation learning with a focus on autoencoder-based models. To organize these results we make use of meta-priors believed useful for downstream tasks, such as disentanglement and hierarchical organization of features. In particular, we uncover three main mechanisms to enforce such properties, namely (i) regularizing the (approximate or aggregate) posterior distribution, (ii) factorizing the encoding and decoding distribution, or (iii) introducing a structured prior distribution. While there are some promising results, implicit or explicit supervision remains a key enabler and all current methods use strong inductive biases and modeling assumptions. Finally, we provide an analysis of autoencoder-based representation learning through the lens of rate-distortion theory and identify a clear tradeoff between the amount of prior knowledge available about the downstream tasks, and how useful the representation is for this task.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\DDUVT5AT\\Tschannen et al. - 2018 - Recent Advances in Autoencoder-Based Representatio.pdf;C\:\\Users\\Fab\\Zotero\\storage\\V2YIM77C\\1812.html}
}

@inproceedings{vahdatNVAEDeepHierarchical2020,
  title = {{{NVAE}}: {{A Deep Hierarchical Variational Autoencoder}}},
  shorttitle = {{{NVAE}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vahdat, Arash and Kautz, Jan},
  date = {2020},
  volume = {33},
  pages = {19667--19679},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/hash/e3b21256183cf7c2c7a66be163579d37-Abstract.html},
  urldate = {2023-05-22},
  abstract = {Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256x256 pixels. The source code is publicly available.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\2Z8KDF5D\\Vahdat and Kautz - 2020 - NVAE A Deep Hierarchical Variational Autoencoder.pdf}
}

@article{valiDeepLearningLand2020,
  title = {Deep {{Learning}} for {{Land Use}} and {{Land Cover Classification Based}} on {{Hyperspectral}} and {{Multispectral Earth Observation Data}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Land Use}} and {{Land Cover Classification Based}} on {{Hyperspectral}} and {{Multispectral Earth Observation Data}}},
  author = {Vali, Ava and Comai, Sara and Matteucci, Matteo},
  date = {2020-01},
  journaltitle = {Remote Sensing},
  volume = {12},
  number = {15},
  pages = {2495},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-4292},
  doi = {10.3390/rs12152495},
  url = {https://www.mdpi.com/2072-4292/12/15/2495},
  urldate = {2023-05-01},
  abstract = {Lately, with deep learning outpacing the other machine learning techniques in classifying images, we have witnessed a growing interest of the remote sensing community in employing these techniques for the land use and land cover classification based on multispectral and hyperspectral images; the number of related publications almost doubling each year since 2015 is an attest to that. The advances in remote sensing technologies, hence the fast-growing volume of timely data available at the global scale, offer new opportunities for a variety of applications. Deep learning being significantly successful in dealing with Big Data, seems to be a great candidate for exploiting the potentials of such complex massive data. However, there are some challenges related to the ground-truth, resolution, and the nature of data that strongly impact the performance of classification. In this paper, we review the use of deep learning in land use and land cover classification based on multispectral and hyperspectral images and we introduce the available data sources and datasets used by literature studies; we provide the readers with a framework to interpret the-state-of-the-art of deep learning in this context and offer a platform to approach methodologies, data, and challenges of the field.},
  issue = {15},
  langid = {english},
  keywords = {convolutional neural networks,data fusion,deep Learning,end-to-end learning,feature engineering,ground-truth scarcity,hyperspectral data,LULC classification,machine learning,multispectral data,remote sensing data},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\VJBFKY87\\Vali et al. - 2020 - Deep Learning for Land Use and Land Cover Classifi.pdf}
}

@inproceedings{verleysenCurseDimensionalityData2005,
  title = {The {{Curse}} of {{Dimensionality}} in {{Data Mining}} and {{Time Series Prediction}}},
  booktitle = {Computational {{Intelligence}} and {{Bioinspired Systems}}},
  author = {Verleysen, Michel and François, Damien},
  editor = {Cabestany, Joan and Prieto, Alberto and Sandoval, Francisco},
  date = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {758--770},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11494669_93},
  abstract = {Modern data analysis tools have to work on high-dimensional data, whose components are not independently distributed. High-dimensional spaces show surprising, counter-intuitive geometrical properties that have a large influence on the performances of data analysis tools. Among these properties, the concentration of the norm phenomenon results in the fact that Euclidean norms and Gaussian kernels, both commonly used in models, become inappropriate in high-dimensional spaces. This papers presents alternative distance measures and kernels, together with geometrical methods to decrease the dimension of the space. The methodology is applied to a typical time series prediction example.},
  isbn = {978-3-540-32106-4},
  langid = {english},
  keywords = {Data Analysis Tool,Gaussian Kernel,Norm Phenomenon,Stock Market Index,Time Series Prediction},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\5WN5758I\\Verleysen and François - 2005 - The Curse of Dimensionality in Data Mining and Tim.pdf}
}

@online{volodymyrkuleshovVariationalAutoencoder,
  title = {The Variational Auto-Encoder},
  author = {{Volodymyr Kuleshov} and {Stefano Ermon}},
  url = {https://ermongroup.github.io/cs228-notes/extras/vae/},
  urldate = {2023-05-04},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\JRDFV2QY\\vae.html}
}

@online{wangContrastVAEContrastiveVariational2022,
  title = {{{ContrastVAE}}: {{Contrastive Variational AutoEncoder}} for {{Sequential Recommendation}}},
  shorttitle = {{{ContrastVAE}}},
  author = {Wang, Yu and Zhang, Hengrui and Liu, Zhiwei and Yang, Liangwei and Yu, Philip S.},
  date = {2022-12-05},
  eprint = {2209.00456},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.00456},
  urldate = {2023-02-19},
  abstract = {Aiming at exploiting the rich information in user behaviour sequences, sequential recommendation has been widely adopted in real-world recommender systems. However, current methods suffer from the following issues: 1) sparsity of user-item interactions, 2) uncertainty of sequential records, 3) long-tail items. In this paper, we propose to incorporate contrastive learning into the framework of Variational AutoEncoders to address these challenges simultaneously. Firstly, we introduce ContrastELBO, a novel training objective that extends the conventional single-view ELBO to two-view case and theoretically builds a connection between VAE and contrastive learning from a two-view perspective. Then we propose Contrastive Variational AutoEncoder (ContrastVAE in short), a two-branched VAE model with contrastive regularization as an embodiment of ContrastELBO for sequential recommendation. We further introduce two simple yet effective augmentation strategies named model augmentation and variational augmentation to create a second view of a sequence and thus making contrastive learning possible. Experiments on four benchmark datasets demonstrate the effectiveness of ContrastVAE and the proposed augmentation methods. Codes are available at https://github.com/YuWang-1024/ContrastVAE},
  pubstate = {preprint},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\U6ZB8GPZ\\Wang et al. - 2022 - ContrastVAE Contrastive Variational AutoEncoder f.pdf;C\:\\Users\\Fab\\Zotero\\storage\\YDPKPFPL\\2209.html}
}

@inproceedings{weigendGeneralizationWeightEliminationApplication1990,
  title = {Generalization by {{Weight-Elimination}} with {{Application}} to {{Forecasting}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Weigend, Andreas and Rumelhart, David and Huberman, Bernardo},
  date = {1990},
  volume = {3},
  publisher = {{Morgan-Kaufmann}},
  url = {https://proceedings.neurips.cc/paper/1990/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html},
  urldate = {2023-05-27},
  abstract = {Inspired by the information theoretic idea of minimum description length, we add  a term  to the back propagation cost function that penalizes network complexity.  We  give  the  details  of the  procedure,  called  weight-elimination,  describe  its  dynamics, and clarify the meaning of the parameters involved. From a Bayesian  perspective,  the complexity term  can  be usefully interpreted as  an  assumption  about prior distribution of the weights.  We  use  this  procedure  to  predict  the  sunspot time series and the notoriously noisy series of currency exchange rates.},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\3TPRN39K\\Weigend et al. - 1990 - Generalization by Weight-Elimination with Applicat.pdf}
}

@article{weiIntegrationDomainKnowledgeGuided2021,
  title = {Towards {{Integration}} of {{Domain Knowledge-Guided Feature Engineering}} and {{Deep Feature Learning}} in {{Surface Electromyography-Based Hand Movement Recognition}}},
  author = {Wei, Wentao and Hu, Xuhui and Liu, Hua and Zhou, Ming and Song, Yan},
  date = {2021-12-29},
  journaltitle = {Computational Intelligence and Neuroscience},
  volume = {2021},
  pages = {e4454648},
  publisher = {{Hindawi}},
  issn = {1687-5265},
  doi = {10.1155/2021/4454648},
  url = {https://www.hindawi.com/journals/cin/2021/4454648/},
  urldate = {2023-05-01},
  abstract = {As a machine-learning-driven decision-making problem, the surface electromyography (sEMG)-based hand movement recognition is one of the key issues in robust control of noninvasive neural interfaces such as myoelectric prosthesis and rehabilitation robot. Despite the recent success in sEMG-based hand movement recognition using end-to-end deep feature learning technologies based on deep learning models, the performance of today’s sEMG-based hand movement recognition system is still limited by the noisy, random, and nonstationary nature of sEMG signals and researchers have come up with a number of methods that improve sEMG-based hand movement via feature engineering. Aiming at achieving higher sEMG-based hand movement recognition accuracies while enabling a trade-off between performance and computational complexity, this study proposed a progressive fusion network (PFNet) framework, which improves sEMG-based hand movement recognition via integration of domain knowledge-guided feature engineering and deep feature learning. In particular, it learns high-level feature representations from raw sEMG signals and engineered time-frequency domain features via a feature learning network and a domain knowledge network, respectively, and then employs a 3-stage progressive fusion strategy to progressively fuse the two networks together and obtain the final decisions. Extensive experiments were conducted on five sEMG datasets to evaluate our proposed PFNet, and the experimental results showed that the proposed PFNet could achieve the average hand movement recognition accuracies of 87.8\%, 85.4\%, 68.3\%, 71.7\%, and 90.3\% on the five datasets, respectively, which outperformed those achieved by the state of the arts.},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\IPFZQPXH\\Wei et al. - 2021 - Towards Integration of Domain Knowledge-Guided Fea.pdf}
}

@article{weiRecentAdvancesVariational2021,
  title = {Recent {{Advances}} in {{Variational Autoencoders With Representation Learning}} for {{Biomedical Informatics}}: {{A Survey}}},
  shorttitle = {Recent {{Advances}} in {{Variational Autoencoders With Representation Learning}} for {{Biomedical Informatics}}},
  author = {Wei, Ruoqi and Mahmood, Ausif},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {4939--4956},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3048309},
  abstract = {Variational autoencoders (VAEs) are deep latent space generative models that have been immensely successful in multiple exciting applications in biomedical informatics such as molecular design, protein design, medical image classification and segmentation, integrated multi-omics data analyses, and large-scale biological sequence analyses, among others. The fundamental idea in VAEs is to learn the distribution of data in such a way that new meaningful data with more intra-class variations can be generated from the encoded distribution. The ability of VAEs to synthesize new data with more representation variance at state-of-art levels provides hope that the chronic scarcity of labeled data in the biomedical field can be resolved. Furthermore, VAEs have made nonlinear latent variable models tractable for modeling complex distributions. This has allowed for efficient extraction of relevant biomedical information from learned features for biological data sets, referred to as unsupervised feature representation learning. In this article, we review the various recent advancements in the development and application of VAEs for biomedical informatics. We discuss challenges and future opportunities for biomedical research with respect to VAEs.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Bioinformatics,Biological system modeling,biomedical informatics,Data models,data representation,Decoding,Deep learning,generative models,latent space,Mathematical model,representation learning,Training,unsupervised learning,variational autoencoders (VAEs)},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\K3ZNRVJA\\Wei and Mahmood - 2021 - Recent Advances in Variational Autoencoders With R.pdf;C\:\\Users\\Fab\\Zotero\\storage\\6DB7RA94\\9311619.html}
}

@inproceedings{wuGreedyHierarchicalVariational2021,
  title = {Greedy {{Hierarchical Variational Autoencoders}} for {{Large-Scale Video Prediction}}},
  author = {Wu, Bohan and Nair, Suraj and Martin-Martin, Roberto and Fei-Fei, Li and Finn, Chelsea},
  date = {2021},
  pages = {2318--2328},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Greedy_Hierarchical_Variational_Autoencoders_for_Large-Scale_Video_Prediction_CVPR_2021_paper.html},
  urldate = {2023-05-22},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\8D3RCCDF\\Wu et al. - 2021 - Greedy Hierarchical Variational Autoencoders for L.pdf}
}

@article{wuImprovingInterpretabilityRegularization2018,
  title = {Improving {{Interpretability}} and {{Regularization}} in {{Deep Learning}}},
  author = {Wu, Chunyang and Gales, Mark J. F. and Ragni, Anton and Karanasou, Penny and Sim, Khe Chai},
  date = {2018-02},
  journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {26},
  number = {2},
  pages = {256--265},
  issn = {2329-9304},
  doi = {10.1109/TASLP.2017.2774919},
  abstract = {Deep learning approaches yield state-of-the-art performance in a range of tasks, including automatic speech recognition. However, the highly distributed representation in a deep neural network (DNN) or other network variations is difficult to analyze, making further parameter interpretation and regularization challenging. This paper presents a regularization scheme acting on the activation function output to improve the network interpretability and regularization. The proposed approach, referred to as activation regularization, encourages activation function outputs to satisfy a target pattern. By defining appropriate target patterns, different learning concepts can be imposed on the network. This method can aid network interpretability and also has the potential to reduce overfitting. The scheme is evaluated on several continuous speech recognition tasks: the Wall Street Journal continuous speech recognition task, eight conversational telephone speech tasks from the IARPA Babel program and a U.S. English broadcast news task. On all the tasks, the activation regularization achieved consistent performance gains over the standard DNN baselines.},
  eventtitle = {{{IEEE}}/{{ACM Transactions}} on {{Audio}}, {{Speech}}, and {{Language Processing}}},
  keywords = {Activation regularisation,deep learning,interpretability,neural network,Neural networks,Speech,Speech processing,Speech recognition,Training,Transforms,visualisation},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\9UMJCC7U\\Wu et al. - 2018 - Improving Interpretability and Regularization in D.pdf;C\:\\Users\\Fab\\Zotero\\storage\\T473AUHH\\8114209.html}
}

@inproceedings{yeInfoVAEGANLearningJoint2021,
  title = {{{InfoVAEGAN}}: {{Learning Joint Interpretable Representations}} by {{Information Maximization}} and {{Maximum Likelihood}}},
  shorttitle = {{{InfoVAEGAN}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Ye, Fei and Bors, Adrian G.},
  date = {2021-09},
  pages = {749--753},
  issn = {2381-8549},
  doi = {10.1109/ICIP42928.2021.9506169},
  abstract = {Learning disentangled and interpretable representations is an important step towards accomplishing comprehensive data representations on the manifold. In this paper, we propose a novel representation learning algorithm which combines the inference abilities of Variational Autoencoders (VAE) with the generalization capability of Generative Adversarial Networks (GAN). The proposed model, called InfoVAEGAN, consists of three networks: Encoder, Generator and Discriminator. InfoVAEGAN aims to jointly learn discrete and continuous interpretable representations in an unsupervised manner by using two different data-free log-likelihood functions onto the variables sampled from the generator’s distribution. We propose a two-stage algorithm for optimizing the inference network separately from the generator training. Moreover, we enforce the learning of interpretable representations through the maximization of the mutual information between the existing latent variables and those created through generative and inference processes.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  keywords = {Disentangled representations,Generative adversarial networks,Generators,Hybrid VAE-GAN generative models,Inference algorithms,Inference mechanisms,Manifolds,Mutual information,Tools,Training},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\KAIZD6X6\\Ye and Bors - 2021 - InfoVAEGAN Learning Joint Interpretable Represent.pdf;C\:\\Users\\Fab\\Zotero\\storage\\PNITGTEZ\\9506169.html}
}

@article{yuanBridgeGANInterpretableRepresentation2020,
  title = {Bridge-{{GAN}}: {{Interpretable Representation Learning}} for {{Text-to-Image Synthesis}}},
  shorttitle = {Bridge-{{GAN}}},
  author = {Yuan, Mingkuan and Peng, Yuxin},
  date = {2020-11},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {30},
  number = {11},
  pages = {4258--4268},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2019.2953753},
  abstract = {Text-to-image synthesis is to generate images with the consistent content as the given text description, which is a highly challenging task with two main issues: visual reality and content consistency. Recently, it is available to generate images with high visual reality due to the significant progress of generative adversarial networks. However, translating text description to image with high content consistency is still ambitious. For addressing the above issues, it is reasonable to establish a transitional space with interpretable representation as a bridge to associate text and image. So we propose a text-to-image synthesis approach named Bridge-like Generative Adversarial Networks (Bridge-GAN). Its main contributions are: (1) A transitional space is established as a bridge for improving content consistency, where the interpretable representation can be learned by guaranteeing the key visual information from given text descriptions. (2) A ternary mutual information objective is designed for optimizing the transitional space and enhancing both the visual reality and content consistency. It is proposed under the goal to disentangle the latent factors conditioned on text description for further interpretable representation learning. Comprehensive experiments on two widely-used datasets verify the effectiveness of our Bridge-GAN with the best performance.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems}} for {{Video Technology}}},
  keywords = {Bridge circuits,Bridge-GAN,Image synthesis,interpretable representation learning,Mutual information,Semantics,Task analysis,Text-to-image synthesis,Training,Visualization},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\GAGWYLD9\\Yuan and Peng - 2020 - Bridge-GAN Interpretable Representation Learning .pdf;C\:\\Users\\Fab\\Zotero\\storage\\CP52ACI5\\8902154.html}
}

@incollection{zhangArtificialNeuralNetwork2018,
  title = {Artificial {{Neural Network}}},
  booktitle = {Multivariate {{Time Series Analysis}} in {{Climate}} and {{Environmental Research}}},
  author = {Zhang, Zhihua},
  editor = {Zhang, Zhihua},
  date = {2018},
  pages = {1--35},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-67340-0_1},
  url = {https://doi.org/10.1007/978-3-319-67340-0\_1},
  urldate = {2023-05-01},
  abstract = {Multivariate time series analysis in climate and environmental research always requires to process huge amount of data. Inspired by human nervous system, the artificial neural network methodology is a powerful tool to handle this kind of difficult and challenge problems and has been widely used to investigate mechanism of climate change and predict the climate change trend. The main advantage is that artificial neural networks make full use of some unknown information hidden in climate data although they cannot extract it. In this chapter, we will introduce various neural networks, including linear networks, radial basis function networks, generalized regression networks, Kohonen self-organizing networks, learning vector quantization networks, and Hopfield networks.},
  isbn = {978-3-319-67340-0},
  langid = {english},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\T876TTZJ\\Zhang - 2018 - Artificial Neural Network.pdf}
}

@article{zhangOmiEmbedUnifiedMultiTask2021,
  title = {{{OmiEmbed}}: {{A Unified Multi-Task Deep Learning Framework}} for {{Multi-Omics Data}}},
  shorttitle = {{{OmiEmbed}}},
  author = {Zhang, Xiaoyu and Xing, Yuting and Sun, Kai and Guo, Yike},
  date = {2021-01},
  journaltitle = {Cancers},
  volume = {13},
  number = {12},
  pages = {3047},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-6694},
  doi = {10.3390/cancers13123047},
  url = {https://www.mdpi.com/2072-6694/13/12/3047},
  urldate = {2023-05-02},
  abstract = {High-dimensional omics data contain intrinsic biomedical information that is crucial for personalised medicine. Nevertheless, it is challenging to capture them from the genome-wide data, due to the large number of molecular features and small number of available samples, which is also called “the curse of dimensionality” in machine learning. To tackle this problem and pave the way for machine learning-aided precision medicine, we proposed a unified multi-task deep learning framework named OmiEmbed to capture biomedical information from high-dimensional omics data with the deep embedding and downstream task modules. The deep embedding module learnt an omics embedding that mapped multiple omics data types into a latent space with lower dimensionality. Based on the new representation of multi-omics data, different downstream task modules were trained simultaneously and efficiently with the multi-task strategy to predict the comprehensive phenotype profile of each sample. OmiEmbed supports multiple tasks for omics data including dimensionality reduction, tumour type classification, multi-omics integration, demographic and clinical feature reconstruction, and survival prediction. The framework outperformed other methods on all three types of downstream tasks and achieved better performance with the multi-task strategy compared to training them individually. OmiEmbed is a powerful and unified framework that can be widely adapted to various applications of high-dimensional omics data and has great potential to facilitate more accurate and personalised clinical decision making.},
  issue = {12},
  langid = {english},
  keywords = {cancer classification,deep learning,multi-omics data,multi-task learning,survival prediction},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\TUZKG7PV\\Zhang et al. - 2021 - OmiEmbed A Unified Multi-Task Deep Learning Frame.pdf}
}

@article{zhangSlowFeatureAnalysis2012,
  title = {Slow {{Feature Analysis}} for {{Human Action Recognition}}},
  author = {Zhang, Zhang and Tao, Dacheng},
  date = {2012-03},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {34},
  number = {3},
  pages = {436--450},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2011.157},
  abstract = {Slow Feature Analysis (SFA) extracts slowly varying features from a quickly varying input signal [1]. It has been successfully applied to modeling the visual receptive fields of the cortical neurons. Sufficient experimental results in neuroscience suggest that the temporal slowness principle is a general learning principle in visual perception. In this paper, we introduce the SFA framework to the problem of human action recognition by incorporating the discriminative information with SFA learning and considering the spatial relationship of body parts. In particular, we consider four kinds of SFA learning strategies, including the original unsupervised SFA (U-SFA), the supervised SFA (S-SFA), the discriminative SFA (D-SFA), and the spatial discriminative SFA (SD–SFA), to extract slow feature functions from a large amount of training cuboids which are obtained by random sampling in motion boundaries. Afterward, to represent action sequences, the squared first order temporal derivatives are accumulated over all transformed cuboids into one feature vector, which is termed the Accumulated Squared Derivative (ASD) feature. The ASD feature encodes the statistical distribution of slow features in an action sequence. Finally, a linear support vector machine (SVM) is trained to classify actions represented by ASD features. We conduct extensive experiments, including two sets of control experiments, two sets of large scale experiments on the KTH and Weizmann databases, and two sets of experiments on the CASIA and UT-interaction databases, to demonstrate the effectiveness of SFA for human action recognition. Experimental results suggest that the SFA-based approach (1) is able to extract useful motion patterns and improves the recognition performance, (2) requires less intermediate processing steps but achieves comparable or even better performance, and (3) has good potential to recognize complex multiperson activities.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Feature extraction,Human action recognition,Humans,Neurons,Pattern recognition,slow feature analysis.,Spatiotemporal phenomena,Vectors,Visualization},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\NQBMBLMJ\\Zhang and Tao - 2012 - Slow Feature Analysis for Human Action Recognition.pdf;C\:\\Users\\Fab\\Zotero\\storage\\RCB6IWT4\\6136516.html}
}

@book{zhengFeatureEngineeringMachine2018,
  title = {Feature {{Engineering}} for {{Machine Learning}}: {{Principles}} and {{Techniques}} for {{Data Scientists}}},
  shorttitle = {Feature {{Engineering}} for {{Machine Learning}}},
  author = {Zheng, Alice and Casari, Amanda},
  date = {2018-03-23},
  eprint = {sthSDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{"O'Reilly Media, Inc."}},
  abstract = {Feature engineering is a crucial step in the machine-learning pipeline, yet this topic is rarely examined on its own. With this practical book, you’ll learn techniques for extracting and transforming features—the numeric representations of raw data—into formats for machine-learning models. Each chapter guides you through a single data problem, such as how to represent text or image data. Together, these examples illustrate the main principles of feature engineering.Rather than simply teach these principles, authors Alice Zheng and Amanda Casari focus on practical application with exercises throughout the book. The closing chapter brings everything together by tackling a real-world, structured dataset with several feature-engineering techniques. Python packages including numpy, Pandas, Scikit-learn, and Matplotlib are used in code examples.You’ll examine:Feature engineering for numeric data: filtering, binning, scaling, log transforms, and power transformsNatural text techniques: bag-of-words, n-grams, and phrase detectionFrequency-based filtering and feature scaling for eliminating uninformative featuresEncoding techniques of categorical variables, including feature hashing and bin-countingModel-based feature engineering with principal component analysisThe concept of model stacking, using k-means as a featurization techniqueImage feature extraction with manual and deep-learning techniques},
  isbn = {978-1-4919-5319-8},
  langid = {english},
  pagetotal = {245},
  keywords = {Computers / Data Science / Data Analytics,Computers / Data Science / Data Modeling \& Design,Computers / Data Science / Data Warehousing,Computers / Data Science / General,Computers / Database Administration \& Management}
}

@article{zhouVisuallyInterpretableRepresentation2020,
  title = {Visually {{Interpretable Representation Learning}} for {{Depression Recognition}} from {{Facial Images}}},
  author = {Zhou, Xiuzhuang and Jin, Kai and Shang, Yuanyuan and Guo, Guodong},
  date = {2020-07},
  journaltitle = {IEEE Transactions on Affective Computing},
  volume = {11},
  number = {3},
  pages = {542--552},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2018.2828819},
  abstract = {Recent evidence in mental health assessment have demonstrated that facial appearance could be highly indicative of depressive disorder. While previous methods based on the facial analysis promise to advance clinical diagnosis of depressive disorder in a more efficient and objective manner, challenges in visual representation of complex depression pattern prevent widespread practice of automated depression diagnosis. In this paper, we present a deep regression network termed DepressNet to learn a depression representation with visual explanation. Specifically, a deep convolutional neural network equipped with a global average pooling layer is first trained with facial depression data, which allows for identifying salient regions of input image in terms of its severity score based on the generated depression activation map (DAM). We then propose a multi-region DepressNet, with which multiple local deep regression models for different face regions are jointly leaned and their responses are fused to improve the overall recognition performance. We evaluate our method on two benchmark datasets, and the results show that our method significantly boosts state-of-the-art performance of the visual-based depression recognition. Most importantly, the DAM induced by our learned deep model may help reveal the visual depression pattern on faces and understand the insights of automated depression diagnosis.},
  eventtitle = {{{IEEE Transactions}} on {{Affective Computing}}},
  keywords = {Computer architecture,deep convolutional neural network,depression activation map,Depression recognition,Face,face recognition,Face recognition,Feature extraction,Image recognition,Videos,Visualization},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\N2B8BAMH\\Zhou et al. - 2020 - Visually Interpretable Representation Learning for.pdf;C\:\\Users\\Fab\\Zotero\\storage\\YD2SGVUC\\8344107.html}
}

@article{zouConvolutionalNeuralNetwork2018,
  title = {Convolutional Neural Network Simplification via Feature Map Pruning},
  author = {Zou, Junhua and Rui, Ting and Zhou, You and Yang, Chengsong and Zhang, Sai},
  date = {2018-08-01},
  journaltitle = {Computers \& Electrical Engineering},
  shortjournal = {Computers \& Electrical Engineering},
  volume = {70},
  pages = {950--958},
  issn = {0045-7906},
  doi = {10.1016/j.compeleceng.2018.01.036},
  url = {https://www.sciencedirect.com/science/article/pii/S0045790617326393},
  urldate = {2022-11-05},
  abstract = {Convolutional neural networks (CNNs) have been a focus area of machine learning in recent years, and they are widely used in vision and speech processing because of their superior performance. However, CNNs are usually resource-heavy to ensure higher accuracy, i.e., an accurate network with millions of parameters requires high performance computing devices. This prevents the use of CNNs in resource-limited hardware. In this paper, we propose a novel CNN simplification method to prune feature maps with relatively low discriminability magnitudes, which can produce a simplified CNN with reduced computational cost. Specifically, we define the critical points among the discriminability values of feature maps in each convolutional layer, and use these critical points to easily find the best pruning number of feature maps. Our experimental results show that in each convolutional layer of the VGG model, 15.6\% to 59.7\% of feature maps can be pruned without any loss of accuracy in classification tasks.},
  langid = {english},
  keywords = {Convolutional neural network,Critical points,Discriminability,Feature maps pruning},
  file = {C\:\\Users\\Fab\\Zotero\\storage\\P9ZINAV9\\S0045790617326393.html}
}
