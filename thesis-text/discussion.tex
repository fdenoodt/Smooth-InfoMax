\chapter{Conclusion and Future work} \label{cha:6}
% scribbr:
% Step 1: Summarize your key findings
% Step 2: Give your interpretations (on results)
% Step 3: Discuss the implications
	% link met literature, bv kl divergence geeft veel useless dimensions (is same as literature)
% Step 4: Acknowledge the limitations
% Step 5: Share your recommendations
	% = future work, eventueel gericht op die limitaties.

	
In this thesis, we introduced V-GIM, a self-supervised approach for interpretable representation learning using mutual information (MI) maximisation. In this chapter, we provide a discussion of V-GIM's results with respect to its interpretability. We discuss its limitations and make recommendations for plausible future work. Finally, we conclude this thesis with a summary of our main findings.

%% why interpretable: chat gpt wou dat niet
%V-GIM's interpretability is achieved by defining latent representations as samples from Gaussian distributions which are optimised to be similar to the standard normal. As such, the dataset will cover the entire latent space around the origin, such that sampling a random point from this space is likely to result in a data point that is similar to the data. 



\section{Representation analysis}
	
	% no b, wel a
	We analysed V-GIM's representations using t-SNE plots, linear classifiers, and decoders trained on top of V-GIM's representations. We observed that the representations contained vowel information but lacked consonant information. This was observed in both the t-SNE plots and the linear classifier results. We suggest that this is related to the duration of the phonemes. The InfoNCE objective, from which our loss function is derived, maximises the MI between temporally nearby patches, assuming the presence of common information in nearby data. However, the vowels in the dataset are typically pronounced for longer duration than the consonants, and thus, representations where a consonant is being pronounced have less information in common with nearby representations as in those representations the consonant may not be pronounced any more. These findings align with \cite{lowePuttingEndEndtoEnd2020a} who suggested that optimisation of the InfoNCE objective favours global information over local information. 
	
	The decoder provided insights into the speech information that remained in the representations. While the pronounced sounds were generally recognisable, the decoder occasionally generated incorrect consonants, for instance by producing the sound ``ba" when the original sound was ``ga". This further supports our findings that the representations contain less consonant information. Additionally, the pronounced sounds were recognisable but sounded distorted. It seemed that information that was not related to the identity of phonemes (for instance related to the identity of the speaker) was almost entirely lost. This suggests that (among others) features needed for speaker identification may no longer be present in the representations. 
	
	Interestingly, the vowel information was found to be concentrated in only a small subset of dimensions. This was observed in the vowel experiment, where a linear classifier trained on V-GIM's first module achieved high accuracies by assigning high weights to a few dimensions, while the majority of weights were close to zero, indicating that those dimensions did not contribute to the prediction. This suggests that the size of representations could be further reduced by removing dimensions that did not contribute to the task. Some of these dimensions likely carry different information, while others may be completely useless.
		
	% why useless dimensions appear
	We attribute the presence of useless dimensions in V-GIM's representations to the KL divergence term in the $\Lvnce$ loss function (see section \ref{cha:vgim_learning_objective}). The histogram plots (see section \ref{cha:distributions}) revealed that some dimensions' distributions were nearly identical to the standard normal distribution, while others showed more variation. We assume that the dimensions with more variation most likely carry all the actual information and contribute to a good InfoNCE bound, while the identical dimensions do not carry any useful information but help maintain a low KL divergence.
	
			
	% diff priors
	This problem of useless dimensions is also known in VAEs and can be mitigated by choosing different priors or posteriors. For instance, VampPrior addresses this problem by using a mixture of Gaussians as prior instead of the typical standard normal \citep{tomczakVAEVampPrior2018}. Further work could explore alternative priors introduced to VAEs which we discussed in section \ref{cha:rel_alt_priors}, and investigate their performance in V-GIM. Alternatively, the problem of useless dimensions could potentially be mitigated by introducing a regularisation term applied to the weights of the similarity score function $\fkm$, which would enforce similar weights between different dimensions. This regularisation would encourage each dimension to contribute an equal amount of information.
	
	% disentanglement
	With regards to representation disentanglement, \cite{burgessUnderstandingDisentanglingBeta2018} argue that choosing a standard normal prior in VAEs encourages disentangled representations. Similarly, V-GIM also utilises a standard normal prior, and its impact concerning disentanglement should be further investigated in future work.
	
	
	% V-GIM enables interpretability of internal representations as well, potentially enabling to understand the network

	Continuing with the interpretability analysis, V-GIM's regularisation term ensures that sampling a random point in the latent space around the origin will likely result in a point that is similar to the original data. Since the training set covers the entire space around the origin, a decoder trained on this space will likely generalise well to unseen data around the origin. Therefore, the interpolation experiment allowed us to investigate what exact information was contained in each dimension in each of V-GIM's modules. 
	
	We discovered three categories: dimensions containing information from one or two specific frequency bins, dimensions containing information spanning a range of frequency bins, and dimensions containing no information at all. Most dimensions were active around the 100 Hz to 200 Hz frequency range, similar to the pitch of a male voice \citep{rePreferencesVeryLow2012}.
	
	% towards true XAI
	While our work focused on understanding V-GIM's representations for two modules, achieving true explainable AI requires understanding not only the model's outputs but also how it obtained its outputs. V-GIM could serve as an initial step in this direction by defining each layer as a module, allowing for a better understanding of each activation in the network. Further research could explore the associated weights between modules to gain further insights into the model's internal workings.

\section{Performance and Representation Variability} 
	% v-gim = gim performance
	The syllable classifier (see section \ref{cha:exper_classifier}) provided insights into V-GIM's performance, which we compared to GIM. Overall, V-GIM's performance is similar to GIM, indicating that the additional regularisation term resulting in better interpretable representations, does not harm performance significantly.
	
	% gim/cpc better in org paper
	However, results were mediocre for both GIM and V-GIM, obtaining test accuracies around 51\% and 54\% for 9 classes, with performance further decreasing in the deeper modules. Meanwhile, \cite{oordRepresentationLearningContrastive2019} and \cite{lowePuttingEndEndtoEnd2020a} observed better performance in their papers for a similar speech recognition problem, for phoneme classification on the LibriSpeech dataset. In particular, \citeauthor{lowePuttingEndEndtoEnd2020a} obtained an accuracy of 73.4\% with GIM and 64.9\% with CPC.
	
	% why: wij langere tijds duratie is kleinere representatie
	We attribute this performance discrepancy to the captured speech duration that each representation captures. \citeauthor{lowePuttingEndEndtoEnd2020a} and \citeauthor{oordRepresentationLearningContrastive2019} make use of the same architecture where representations capture smaller speech durations compared to our architecture. Their representations must thus summarise less information, while also having more capacity to do so, having a total of 512 dimensions per representation rather than 32 as is in our case. As our primary focus was to understand the models underlying representations, rather than obtain state-of-the-art performance, we accepted this loss in performance.
	
	In addition to the more restricted capacity of our representations, the nature of the sequential data also plays a major role in the performance. In particular, MI maximising using the InfoNCE objective requires the presence of common information between the temporally nearby patches of data. However, as the window length increases of individual representations in the deeper convolutional layers, there may be less common information in the nearby patches for the InfoNCE objective to capitalise on. For instance, consider a speech wave where the syllable ``ba" is pronounced. This syllable contains two building blocks, the ``b" and the ``a". If this syllable would be represented by exactly two
	representations, one representation capturing the time window where the ``b" is being pronounced, and the second for the ``a", then these windows no longer have the same pronounced phoneme in common. Consequently, since the InfoNCE objective aims to preserve the common information between these windows and considers inconsistencies as noise, their representations will no longer contain information on the pronounced phoneme. This is observed in the decreased performance of the deeper modules, where deeper representations must encode a longer speech windows. The extent to which sequential data can be downscaled is thus dependent on the amount of MI between the patches.
	
	% batch norm, we do better
	While performance decreases in the deeper modules due to limited MI, V-GIM significantly outperforms GIM in the syllable experiment within the second module. V-GIM achieves a test accuracy of 41\%, compared to GIM's 28\%. We hypothesise this is related to V-GIM's internal batch normalisation mechanism between modules, thus preventing internal covariate shift from occurring between modules. Meanwhile, GIM does not have any normalisation in between modules, resulting in successive modules not being able to catch up with the changes from the predeceasing modules. While this problem did not become apparent for \citeauthor{lowePuttingEndEndtoEnd2020a}, we argue that this is related to the smaller learning rate and restricted architecture depths which consist of a single layer per module, and thus is less punished by internal covariate shift.
			
	Furthermore, V-GIM's representation variability could potentially provide a generalisation benefit for downstream tasks when little labelled data is available, as the distributions limit the number of plausible decision boundaries that can separate the data. However, the linear classifiers trained on a smaller subset of the labelled data did not seem to benefit from this variability and obtained similar performance to those trained with GIM's representations (see section \ref{cha:generalisation_study}). 
	
	One hypothesis is that the classifiers are optimised using the cross entropy loss function and therefore, may behave similarly to Support Vector Machines (SVM). SVMs can filter out a large amount of the plausible decision boundaries by selecting the boundary that maximises the margin between the classes \citep{hearstSupportVectorMachines1998, nobleWhatSupportVector2006}. As a result, V-GIM's restrictions on the number of decision boundaries do not make a significant contribution to better generalisation, as many potential decision boundaries that would separate the data are already eliminated. At this moment, this is only a conjecture and should be investigated more thoroughly in future work. Additionally, alternative downstream tasks learned with V-GIM's representations should be investigated as well. Different learning algorithms such as the Perceptron Learning Algorithm (PLA) could potentially find better value in V-GIM's representations compared to GIM's representations. These findings would not only be interesting for V-GIM but also for VAEs.
	
	% quantised learning
	Another interesting research line would be in quantised learning, which aims to make ANNs more efficient and less memory expensive by making use of reduced-precision representations for the weights and activations in the network \cite{blottFINNREndtoEndDeepLearning2018}. However, this reduced precision results in more zero gradients as gradients approaching zero have less precision to differentiate themselves from an actual value of zero. Quantised learning is therefore even more susceptible to the vanishing gradient problem \citep{kimDistanceawareQuantization2021}. V-GIM could potentially provide a solution to this problem. In V-GIM, modules are trained greedily and gradients do not flow between modules. This makes V-GIM less prone to vanishing gradients, as discussed by \cite{lowePuttingEndEndtoEnd2020a}. Future work should investigate quantised learning with V-GIM further, as it could offer a solution to obtain the benefits from quantised learning without being affected by the drawbacks.
	
	
	Finally, V-GIM's regularisation term pulls data points in the latent space close to the centre. The distance from the origin could potentially be used as a reliability score. For example, when V-GIM applies inference on new data, values far from the centre could potentially be flagged as outliers, providing indications of data that the model cannot generalise well to. Future work could incorporate this information using outlier detectors, offering solutions for continuous training methodologies in a production environment.
		


		
		
		
		

		
	%		
	%		 
	%		
	%		We hypothesise that the generalisation benefit from representation learning may be dependent on the learning algorithm used for the downstream tasks. Although our classifiers optimised using cross entropy did not 
	%		
	%		
	%		% miss is onze classifier ding meer zoals SVM
	%		The experiment was done using a linear classifier optimised with the cross entropy loss, 
	%		
	%		V-GIM 
	%		 However more research should be done to be certain. We hypthesise the linear classifier we used which optimises CE, may internally do something similar to SVM where it already finds the best boundary without the need for the additional informration. However, alternative information could potentially benefit from this infused information resulting in a smaller set of plausible decision boundaries, hence improving generalisaiton.
	%		
	%		One theory is that CE optimisation behaves similarly to SVM and in fact maximises the boundary between the classes.
		
		
		
		%		While optimisation algorithms such as SVM aim to maximise the margin between classes, simpler algorthms such as the perceptron learning algorithm (PLA) simply attempt to find a boundary which separates the classes without attempting to find the ``best" separation. The representation variance could potentially infuse information on the  
		%		 such that the representation variance
		%		The classifier was trained to optimise the Cross Entropy loss,
		%		
		%		Further work should investigate this theorem in more detail in more detail. It is not only applicable to V-GIM, but also VAE.
		%		
		%and compare which algorithms may benefit from the representation variability and which ones do not
		 
		
%		% repr variability:	
%		- didn't observe a benefit from variation variance, even for the smallest subset sizes.
%		- We hypothesised representation variance, resulting in more data points could improve the decision boundary, encouraging the boundary to be similar as to SVM, where distance is maximised for each point.
%		- Taking inspiration from SVM's decision boundary, we investigated whether V-GIM's representation could offer a similar approach for alternative downstream tasks, is a potential 
%		- encourage a better boundary, similar to SVM's \citep{hearstSupportVectorMachines1998, nobleWhatSupportVector2006}, maximising the margin between classes.
%		--> didn't seem the case.
%		- explanation on why should be further investigated. One hypothesis is related to SVM's ...
%		% Should do more research in this, potentially certain algorithms such as PLA can strongly benefit from this. \citep{gallantPerceptronbasedLearningAlgorithms1990}
%		
	
		
		% why GIM/CPC better performance (summarise less, so more MI between representations)
		
		%We believe this is related to the size of individual representations, as they have 512 rather than 32 as in our work. Additionally, our representations capture longer time sequences and have a smaller resulting in potentially less mutual information between temporally nearby patches. Due to computational constraints, and since our primary concern was to analyse these representations, we maintained our own architecture where representations contain longer time frames.
		
		% performance is worse in second module, further attributed to less mutual information.
		% cpc/gim better because doesn't downscale any further. shows that there is a limit on how much information is gone, as lowe says: favours global information, so the larger we summarise the details we lose
		% how much sequential data can be downscaled is thus dependent on the amount of mutual information.
		
		
		

			%Since, our representations capture longer time sequences, the InfoNCE objective must maximise the mutual information with the successive representations which are further away and thus have less information in common, as the speech wave corresponding to future representations may be pronouncing other phonemes, hence no longer having this information in common.
		

		
		% further seen in deeper modules, which capture longer speech durations. Perforce further decreases, indicating that there is no longer enough common information in the nearby data.
	
		
		
		%[TODO]
		% performance afhankelijk van hoeveel informatie gedeeld is. als representaties zeer grote time frames moeten capturen, is dat enkel mogelijk als er voldoende gemeenschappelijke informatie is met de opvolgende time frames.
		%		Additionally, we observed performance further decreased in future modules, indicating that the speech waves of temporally nearby representations may no longer have as much common information. This demonstrates that speech waves can only be reduces in size to a certain extend without hurting performance. If further dimensionality reduction is required, we propose to explore the addition of sparse networks.
			% how much sequential data can be downscaled is thus dependent on the amount of mutual information.
			
			
	
	
		
		



	
	
	
%\section{memory}
%		- while V-GIM's greedy approach allows for distributed learning, enabling training on resource constraint devices. each module has a memory overhead due to the similarity score fkm, causing the combined memory requirements to be higher.
%		- while GIM argues to resolve memory constraints, not entirely true. In fact we even countered the opposite as containing multiple neural networks, each with their own personal loss function (the loss function is based on fk which contains parameters that must be learned), and thus for early layers where the sequence is still long, a lot of memory is required. We went for a compromise on GIM by splitting up the architecture in merely two modules, significantly reducing the memory constraints.
%	








%-- 
%decaying learing rate:
%we train using decaying lr, because models must first learn distributions and goes too slow if lr is too small.
%and a learning rate scheduler
%ExponentialLR
%decay rate 0.995
%
%---








%---
%The second module in GIM clearly doesn't have as much effect. This can be explained because there may not be as much common information anymore between the patches. There may be a source that says that cpc learns low level features, but the second module is supposed to learn more high level features, which cpc may have trouble with?
%---
%
%Future work:
%- Related work in VAE shows that gradually increasing regularisation term, results in better disentengledment, while avoiding posterior collapse. could have a kldweight scheduler.
%
%- not constrained solely to InfoNCE loss, the GIM architecture could work for other losses too that allow for greedy optimisation.
%
%
%- I didn't add an autoregressor as i didn't find a performance benefit. Potentially, with larger architecture could further improve performance.
%
%
%
%----
%Towards production setting:
%encodings are thus optimised to be close the standard normal. When in a production environment and new data is given, could in fact have an idea of how well generalisation to the production data: eg via anomaly detection if encodings are too far away from center. 
%= gives automated way of verifying generalisation.
%
%can then maybe see to which data that doesn't generalise well via outliers.
%
%----
%
%
%future work:
%- disentanglement should do more investations
%
%
%---
%GIM: Modular training
%could incrementally increase numb of modules and observe performance increase for downstream tasks.
%based on this, could find smallest gim architecture depth which satisfies required accuracies.
%
%----
%interpretability:
%most dimensions sensitive around 75 to 150 hz. this is as expected as the adult man speaks around 80 to 180 hz.
%
%---
%interpretability is only as good as the decoder. if a shitty decoder doesn't construct well, doesn't necessarily give correct conclusions about V-GIM.
%
%
%---
%Future work: alternatieve prior (zie related work.)
%
%
%
%
%
%
%\begin{itemize}
%	\item Explainability of latents is dependent on the performance of the decoder.
%	\item Intermediate loss function with kld resulted in similar behaviour as batch normalisation. Resulting in faster convergence than without kld.
%	\item We observed no quality loss in the learned representations. Data was equally easily separable.
%\end{itemize}















% ------------------------
% *************
%van interpretability section:
	%. Consequently, if activations are understandable, understanding the exact weights may become more feasible as only a single layer must be analysed at a time.

%	In the interpolation study, decoders were trained on each of V-GIM's modules, providing us with insights in the contained information of each dimension. We discovered three categories: dimensions containing information of one or two specific frequency bins, dimensions containing information spanning an entire range of frequency bins, and dimensions containing no information at all, we call these the useless dimensions. Most dimensions were active around the 100Hz to 200Hz frequency range, which is similar to the pitch of a male voice.
%	
%	
%
%	further work, could take to more extremes a single module per layer such that each layer can be analyses and then potentially also the weights.







% disclaimer: decoder only works on V-GIM, not GIM.
%	It is noteworthy that insights obtained from decoder only viable because of V-GIM's regularisation term, and not in regularisation-free MI maximisation techniques such as CPC and V-GIM.
%	

%Additionally, the addition of an optional decoder provided benefits over encoder-decoder architectures, as the decoder was not required for training, providing more available memory for more complex architectures.

%	Additionally, V-GIM's module architecture enables the observation of interpretable activations in between the network as well. Further work could investigate these internal representations further, so not only do we have the means to understand the final representations, as X, Y, we even have the means to understand internal, potentially giving even better insights in how neural networks operate. While other representation learning techniques, x,y,z claim interpretable representations, V-GIM's representations are interpretable, but additionally provide insights in the internal mechanism of the network as well.

%	Note that:
%		Interpretability analysis gives insight in information that is available, but making claims on what information is not included is harder, as could be that decoder didn't see it. interpretability analysis gives insight in information that is available, but making claims on what information is not included is harder, as could be that decoder didn't see it. 

%	 	- some dimensions were very nicely Gaussian shaped while others were not, indicating that optimisation function could potentially maintain useless dimensions to keep up good cost function, while containing all information. So V-GIM exploits loss function, not necessarly learning as we expect.
%	 	- test alternative priors van VAE
%		 - test disentanglement


%By encoding each data point to its latent representation and creating a histogram for of the representations per dimension, we observed that V-GIM does indeed enforce each dimension to be standard normal, indicating that implications with respect to interpretability using the decoder are indeed applicable. 


\section{Final Conclusion}

%can we improve interpretability of learning approaches through incorporating explainability requirements into the network, for CPC.

We introduced Variational Greedy InfoMax, a self-supervised representation learning approach which incorporates interpretability requirements into the design of the network. This approach enables the analysis of the internal representations through a decoder, ensuring that the decodings are not only meaningful but also that we can use them to gain valuable insights into the underlying structure these representations.



In particular, we found that V-GIM learned internal representations which were sensitive to specific vowels, while consonant information was lacking. Furthermore, individual dimensions in the representations captured information on specific frequency bins or entire neighbourhoods of frequency bins. Meanwhile, certain dimensions did not appear to contain any information at all. This shows that the individual concepts that neurons are sensitive to, can be observed for both the output neurons but also the internal neurons, enabling us to better understand these networks internally, by observing the internal mechanisms these networks have learned.

In addition to the interpretability benefits, V-GIM's greedy learning approach combined with the constraints applied to the latent space of each module, results in an internal batch normalisation mechanism. This mechanism, leads to improved performance of the deeper modules, outperforming V-GIM's non-variational counterpart, Greedy InfoMax.

However, it is important to note that the representation variability obtained from V-GIM's stochastic representations does not appear to improve the performance of downstream tasks in scenarios where labelled data is scarce. Future work should investigate this in more detail, as these findings could potentially be attributed to the nature of the downstream task rather than the quality of the representations themselves.

%
%V-GIM enables easier analysis of the model through post-hoc explainability approaches, for instance, through a decoder.


% *** FOR INTRODUCTION OR ABSTRACT? ***
% V-GIM's latent space constraints ensure that a decoder trained on this space would generalise well to unseen data and predict new data points similar to the dataset, improving interpretability of reconstructions, allowing for meaningful interpolations between representations.

% vgims latent space constraint ensures that sampling a random point from a standard normal distribution is likely to correspond to a meaningful data point in the original space. As such, decoding the interpolation of two latent representations is more likely to result into a meaningful reconstruction, improving interpretability obtained form the decoder.


% (and ensure that the data corresponding to high neuron activations correspond to data points that are similar to the dataset)






%- results:
%	- found individual channels that were sensitive for specific to phonemes, a, u i ... meanwhile consonant information no longer seemed to be maintained in the representations.
%	- additionally certain dimensions were sensitive to frequencies
%	
%	-In addition, V-GIM's split up architecture resulted in other benefits such as an internal batch normalisation layer
%	
%	- meanwhile the representation variability in V-GIM's stochastic representations does not appear to improve performance of downstream tasks with few labelled data.
%	
%

%
%
%
%- short and general: dont discuss specific results, 
%- but broad statements that sum up the most important insights
%- do not introduce new data or interpretation

%reminder the reader:
%- why you took the approach
%- what you expected to find
%- how well the results matched expectations
%
%make recommendations
%
%emphasise contributions



