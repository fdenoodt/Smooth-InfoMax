\chapter{Discussion and future work}
% scribbr:
% Step 1: Summarize your key findings
% Step 2: Give your interpretations (on results)
% Step 3: Discuss the implications
	% link met literature, bv kl divergence geeft veel useless dimensions (is same as literature)
% Step 4: Acknowledge the limitations
% Step 5: Share your recommendations
	% = future work, eventueel gericht op die limitaties.

	
In this thesis we introduced V-GIM, a self-supervised approach for interpretable representation learning through mutual information maximisation. In this thesis, we provide a discussion on V-GIM's results with respective to its interpretability. We discuss its limitations, and make recommendations for plausible future work.

%% why interpretable: chat gpt wou dat niet
%V-GIM's interpretability is achieved by defining latent representations as samples from Gaussian distributions which are optimised to be similar to the standard normal. As such, the dataset will cover the entire latent space around the origin, such that sampling a random point from this space is likely to result in a data point that is similar to the data. 



\section{Interpretability}
	
	% no b, wel a
	We analysed V-GIM's representations using t-SNE plots, linear classifiers, and decoders trained on top of V-GIM's representations. We observed that the representations contained vowel information but lacked consonant information. This was observed in both the t-SNE plots and the linear classifier results. We suggest that this is related to the duration of the phonemes. The InfoNCE objective maximises the mutual information between temporally nearby patches, assuming presence of common information in nearby data. However, the vowels in the dataset are typically pronounced for longer duration than the consonants, and thus, representations where a consonant is being pronounced have fewer information in common with nearby representations as in those representations the consonant may not be pronounced any more. These findings are align with \cite{lowePuttingEndEndtoEnd2020} who suggested that optimisation the InfoNCE objective favours global information over local information. 
	
	The decoder provided with insights into the speech information that remained in the representations. While the pronounced sounds were generally recognisable, the decoder occasionally generated incorrect consonants, for instance by producing the sound ``ba" when the original sound was ``ga". This further supports our findings that the representations contain less consonant information. Additionally the pronounced sounds were recognisable but sounded distorted, making it almost impossible to recognise the speaker's identity. This indicates that the speaker's identity may no longer be present in the representations.
	
	Interestingly, the vowel information was found to be concentrated in only a small subset of dimensions. This was observed in the vowel experiment, where a linear classifier trained on V-GIM's first module achieved high accuracies by assigning high weights to a few dimensions, while the majority of weights were close to zero, indicating that those dimensions did not contribute to the prediction. This suggests that the size of representations could be further reduced by removing dimensions that do not contribute to the task. Some of these dimensions likely carry different information, while others may be completely useless.
	
	
	% why useless dimensions appear
	We attribute the presence of useless dimensions in V-GIM's representations to the KL divergence term in the $\Lvnce$ loss function. The histogram plots revealed that some dimensions' distributions were nearly identical to the standard normal distribution, while others showed more variation. We assume that certain dimensions with more variation most likely carry all the actual information and contribute to a good InfoNCE bound, while the identical dimensions do not carry any useful information but help maintain a low KL divergence.
	
			
	% diff priors
	This problem of useless dimensions is also known in VAEs and can be mitigated by choosing different priors or posteriors. For instance, VampPrior addresses this problem by using a mixture of Gaussians as prior in stead of the typical standard normal \citep{tomczakVAEVampPrior2018}. Further work could explore alternative priors introduced to VAEs which we discussed in section \ref{cha:rel_alt_priors}, and investigate their performance in V-GIM. Alternatively, the problem of useless dimensions could potentially be mitigated by introducing a regularisation term applied to the weights of the similarity score function $\fkm$, which would enforce similar weights between different dimensions. This regularisation would encourage each dimension to contribute an equal amount of information.
	
	% disentanglement
	With regards to representation disentanglement, \cite{burgessUnderstandingDisentanglingBeta2018} argue that choosing a standard normal prior in VAEs encourages disentangled representations. These ideas can also be applied to V-GIM and should be further investigated in future work.
	
	
	% V-GIM enables interpretability of internal representations as well, potentially enabling to understand the network
	
	V-GIM's regularisation term ensures that sampling a random point in the latent space around the origin will likely result in a point that is similar to the original data. Moreover, since the training set covers the entire space around the origin, a decoder trained on this space will likely generalise well to unseen data around the origin. Therefore, the interpolation experiment allowed us to investigate what exact information was contained in each dimension, in each of V-GIM's modules. 
	
	We discovered three categories: dimensions containing information from one or two specific frequency bins, dimensions containing information spanning a range of frequency bins, and dimensions containing no information at all. Most dimensions were active around the 100Hz to 200Hz frequency range, similar to the pitch of a male voice \citep{rePreferencesVeryLow2012}.
	
	% towards true XAI
	While our work focused on understanding V-GIM's representations for two modules, achieving true explainable AI requires understanding not only the model's outputs but also how it obtained its outputs. V-GIM could serve as an initial step in this direction by defining each layer as a module, allowing for a better understanding of each activation in the network. Further research could explore the associated weights between modules to gain further insights in the model's internal workings.

	%. Consequently, if activations are understandable, understanding the exact weights may become more feasible as only a single layer must be analysed at a time.
		 
	%	In the interpolation study, decoders were trained on each of V-GIM's modules, providing us with insights in the contained information of each dimension. We discovered three categories: dimensions containing information of one or two specific frequency bins, dimensions containing information spanning an entire range of frequency bins, and dimensions containing no information at all, we call these the useless dimensions. Most dimensions were active around the 100Hz to 200Hz frequency range, which is similar to the pitch of a male voice.
	%	
	%	
	%
	%	further work, could take to more extremes a single module per layer such that each layer can be analyses and then potentially also the weights.
	
	



	
	
	% disclaimer: decoder only works on V-GIM, not GIM.
	%	It is noteworthy that insights obtained from decoder only viable because of V-GIM's regularisation term, and not in regularisation-free MI maximisation techniques such as CPC and V-GIM.
	%	
	
	%Additionally, the addition of an optional decoder provided benefits over encoder-decoder architectures, as the decoder was not required for training, providing more available memory for more complex architectures.
	
	%	Additionally, V-GIM's module architecture enables the observation of interpretable activations in between the network as well. Further work could investigate these internal representations further, so not only do we have the means to understand the final representations, as X, Y, we even have the means to understand internal, potentially giving even better insights in how neural networks operate. While other representation learning techniques, x,y,z claim interpretable representations, V-GIM's representations are interpretable, but additionally provide insights in the internal mechanism of the network as well.
	
	%	Note that:
	%		Interpretability analysis gives insight in information that is available, but making claims on what information is not included is harder, as could be that decoder didn't see it. interpretability analysis gives insight in information that is available, but making claims on what information is not included is harder, as could be that decoder didn't see it. 
		
	%	 	- some dimensions were very nicely Gaussian shaped while others were not, indicating that optimisation function could potentially maintain useless dimensions to keep up good cost function, while containing all information. So V-GIM exploits loss function, not necessarly learning as we expect.
	%	 	- test alternative priors van VAE
	%		 - test disentanglement
		

%By encoding each data point to its latent representation and creating a histogram for of the representations per dimension, we observed that V-GIM does indeed enforce each dimension to be standard normal, indicating that implications with respect to interpretability using the decoder are indeed applicable. 



		
\section{Performance benefits and representation variability}
		% beter in discussie van results?
		\cite{oordRepresentationLearningContrastive2019} and \cite{lowePuttingEndEndtoEnd2020} observed better performance in their papers for a similar speech recognition problem. We believe this is related to the size of individual representations, as they have 512 rather than 32 as in our work. Additionally, our representations capture longer time sequences and have a smaller resulting in potentially less mutual information between temporally nearby patches. Due to computational constraints, and since our primary concern was to analyse these representations, we maintained our own architecture where representations contain longer time frames.


		- performance is worse in second module, further attributed to less mutual information.

		- didn't observe a benefit from variation variance, even for the smallest subset sizes.
		- We hypothesised representation variance, resulting in more data points could improve the decision boundary, encouraging the boundary to be similar as to SVM, where distance is maximised for each point.
		- Taking inspiration from SVM's decision boundary, we investigated whether V-GIM's representation could offer a similar approach for alternative downstream tasks, is a potential 
			- encourage a better boundary, similar to SVM's \citep{hearstSupportVectorMachines1998, nobleWhatSupportVector2006}, maximising the margin between classes.
			 --> didn't seem the case.
		- explanation on why should be further investigated. One hypothesis is related to SVM's ...
		
			
\section{batch normalisation}
		- sindy didn't have issues of batch norm, but believe this is because each module consisted of a single layer, ours contain a number of layers. potentially: outputs from first module change too fast for second module to catch up.
	
\section{memory}
		- while V-GIM's greedy approach allows for distributed learning, enabling training on resource constraint devices. each module has a memory overhead due to the similarity score fkm, causing the combined memory requirements to be higher.
		- while GIM argues to resolve memory constraints, not entirely true. In fact we even countered the opposite as containing multiple neural networks, each with their own personal loss function (the loss function is based on fk which contains parameters that must be learned), and thus for early layers where the sequence is still long, a lot of memory is required. We went for a compromise on GIM by splitting up the architecture in merely two modules, significantly reducing the memory constraints.
	








%-- 
%decaying learing rate:
%we train using decaying lr, because models must first learn distributions and goes too slow if lr is too small.
%and a learning rate scheduler
%ExponentialLR
%decay rate 0.995
%
%---








%---
%The second module in GIM clearly doesn't have as much effect. This can be explained because there may not be as much common information anymore between the patches. There may be a source that says that cpc learns low level features, but the second module is supposed to learn more high level features, which cpc may have trouble with?
%---
%
%Future work:
%- Related work in VAE shows that gradually increasing regularisation term, results in better disentengledment, while avoiding posterior collapse. could have a kldweight scheduler.
%
%- not constrained solely to InfoNCE loss, the GIM architecture could work for other losses too that allow for greedy optimisation.
%
%
%- I didn't add an autoregressor as i didn't find a performance benefit. Potentially, with larger architecture could further improve performance.
%
%
%
%----
%Towards production setting:
%encodings are thus optimised to be close the standard normal. When in a production environment and new data is given, could in fact have an idea of how well generalisation to the production data: eg via anomaly detection if encodings are too far away from center. 
%= gives automated way of verifying generalisation.
%
%can then maybe see to which data that doesn't generalise well via outliers.
%
%----
%
%
%future work:
%- disentanglement should do more investations
%
%
%---
%GIM: Modular training
%could incrementally increase numb of modules and observe performance increase for downstream tasks.
%based on this, could find smallest gim architecture depth which satisfies required accuracies.
%
%----
%interpretability:
%most dimensions sensitive around 75 to 150 hz. this is as expected as the adult man speaks around 80 to 180 hz.
%
%---
%interpretability is only as good as the decoder. if a shitty decoder doesn't construct well, doesn't necessarily give correct conclusions about V-GIM.
%
%
%---
%Future work: alternatieve prior (zie related work.)
%
%
%
%
%
%
%\begin{itemize}
%	\item Explainability of latents is dependent on the performance of the decoder.
%	\item Intermediate loss function with kld resulted in similar behaviour as batch normalisation. Resulting in faster convergence than without kld.
%	\item We observed no quality loss in the learned representations. Data was equally easily separable.
%\end{itemize}