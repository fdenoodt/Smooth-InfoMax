\documentclass[]{book}
\usepackage{vub}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{pgfplots}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{subcaption}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{multirow}
\usepackage{array, makecell, rotating}
\usepackage{cleveref}
\usepackage{natbib}
\usepackage[toc,page]{appendix}
\usepackage{listofitems} % for \readlist to create arrays
\usetikzlibrary{arrows.meta} % for arrow size
\usepackage[outline]{contour} % glow around text
\contourlength{1.4pt}
\tikzstyle{mynode}=[thick,draw=blue,fill=blue!20,circle,minimum size=22]


%TODO UITLEG DISENTANGLEMENT:
%"Disentangled representation is a method that disentangles or represents each feature into narrowly defined variables and encodes them as separate dimensions [1]." cite latifDeepRepresentationLearning2021
%Y. Bengio, A. Courville, and P. Vincent, “Representation learning: A review and new perspectives,” IEEE transactions on pattern analysis and machine intelligence, vol. 35, no. 8, pp. 1798–1828, 2013


\tikzset{>=latex} % for LaTeX arrow head
\usepackage{xcolor}
\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}
\tikzstyle{node}=[thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6]
\tikzstyle{node in}=[node,green!20!black,draw=mygreen!30!black,fill=mygreen!25]
\tikzstyle{node hidden}=[node,blue!20!black,draw=myblue!30!black,fill=myblue!20]
\tikzstyle{node convol}=[node,orange!20!black,draw=myorange!30!black,fill=myorange!20]
\tikzstyle{node out}=[node,red!20!black,draw=myred!30!black,fill=myred!20]
\tikzstyle{connect}=[thick,mydarkblue] %,line cap=round
\tikzstyle{connect arrow}=[-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten <=0.5,shorten >=1]
\tikzset{ % node styles, numbered for easy mapping with \nstyle
	node 1/.style={node in},
	node 2/.style={node hidden},
	node 3/.style={node out},
}
\def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3


\usetikzlibrary{shapes.geometric, arrows}
\usepackage[pdftex]{pict2e}




%\includeonly{background}
%\includeonly{variationalcontrastivepredictivecoding}
%\includeonly{experiments}
%\includeonly{relatedwork}
%\includeonly{appendix}





\pagenumbering{gobble}




%\title{Variational Greedy InfoMax: Interpretable Representation Learning with Latent Space Constraints}
%\subtitle{Combining Contrastive Predictive Coding and Variation Autoencoders for Enhanced Self-Supervised Learning}

\title{Variational Greedy InfoMax}
\subtitle{Interpretable representation learning with latent space constraints}

\author{Fabian Denoodt}
\faculty{Science and Bio-Engineering Sciences}
\promotors{Promotor(s):~Prof. Dr. Bart de Boer}
\pretitle{Master thesis submitted in partial fulfilment of the requirements for the degree of Master of Science In de Ingenieurswetenschappen: Computerwetenschappen}
\date{2022-2023}


\begin{document}
\maketitle
\title{[Dutch] Variational Greedy InfoMax}
\subtitle{[Dutch] Towards independent and interpretable representations}
\pretitle{Proefschrift ingediend met het oog op het behalen van de graad van Master of Science In de Ingenieurswetenschappen: Computerwetenschappen}
\faculty{Wetenschappen en Bio-ingenieurswetenschappen}
\maketitle

\tableofcontents


\input{commands}

\include{introduction}
\include{background}
\include{variationalcontrastivepredictivecoding}
\include{experiments}
\include{relatedwork}

\chapter{Discussion}

-- 
decaying learing rate:
	we train using decaying lr, because models must first learn distributions and goes too slow if lr is too small.
	and a learning rate scheduler
	ExponentialLR
	decay rate 0.995

---
batch norm:
 - sindy didn't have issues of batch norm, but believe this is because each module consisted of a single layer, ours contain a number of layers. potentially: outputs from first module change too fast for second module to catch up.




while GIM argues to resolve memory constraints, not entirely true. In fact we even countered the opposite as containing multiple neural networks, each with their own personal loss function (the loss function is based on fk which contains parameters that must be learned), and thus for early layers where the sequence is still long, a lot of memory is required. We went for a compromise on GIM by splitting up the architecture in merely two modules, significantly reducing the memory constraints.


---
The second module in GIM clearly doesn't have as much effect. This can be explained because there may not be as much common information anymore between the patches. There may be a source that says that cpc learns low level features, but the second module is supposed to learn more high level features, which cpc may have trouble with?
---

Future work:
 - Related work in VAE shows that gradually increasing regularisation term, results in better disentengledment, while avoiding posterior collapse. could have a kldweight scheduler.
 
- not constrained solely to InfoNCE loss, the GIM architecture could work for other losses too that allow for greedy optimisation.


- I didn't add an autoregressor as i didn't find a performance benefit. Potentially, with larger architecture could further improve performance.



----
Towards production setting:
	encodings are thus optimised to be close the standard normal. When in a production environment and new data is given, could in fact have an idea of how well generalisation to the production data: eg via anomaly detection if encodings are too far away from center. 
	= gives automated way of verifying generalisation.
	
	can then maybe see to which data that doesn't generalise well via outliers.
	
----


future work:
- disentanglement should do more investations


---
GIM: Modular training
could incrementally increase numb of modules and observe performance increase for downstream tasks.
based on this, could find smallest gim architecture depth which satisfies required accuracies.

----
interpretability:
most dimensions sensitive around 75 to 150 hz. this is as expected as the adult man speaks around 80 to 180 hz.

---
interpretability is only as good as the decoder. if a shitty decoder doesn't construct well, doesn't necessarily give correct conclusions about V-GIM.


---
Future work:alternatieve prior (zie related work.)






\begin{itemize}
	\item Explainability of latents is dependent on the performance of the decoder.
	\item Intermediate loss function with kld resulted in similar behaviour as batch normalisation. Resulting in faster convergence than without kld.
	\item We observed no quality loss in the learned representations. Data was equally easily separable.
\end{itemize}



\bibliographystyle{apalike}
\bibliography{references}


\include{appendix}

\end{document}
