# pylint: disable=Missing class docstringpylint(missing-class-docstring)


import torch.nn as nn

from models import (
    cnn_encoder,
    loss_InfoNCE,
)

class IndependentModule(nn.Module):
    def __init__(
        self, opt,
        # hidden either for cnn or fully connected
        enc_kernel_sizes, enc_strides, enc_padding, hidden_dim, enc_input=1, calc_accuracy=False,
    ):
        super(IndependentModule, self).__init__()

        self.opt = opt
        self.calc_accuracy = calc_accuracy

        # encoder
        self.encoder = cnn_encoder.CNNEncoder(
            input_dim=enc_input,
            hidden=hidden_dim,
            kernel_sizes=enc_kernel_sizes,
            strides=enc_strides,
            padding=enc_padding,
        )
        self.hidden_dim = hidden_dim
        
        self.loss = loss_InfoNCE.InfoNCE_Loss(opt, self.hidden_dim, self.hidden_dim, calc_accuracy)
        # self.loss = loss_InfoNCE.InfoNCE_Loss(opt, self.hidden_dim, self.enc_hidden, calc_accuracy)

    def get_latents(self, x):
        """
        Calculate the latent representation of the input (using both the encoder and the autoregressive model)
        :param x: batch with sampled audios (dimensions: B x C x L)
        :return: c - latent representation of the input (either the output of the autoregressor,
                if use_autoregressor=True, or the output of the encoder otherwise)
                z - latent representation generated by the encoder (or x if self.use_encoder=False)
                both of dimensions: B x L x C
        """
        # encoder in and out: B x C x L, permute to be  B x L x C
        z = self.encoder(x)
        z = z.permute(0, 2, 1)

        return z

    def forward(self, x):
        """
        combines all the operations necessary for calculating the loss and accuracy of the network given the input
        :param x: batch with sampled audios (dimensions: B x C x L)
        :return: total_loss - average loss over all samples, timesteps and prediction steps in the batch
                accuracies - average accuracies over all samples, timesteps and predictions steps in the batch
                c - latent representation of the input (either the output of the autoregressor,
                if use_autoregressor=True, or the output of the encoder otherwise)
        """

        # B x L x C = Batch size x #channels x length
        z = self.get_latents(x)

        total_loss, accuracies = self.loss.get_loss(z)

        # for multi-GPU training
        total_loss = total_loss.unsqueeze(0)
        accuracies = accuracies.unsqueeze(0)

        return total_loss, accuracies, z
        # todo: fix functions that call forward, they no longer receive a c
    
